{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Knows You - Predict Reddit user personalities based on comments \n",
    "\n",
    "### Contents\n",
    "1. Introduction \n",
    "2. Import Packages and Data \n",
    "3. Data Cleaning & Initial EDA\n",
    "4. Text Processing \n",
    "5. Simple Models\n",
    "6. SpaCy Text Processing\n",
    "7. Models & Grid Search\n",
    "8. Dealing with Imbalanced Data \n",
    "9. Models\n",
    "10. LDA Topic Modelling\n",
    "11. Limitations\n",
    "12. Future Improvements\n",
    "13. Conclusion\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Nicknamed “Front Page of the Internet”, Reddit has always been a conglomerate of information since its inception in 2005. In 2018 alone, there are 153 million posts and 1.2 billion comments added to this popular online forum (Reddit, 2018). As one of the most popular websites on the internet, the high volume of daily activity is valued by advertisers, but Reddit seems like a hard place to crack.\n",
    "\n",
    "Unlike other social networks such as Facebook and Instagram, users can post anonymously , thus granted more freedom. But do the posts still somehow reveal who we are deep down? This project aims to  predict what type of personality (MBTI) the user is based on their posts. \n",
    "\n",
    "## Import Packages and Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:13:03.017928Z",
     "start_time": "2019-12-15T19:12:58.671995Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Doylism/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# regular packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re \n",
    "import os\n",
    "import string\n",
    "\n",
    "\n",
    "# nltk \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:13:20.086174Z",
     "start_time": "2019-12-15T19:13:13.315652Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data \n",
    "df = pd.read_csv('../../../original_data/mbti_reddit_1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T19:13:32.460363Z",
     "start_time": "2019-12-15T19:13:32.438247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flair_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>INFP: The Dreamer Senpai</td>\n",
       "      <td>Lol that's why I left.</td>\n",
       "      <td>entp</td>\n",
       "      <td>LadyBanterbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INTP: The Theorist</td>\n",
       "      <td>I was just about to post \"I try telling people...</td>\n",
       "      <td>INTP</td>\n",
       "      <td>Finarin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INFP: The Dreamer</td>\n",
       "      <td>My first thought was Pepsi or something. Proba...</td>\n",
       "      <td>WTF</td>\n",
       "      <td>xanplease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ENTP: Antisocial Extrovert, Rational Eccentric</td>\n",
       "      <td>Not if the formula is something like \"every ti...</td>\n",
       "      <td>youtubehaiku</td>\n",
       "      <td>HeirToGallifrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INTP/18/m/blankly staring at you</td>\n",
       "      <td>Does this imply I'm a five now?</td>\n",
       "      <td>entp</td>\n",
       "      <td>lightfive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INTP: The Theorist</td>\n",
       "      <td>Well, I wouldn't know but I think there's a lo...</td>\n",
       "      <td>InternetIsBeautiful</td>\n",
       "      <td>ElementalVoltage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>The INFJ Dude</td>\n",
       "      <td>sine na, support the directors, actors and oth...</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>BabyFlo70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Honorary INFP; INTP/21/F</td>\n",
       "      <td>I use just enough vacation days so that I don'...</td>\n",
       "      <td>tumblr</td>\n",
       "      <td>RockinSocksReborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>intp or something of the sort</td>\n",
       "      <td>Can be ur angle... or you're devil ;)</td>\n",
       "      <td>woof_irl</td>\n",
       "      <td>crowbird_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INTP/23/F</td>\n",
       "      <td>I mean we don't how much influence Crow has on...</td>\n",
       "      <td>RWBY</td>\n",
       "      <td>RockinSocksReborn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             body  \\\n",
       "flair_text                                                                                          \n",
       "INFP: The Dreamer Senpai                                                  Lol that's why I left.    \n",
       "INTP: The Theorist                              I was just about to post \"I try telling people...   \n",
       "INFP: The Dreamer                               My first thought was Pepsi or something. Proba...   \n",
       "ENTP: Antisocial Extrovert, Rational Eccentric  Not if the formula is something like \"every ti...   \n",
       "INTP/18/m/blankly staring at you                                  Does this imply I'm a five now?   \n",
       "INTP: The Theorist                              Well, I wouldn't know but I think there's a lo...   \n",
       "The INFJ Dude                                   sine na, support the directors, actors and oth...   \n",
       "Honorary INFP; INTP/21/F                        I use just enough vacation days so that I don'...   \n",
       "intp or something of the sort                              Can be ur angle... or you're devil ;)    \n",
       "INTP/23/F                                       I mean we don't how much influence Crow has on...   \n",
       "\n",
       "                                                          subreddit  \\\n",
       "flair_text                                                            \n",
       "INFP: The Dreamer Senpai                                       entp   \n",
       "INTP: The Theorist                                             INTP   \n",
       "INFP: The Dreamer                                               WTF   \n",
       "ENTP: Antisocial Extrovert, Rational Eccentric         youtubehaiku   \n",
       "INTP/18/m/blankly staring at you                               entp   \n",
       "INTP: The Theorist                              InternetIsBeautiful   \n",
       "The INFJ Dude                                           Philippines   \n",
       "Honorary INFP; INTP/21/F                                     tumblr   \n",
       "intp or something of the sort                              woof_irl   \n",
       "INTP/23/F                                                      RWBY   \n",
       "\n",
       "                                                           author  \n",
       "flair_text                                                         \n",
       "INFP: The Dreamer Senpai                           LadyBanterbury  \n",
       "INTP: The Theorist                                        Finarin  \n",
       "INFP: The Dreamer                                       xanplease  \n",
       "ENTP: Antisocial Extrovert, Rational Eccentric    HeirToGallifrey  \n",
       "INTP/18/m/blankly staring at you                        lightfive  \n",
       "INTP: The Theorist                               ElementalVoltage  \n",
       "The INFJ Dude                                           BabyFlo70  \n",
       "Honorary INFP; INTP/21/F                        RockinSocksReborn  \n",
       "intp or something of the sort                           crowbird_  \n",
       "INTP/23/F                                       RockinSocksReborn  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Initial EDA\n",
    "\n",
    "The original dataset was separated into 17 csv files, each containing around 1.5 million user comments from Reddit. I decided to use only a portion of the data due to computation and time restrain. First I loaded in one file and examine the data.\n",
    "\n",
    "We can see that the personality type is contained in the users' flair_text, aka their signatures. Therefore, the first step is to do some feature engineering to extract the personality types from their flair text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T04:27:15.465222Z",
     "start_time": "2019-12-01T04:26:38.444017Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract MBTI from flair text \n",
    "\n",
    "mbti = ['INFP','INFJ','INTP','INTJ','ENTP','ENFP','ISTP','ISFP','ENTJ','ISTJ','ENFJ','ISFJ','ESTP','ESFP','ESFJ','ESTJ']\n",
    "pat = '|'.join(r\"\\b{}\\b\".format(x) for x in mbti)\n",
    "\n",
    "df['personality'] = df['flair_text'].str.findall(pat, flags=re.I).str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T04:27:24.182447Z",
     "start_time": "2019-12-01T04:27:19.890917Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform text in personality column to all upper case \n",
    "df['personality'] = df['personality'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some users have multiple MBTI personalities in their flair texts, after examing the flairs, I decide to only keep the first one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T04:28:30.580629Z",
     "start_time": "2019-12-01T04:28:14.980544Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the first MBTI indicator from the rest \n",
    "new = df['personality'].str.split(' ', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T04:28:40.807663Z",
     "start_time": "2019-12-01T04:28:40.801925Z"
    }
   },
   "outputs": [],
   "source": [
    "# rename the sub df\n",
    "new.columns=['first','second']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T04:28:57.274301Z",
     "start_time": "2019-12-01T04:28:56.983245Z"
    }
   },
   "outputs": [],
   "source": [
    "# add the separated MBTI to the main dataframe\n",
    "df['MBTI'] = new['first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T04:29:12.090009Z",
     "start_time": "2019-12-01T04:29:07.884100Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the personality column and rename all the columns \n",
    "df = df.drop('personality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T04:29:20.891564Z",
     "start_time": "2019-12-01T04:29:20.877144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flair</th>\n",
       "      <th>comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>username</th>\n",
       "      <th>MBTI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INFP: The Dreamer Senpai</td>\n",
       "      <td>Lol that's why I left.</td>\n",
       "      <td>entp</td>\n",
       "      <td>LadyBanterbury</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INTP: The Theorist</td>\n",
       "      <td>I was just about to post \"I try telling people all the time that I'm always joking unless I say 'I am being serious right now' and they still don't catch on!\"  But here you've already figured out the secret.  It's like you know me.</td>\n",
       "      <td>INTP</td>\n",
       "      <td>Finarin</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFP: The Dreamer</td>\n",
       "      <td>My first thought was Pepsi or something. Probably not alcohol.</td>\n",
       "      <td>WTF</td>\n",
       "      <td>xanplease</td>\n",
       "      <td>INFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ENTP: Antisocial Extrovert, Rational Eccentric</td>\n",
       "      <td>Not if the formula is something like \"every time it says 'Do', add 5 bpm\". Then it would be arithmetic.</td>\n",
       "      <td>youtubehaiku</td>\n",
       "      <td>HeirToGallifrey</td>\n",
       "      <td>ENTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INTP/18/m/blankly staring at you</td>\n",
       "      <td>Does this imply I'm a five now?</td>\n",
       "      <td>entp</td>\n",
       "      <td>lightfive</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            flair  \\\n",
       "0  INFP: The Dreamer Senpai                         \n",
       "1  INTP: The Theorist                               \n",
       "2  INFP: The Dreamer                                \n",
       "3  ENTP: Antisocial Extrovert, Rational Eccentric   \n",
       "4  INTP/18/m/blankly staring at you                 \n",
       "\n",
       "                                                                                                                                                                                                                                  comments  \\\n",
       "0  Lol that's why I left.                                                                                                                                                                                                                    \n",
       "1  I was just about to post \"I try telling people all the time that I'm always joking unless I say 'I am being serious right now' and they still don't catch on!\"  But here you've already figured out the secret.  It's like you know me.   \n",
       "2  My first thought was Pepsi or something. Probably not alcohol.                                                                                                                                                                            \n",
       "3  Not if the formula is something like \"every time it says 'Do', add 5 bpm\". Then it would be arithmetic.                                                                                                                                   \n",
       "4  Does this imply I'm a five now?                                                                                                                                                                                                           \n",
       "\n",
       "      subreddit         username  MBTI  \n",
       "0  entp          LadyBanterbury   INFP  \n",
       "1  INTP          Finarin          INTP  \n",
       "2  WTF           xanplease        INFP  \n",
       "3  youtubehaiku  HeirToGallifrey  ENTP  \n",
       "4  entp          lightfive        INTP  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the columns \n",
    "df.columns = ['flair','comments','subreddit','username','MBTI']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T04:30:11.157994Z",
     "start_time": "2019-12-01T04:30:10.350813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    937352\n",
       "INTP    902498\n",
       "INFJ    816254\n",
       "ENTP    675685\n",
       "INTJ    529188\n",
       "ENTJ    193037\n",
       "ISTP    169520\n",
       "ENFP    154679\n",
       "ENFJ    91137 \n",
       "ESTP    40101 \n",
       "ISFJ    39508 \n",
       "ISTJ    38636 \n",
       "ISFP    26766 \n",
       "ESTJ    17941 \n",
       "ESFP    12475 \n",
       "ESFJ    11311 \n",
       "        9912  \n",
       "Name: MBTI, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique values and counts in the MBTI columns \n",
    "df['MBTI'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T04:32:37.603480Z",
     "start_time": "2019-12-01T04:32:34.515573Z"
    }
   },
   "outputs": [],
   "source": [
    "# there is 9912 comments with no MBTI indicators, we will remove them from the df\n",
    "df = df[df['MBTI']!=''].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T04:32:55.096081Z",
     "start_time": "2019-12-01T04:32:51.573825Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comments Counts by Personality Types')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.countplot(data=df, x='MBTI', order = df['MBTI'].value_counts().index)\n",
    "plt.xlabel('personality types')\n",
    "plt.ylabel('counts')\n",
    "plt.title('Comments Counts by Personality Types')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph we can see that INFP, INTP, INFJ, ENTP and INTJ contribute the most comments in our set. This reflects the nature of Reddit and even the distribution of these types in the population, however, the imbalance of the data is not great for our model. Therefore, I decide to keep one block of the data from the first 5 personalities and use data from the rest of the files to upsample the rest of the personality types. \n",
    "\n",
    "I put the previous feature engineering and filter steps into a script and iterated over all files to get more data for the remaining personality types and generated one df/csv in the end. \n",
    "\n",
    "**Script below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to upsample the data from other data blocks \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# read in a block of data\n",
    "df = pd.read_csv(sys.argv[1])\n",
    "\n",
    "# drop missing value\n",
    "df = df.dropna().copy()\n",
    "\n",
    "# extract MBTI from flair text\n",
    "import re\n",
    "\n",
    "mbti = ['INFP','INFJ','INTP','INTJ','ENTP','ENFP','ISTP','ISFP','ENTJ','ISTJ','ENFJ','ISFJ','ESTP','ESFP','ESFJ','ESTJ']\n",
    "pat = '|'.join(r\"\\b{}\\b\".format(x) for x in mbti)\n",
    "\n",
    "df['personality'] = df['flair_text'].str.findall(pat, flags=re.I).str.join(' ')\n",
    "\n",
    "# transform text in personality column to all upper case\n",
    "df['personality'] = df['personality'].str.upper()\n",
    "\n",
    "# split the first MBTI indicator from the rest\n",
    "new = df['personality'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "# rename the sub df\n",
    "new.columns=['first','second']\n",
    "\n",
    "# add the separated MBTI to the main dataframe\n",
    "df['MBTI'] = new['first']\n",
    "\n",
    "# drop the personality column and rename all the columns\n",
    "df = df.drop('personality', axis=1)\n",
    "\n",
    "# rename the columns\n",
    "df.columns = ['flair','comments','subreddit','username','MBTI']\n",
    "\n",
    "# select personalities we want to keep\n",
    "mbti_selection = ['ENFP','ISTP','ISFP','ENTJ','ISTJ','ENFJ','ISFJ','ESTP','ESFP','ESFJ','ESTJ']\n",
    "# above selection is adjusted according to how many data points there are\n",
    "\n",
    "df_sub = df[df['MBTI'].isin(mbti_selection)].copy().reset_index()\n",
    "\n",
    "# save to new csv file\n",
    "df_sub.to_csv(sys.argv[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the scripts below, I was able to generate multiple csv files, below I read in them into one dataframe, which is the master dataframe I use for the remainder of the project.\n",
    "\n",
    "### Read in multiple files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:41:25.603961Z",
     "start_time": "2019-12-02T00:41:25.589164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../original_data/mbti_reddit_clean1.csv', '../original_data/mbti_reddit_clean10.csv', '../original_data/mbti_reddit_clean11.csv', '../original_data/mbti_reddit_clean12.csv', '../original_data/mbti_reddit_clean13.csv', '../original_data/mbti_reddit_clean14.csv', '../original_data/mbti_reddit_clean15.csv', '../original_data/mbti_reddit_clean16.csv', '../original_data/mbti_reddit_clean17.csv', '../original_data/mbti_reddit_clean18.csv', '../original_data/mbti_reddit_clean2.csv', '../original_data/mbti_reddit_clean3.csv', '../original_data/mbti_reddit_clean4.csv', '../original_data/mbti_reddit_clean5.csv', '../original_data/mbti_reddit_clean6.csv', '../original_data/mbti_reddit_clean7.csv', '../original_data/mbti_reddit_clean9.csv']\n"
     ]
    }
   ],
   "source": [
    "# read in multiple files \n",
    "import glob\n",
    "\n",
    "datafiles = glob.glob('../original_data/mbti_reddit_clean*.csv') #the * is a wildcard\n",
    "\n",
    "datafiles.sort() # must have this line to sort the names \n",
    "\n",
    "print(datafiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:41:57.102899Z",
     "start_time": "2019-12-02T00:41:25.608928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# concat multiple files into one \n",
    "df_new = pd.concat((pd.read_csv(f, lineterminator='\\n') for f in datafiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:41:57.152984Z",
     "start_time": "2019-12-02T00:41:57.112226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3004071, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check rows and shape \n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:41:57.313888Z",
     "start_time": "2019-12-02T00:41:57.167972Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comments</th>\n",
       "      <th>flair</th>\n",
       "      <th>index</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INFP</td>\n",
       "      <td>0</td>\n",
       "      <td>Lol that's why I left.</td>\n",
       "      <td>INFP: The Dreamer Senpai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entp</td>\n",
       "      <td>LadyBanterbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INTP</td>\n",
       "      <td>1</td>\n",
       "      <td>I was just about to post \"I try telling people...</td>\n",
       "      <td>INTP: The Theorist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INTP</td>\n",
       "      <td>Finarin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFP</td>\n",
       "      <td>2</td>\n",
       "      <td>My first thought was Pepsi or something. Proba...</td>\n",
       "      <td>INFP: The Dreamer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WTF</td>\n",
       "      <td>xanplease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>3</td>\n",
       "      <td>Not if the formula is something like \"every ti...</td>\n",
       "      <td>ENTP: Antisocial Extrovert, Rational Eccentric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>youtubehaiku</td>\n",
       "      <td>HeirToGallifrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INTP</td>\n",
       "      <td>4</td>\n",
       "      <td>Does this imply I'm a five now?</td>\n",
       "      <td>INTP/18/m/blankly staring at you</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entp</td>\n",
       "      <td>lightfive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>INTP</td>\n",
       "      <td>5</td>\n",
       "      <td>Well, I wouldn't know but I think there's a lo...</td>\n",
       "      <td>INTP: The Theorist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>InternetIsBeautiful</td>\n",
       "      <td>ElementalVoltage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>6</td>\n",
       "      <td>sine na, support the directors, actors and oth...</td>\n",
       "      <td>The INFJ Dude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>BabyFlo70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>INFP</td>\n",
       "      <td>7</td>\n",
       "      <td>I use just enough vacation days so that I don'...</td>\n",
       "      <td>Honorary INFP; INTP/21/F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tumblr</td>\n",
       "      <td>RockinSocksReborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>INTP</td>\n",
       "      <td>8</td>\n",
       "      <td>Can be ur angle... or you're devil ;)</td>\n",
       "      <td>intp or something of the sort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>woof_irl</td>\n",
       "      <td>crowbird_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>INTP</td>\n",
       "      <td>9</td>\n",
       "      <td>I mean we don't how much influence Crow has on...</td>\n",
       "      <td>INTP/23/F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RWBY</td>\n",
       "      <td>RockinSocksReborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>INTP</td>\n",
       "      <td>10</td>\n",
       "      <td>Many fewer people by now, I'm guessing.</td>\n",
       "      <td>INTP-P-P-P-Poker face</td>\n",
       "      <td>NaN</td>\n",
       "      <td>funny</td>\n",
       "      <td>codepoet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>INFP</td>\n",
       "      <td>11</td>\n",
       "      <td>Not going on a third date isn't exactly a brea...</td>\n",
       "      <td>INFP: The Dreamer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>rabidhamster87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>12</td>\n",
       "      <td>I just want a NES Classic Controller since I a...</td>\n",
       "      <td>INFJ (Male)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nes</td>\n",
       "      <td>SapphireDrew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>13</td>\n",
       "      <td>maybe you were being tongue in cheek, but you ...</td>\n",
       "      <td>ENTP 26 M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drugs</td>\n",
       "      <td>patternsofpatterns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>INFP</td>\n",
       "      <td>14</td>\n",
       "      <td>I agree that the consistant position is to sup...</td>\n",
       "      <td>INFP: The Dreamer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "      <td>francis2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>INTP</td>\n",
       "      <td>15</td>\n",
       "      <td>Alors ?\\n\\nY'a pas de balise integrée. Faut le...</td>\n",
       "      <td>INTP: The Theorist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>france</td>\n",
       "      <td>ScalSaver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>16</td>\n",
       "      <td>Its kind of strange how they will lump very va...</td>\n",
       "      <td>INTJ♂</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Megaten</td>\n",
       "      <td>bunker_man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>INFP</td>\n",
       "      <td>17</td>\n",
       "      <td>Wow, that's some fucked up woman. I'm kind of ...</td>\n",
       "      <td>INFP Bitches be bitchin'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>childfree</td>\n",
       "      <td>I-ate-your-pony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>18</td>\n",
       "      <td>It's about psychotic tire, that kills people. ...</td>\n",
       "      <td>ISTJ | literally your dad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entp</td>\n",
       "      <td>lightseven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>19</td>\n",
       "      <td>I like you</td>\n",
       "      <td>ENTP: The Explorer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reddevils</td>\n",
       "      <td>knoxisback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>20</td>\n",
       "      <td>Hella dank, my dude</td>\n",
       "      <td>Some Rando ENTP that took a wrong turn at Albu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TooMeIrlForMeIrl</td>\n",
       "      <td>-BlitzN9ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>21</td>\n",
       "      <td>Stats mean relatively little when attempting t...</td>\n",
       "      <td>ENTP, Sx 5. Twentysomething male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CFBOffTopic</td>\n",
       "      <td>hammersklavier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>INFP</td>\n",
       "      <td>22</td>\n",
       "      <td>I've never been to this subreddit and I ain't ...</td>\n",
       "      <td>INFP: The Dreamer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>britishproblems</td>\n",
       "      <td>TorbjornOskarsson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>23</td>\n",
       "      <td>No, I made it. But the original comic was just...</td>\n",
       "      <td>INTJ♂</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Megaten</td>\n",
       "      <td>bunker_man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>24</td>\n",
       "      <td>hmmm</td>\n",
       "      <td>INFJ-35-M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>westworld</td>\n",
       "      <td>Squeezycakes17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>INTP</td>\n",
       "      <td>25</td>\n",
       "      <td>Blue cheese to me smells and tastes exactly li...</td>\n",
       "      <td>INTP: The Theorist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>indil47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>26</td>\n",
       "      <td>For sure! Also check out Bjorn Nyland's YouTub...</td>\n",
       "      <td>25F INFJ | Partner to 24M INTJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>teslamotors</td>\n",
       "      <td>Killerzeit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>INTP</td>\n",
       "      <td>27</td>\n",
       "      <td>I helped some friends of mine purchase two Hon...</td>\n",
       "      <td>INTP SPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cars</td>\n",
       "      <td>Uncle_Skeeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>28</td>\n",
       "      <td>When the white kinght becomes the princess [](...</td>\n",
       "      <td>ENTP-xD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forsen</td>\n",
       "      <td>Andrescarmona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>INFP</td>\n",
       "      <td>29</td>\n",
       "      <td>That face is hers? Is she sure???</td>\n",
       "      <td>INFP: The Dreamer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oldpeoplefacebook</td>\n",
       "      <td>xthebirdhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>INTP</td>\n",
       "      <td>30</td>\n",
       "      <td>[INTj-Ne and INTj-Ti](http://www.sociotype.com...</td>\n",
       "      <td>INTP (depressed ENTP?)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INTP</td>\n",
       "      <td>owlsymbolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>INTP</td>\n",
       "      <td>31</td>\n",
       "      <td>En même temps il vaudrait au moins 10 fois ce ...</td>\n",
       "      <td>INTP 5w4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>france</td>\n",
       "      <td>Mr_Canard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>32</td>\n",
       "      <td>I do too, but can one come back from it all? H...</td>\n",
       "      <td>INTJ: The Mastermind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intj</td>\n",
       "      <td>DannyDJaxson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>33</td>\n",
       "      <td>As opposed to INTP? Definitely. And the way yo...</td>\n",
       "      <td>INFJ 20m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entp</td>\n",
       "      <td>RASK0LN1K0V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>34</td>\n",
       "      <td>It may have escaped your notice, but that's th...</td>\n",
       "      <td>41 F, ENTP 7w6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>secretsanta</td>\n",
       "      <td>cyronius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>35</td>\n",
       "      <td>Well you are more my type ;D</td>\n",
       "      <td>INFJ - Ni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overwatch</td>\n",
       "      <td>AndrogynousAve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>INTP</td>\n",
       "      <td>36</td>\n",
       "      <td>The sea anemone simply is built that is can su...</td>\n",
       "      <td>INTP♂</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whowouldwin</td>\n",
       "      <td>polaristar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>37</td>\n",
       "      <td>As a 5w4 I'm still figuring this all out, but ...</td>\n",
       "      <td>[INFJ]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enneagram</td>\n",
       "      <td>LithiumEnergy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>INTP</td>\n",
       "      <td>38</td>\n",
       "      <td>Last time that happened to me I wrongfully fla...</td>\n",
       "      <td>INTP: The Theorist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>buildapc</td>\n",
       "      <td>OppaiGaKawaiiDesu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>INTP</td>\n",
       "      <td>39</td>\n",
       "      <td>Double check all of your cables especially you...</td>\n",
       "      <td>INTP/INTJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>techsupport</td>\n",
       "      <td>2_4_16_256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>INTP</td>\n",
       "      <td>40</td>\n",
       "      <td>Fuck you</td>\n",
       "      <td>INTP♀</td>\n",
       "      <td>NaN</td>\n",
       "      <td>theydidthefuckyou</td>\n",
       "      <td>pemGi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>41</td>\n",
       "      <td>He promised to fuck the climate in his campaig...</td>\n",
       "      <td>ISTP, fuck enneagram</td>\n",
       "      <td>NaN</td>\n",
       "      <td>startrek</td>\n",
       "      <td>gerusz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>42</td>\n",
       "      <td>Yea, that was my main thing about this tbh, wh...</td>\n",
       "      <td>[INTJ]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>orangecounty</td>\n",
       "      <td>Spore2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>43</td>\n",
       "      <td>The prospect of a wedding and the fact that ev...</td>\n",
       "      <td>ENTP♂</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mbti</td>\n",
       "      <td>Aurarus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>INFP</td>\n",
       "      <td>44</td>\n",
       "      <td>To be fair, voting a \"straight Republican tick...</td>\n",
       "      <td>INFP: The Dreamer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>politics</td>\n",
       "      <td>DuplexFields</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>45</td>\n",
       "      <td>I think he isn't cannon. He's from some extend...</td>\n",
       "      <td>24M ENTP 5w4 Sp sx so</td>\n",
       "      <td>NaN</td>\n",
       "      <td>outside</td>\n",
       "      <td>ScalSaver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>INTP</td>\n",
       "      <td>46</td>\n",
       "      <td>It all depends on how you look at it.</td>\n",
       "      <td>[INTP]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>science</td>\n",
       "      <td>Jimmy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>47</td>\n",
       "      <td>I can't believe I had to get this far down to ...</td>\n",
       "      <td>INFJ SX/SO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>videos</td>\n",
       "      <td>Lamzn6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>48</td>\n",
       "      <td>Since some responses just list people, I'll fo...</td>\n",
       "      <td>INTJ♂</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AsianMasculinity</td>\n",
       "      <td>DoktorLuciferWong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>INFP</td>\n",
       "      <td>49</td>\n",
       "      <td>The call of midnight by future world music.</td>\n",
       "      <td>INFP: The Star-Gazer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>MrRyyi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MBTI  Unnamed: 0                                           comments  \\\n",
       "0   INFP           0                            Lol that's why I left.    \n",
       "1   INTP           1  I was just about to post \"I try telling people...   \n",
       "2   INFP           2  My first thought was Pepsi or something. Proba...   \n",
       "3   ENTP           3  Not if the formula is something like \"every ti...   \n",
       "4   INTP           4                    Does this imply I'm a five now?   \n",
       "5   INTP           5  Well, I wouldn't know but I think there's a lo...   \n",
       "6   INFJ           6  sine na, support the directors, actors and oth...   \n",
       "7   INFP           7  I use just enough vacation days so that I don'...   \n",
       "8   INTP           8             Can be ur angle... or you're devil ;)    \n",
       "9   INTP           9  I mean we don't how much influence Crow has on...   \n",
       "10  INTP          10            Many fewer people by now, I'm guessing.   \n",
       "11  INFP          11  Not going on a third date isn't exactly a brea...   \n",
       "12  INFJ          12  I just want a NES Classic Controller since I a...   \n",
       "13  ENTP          13  maybe you were being tongue in cheek, but you ...   \n",
       "14  INFP          14  I agree that the consistant position is to sup...   \n",
       "15  INTP          15  Alors ?\\n\\nY'a pas de balise integrée. Faut le...   \n",
       "16  INTJ          16  Its kind of strange how they will lump very va...   \n",
       "17  INFP          17  Wow, that's some fucked up woman. I'm kind of ...   \n",
       "18  ISTJ          18  It's about psychotic tire, that kills people. ...   \n",
       "19  ENTP          19                                        I like you    \n",
       "20  ENTP          20                                Hella dank, my dude   \n",
       "21  ENTP          21  Stats mean relatively little when attempting t...   \n",
       "22  INFP          22  I've never been to this subreddit and I ain't ...   \n",
       "23  INTJ          23  No, I made it. But the original comic was just...   \n",
       "24  INFJ          24                                               hmmm   \n",
       "25  INTP          25  Blue cheese to me smells and tastes exactly li...   \n",
       "26  INFJ          26  For sure! Also check out Bjorn Nyland's YouTub...   \n",
       "27  INTP          27  I helped some friends of mine purchase two Hon...   \n",
       "28  ENTP          28  When the white kinght becomes the princess [](...   \n",
       "29  INFP          29                  That face is hers? Is she sure???   \n",
       "30  INTP          30  [INTj-Ne and INTj-Ti](http://www.sociotype.com...   \n",
       "31  INTP          31  En même temps il vaudrait au moins 10 fois ce ...   \n",
       "32  INTJ          32  I do too, but can one come back from it all? H...   \n",
       "33  INFJ          33  As opposed to INTP? Definitely. And the way yo...   \n",
       "34  ENTP          34  It may have escaped your notice, but that's th...   \n",
       "35  INFJ          35                       Well you are more my type ;D   \n",
       "36  INTP          36  The sea anemone simply is built that is can su...   \n",
       "37  INFJ          37  As a 5w4 I'm still figuring this all out, but ...   \n",
       "38  INTP          38  Last time that happened to me I wrongfully fla...   \n",
       "39  INTP          39  Double check all of your cables especially you...   \n",
       "40  INTP          40                                           Fuck you   \n",
       "41  ISTP          41  He promised to fuck the climate in his campaig...   \n",
       "42  INTJ          42  Yea, that was my main thing about this tbh, wh...   \n",
       "43  ENTP          43  The prospect of a wedding and the fact that ev...   \n",
       "44  INFP          44  To be fair, voting a \"straight Republican tick...   \n",
       "45  ENTP          45  I think he isn't cannon. He's from some extend...   \n",
       "46  INTP          46              It all depends on how you look at it.   \n",
       "47  INFJ          47  I can't believe I had to get this far down to ...   \n",
       "48  INTJ          48  Since some responses just list people, I'll fo...   \n",
       "49  INFP          49        The call of midnight by future world music.   \n",
       "\n",
       "                                                flair  index  \\\n",
       "0                            INFP: The Dreamer Senpai    NaN   \n",
       "1                                  INTP: The Theorist    NaN   \n",
       "2                                   INFP: The Dreamer    NaN   \n",
       "3      ENTP: Antisocial Extrovert, Rational Eccentric    NaN   \n",
       "4                    INTP/18/m/blankly staring at you    NaN   \n",
       "5                                  INTP: The Theorist    NaN   \n",
       "6                                       The INFJ Dude    NaN   \n",
       "7                            Honorary INFP; INTP/21/F    NaN   \n",
       "8                       intp or something of the sort    NaN   \n",
       "9                                           INTP/23/F    NaN   \n",
       "10                              INTP-P-P-P-Poker face    NaN   \n",
       "11                                  INFP: The Dreamer    NaN   \n",
       "12                                        INFJ (Male)    NaN   \n",
       "13                                          ENTP 26 M    NaN   \n",
       "14                                  INFP: The Dreamer    NaN   \n",
       "15                                 INTP: The Theorist    NaN   \n",
       "16                                              INTJ♂    NaN   \n",
       "17                           INFP Bitches be bitchin'    NaN   \n",
       "18                          ISTJ | literally your dad    NaN   \n",
       "19                                 ENTP: The Explorer    NaN   \n",
       "20  Some Rando ENTP that took a wrong turn at Albu...    NaN   \n",
       "21                   ENTP, Sx 5. Twentysomething male    NaN   \n",
       "22                                  INFP: The Dreamer    NaN   \n",
       "23                                              INTJ♂    NaN   \n",
       "24                                          INFJ-35-M    NaN   \n",
       "25                                 INTP: The Theorist    NaN   \n",
       "26                     25F INFJ | Partner to 24M INTJ    NaN   \n",
       "27                                           INTP SPY    NaN   \n",
       "28                                            ENTP-xD    NaN   \n",
       "29                                  INFP: The Dreamer    NaN   \n",
       "30                             INTP (depressed ENTP?)    NaN   \n",
       "31                                           INTP 5w4    NaN   \n",
       "32                               INTJ: The Mastermind    NaN   \n",
       "33                                           INFJ 20m    NaN   \n",
       "34                                     41 F, ENTP 7w6    NaN   \n",
       "35                                          INFJ - Ni    NaN   \n",
       "36                                              INTP♂    NaN   \n",
       "37                                             [INFJ]    NaN   \n",
       "38                                 INTP: The Theorist    NaN   \n",
       "39                                          INTP/INTJ    NaN   \n",
       "40                                              INTP♀    NaN   \n",
       "41                               ISTP, fuck enneagram    NaN   \n",
       "42                                             [INTJ]    NaN   \n",
       "43                                              ENTP♂    NaN   \n",
       "44                                  INFP: The Dreamer    NaN   \n",
       "45                              24M ENTP 5w4 Sp sx so    NaN   \n",
       "46                                             [INTP]    NaN   \n",
       "47                                         INFJ SX/SO    NaN   \n",
       "48                                              INTJ♂    NaN   \n",
       "49                               INFP: The Star-Gazer    NaN   \n",
       "\n",
       "              subreddit            username  \n",
       "0                  entp      LadyBanterbury  \n",
       "1                  INTP             Finarin  \n",
       "2                   WTF           xanplease  \n",
       "3          youtubehaiku     HeirToGallifrey  \n",
       "4                  entp           lightfive  \n",
       "5   InternetIsBeautiful    ElementalVoltage  \n",
       "6           Philippines           BabyFlo70  \n",
       "7                tumblr   RockinSocksReborn  \n",
       "8              woof_irl           crowbird_  \n",
       "9                  RWBY   RockinSocksReborn  \n",
       "10                funny            codepoet  \n",
       "11            AskReddit      rabidhamster87  \n",
       "12                  nes        SapphireDrew  \n",
       "13                Drugs  patternsofpatterns  \n",
       "14             politics         francis2559  \n",
       "15               france           ScalSaver  \n",
       "16              Megaten          bunker_man  \n",
       "17            childfree     I-ate-your-pony  \n",
       "18                 entp          lightseven  \n",
       "19            reddevils          knoxisback  \n",
       "20     TooMeIrlForMeIrl          -BlitzN9ne  \n",
       "21          CFBOffTopic      hammersklavier  \n",
       "22      britishproblems   TorbjornOskarsson  \n",
       "23              Megaten          bunker_man  \n",
       "24            westworld      Squeezycakes17  \n",
       "25            AskReddit             indil47  \n",
       "26          teslamotors          Killerzeit  \n",
       "27                 cars       Uncle_Skeeter  \n",
       "28               forsen       Andrescarmona  \n",
       "29    oldpeoplefacebook       xthebirdhouse  \n",
       "30                 INTP        owlsymbolism  \n",
       "31               france           Mr_Canard  \n",
       "32                 intj        DannyDJaxson  \n",
       "33                 entp         RASK0LN1K0V  \n",
       "34          secretsanta            cyronius  \n",
       "35            Overwatch      AndrogynousAve  \n",
       "36          whowouldwin          polaristar  \n",
       "37            Enneagram       LithiumEnergy  \n",
       "38             buildapc   OppaiGaKawaiiDesu  \n",
       "39          techsupport          2_4_16_256  \n",
       "40    theydidthefuckyou               pemGi  \n",
       "41             startrek              gerusz  \n",
       "42         orangecounty           Spore2012  \n",
       "43                 mbti             Aurarus  \n",
       "44             politics        DuplexFields  \n",
       "45              outside           ScalSaver  \n",
       "46              science               Jimmy  \n",
       "47               videos              Lamzn6  \n",
       "48     AsianMasculinity   DoktorLuciferWong  \n",
       "49            AskReddit              MrRyyi  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(n=50) # I forgot to set index_col here, have to clean the index mess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:42:03.653970Z",
     "start_time": "2019-12-02T00:41:57.318735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI             3289\n",
       "Unnamed: 0          0\n",
       "comments            0\n",
       "flair               0\n",
       "index         1555087\n",
       "subreddit           0\n",
       "username            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:42:06.316137Z",
     "start_time": "2019-12-02T00:42:03.667065Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop 2 duplicated index column \n",
    "df_new = df_new.drop(['index','Unnamed: 0'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:42:08.496993Z",
     "start_time": "2019-12-02T00:42:06.352413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI         3289\n",
       "comments        0\n",
       "flair           0\n",
       "subreddit       0\n",
       "username        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values again.\n",
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:42:12.019723Z",
     "start_time": "2019-12-02T00:42:08.501673Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the rows with null body text \n",
    "df_clean = df_new.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:42:13.762429Z",
     "start_time": "2019-12-02T00:42:12.025600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI         0\n",
       "comments     0\n",
       "flair        0\n",
       "subreddit    0\n",
       "username     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:43:40.023334Z",
     "start_time": "2019-12-02T00:42:13.806275Z"
    }
   },
   "outputs": [],
   "source": [
    "# save df to a csv for later use\n",
    "df_clean.to_csv('df_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:43:40.793060Z",
     "start_time": "2019-12-02T00:43:40.030930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    312220\n",
       "INTP    301236\n",
       "INFJ    271994\n",
       "ENTJ    257355\n",
       "ISTP    226154\n",
       "ENTP    224612\n",
       "ENFP    206537\n",
       "ENFJ    182589\n",
       "INTJ    176802\n",
       "ESTP    161173\n",
       "ISFJ    157556\n",
       "ISTJ    155944\n",
       "ISFP    142215\n",
       "ESTJ     96501\n",
       "ESFP     67022\n",
       "ESFJ     60872\n",
       "Name: MBTI, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['MBTI'].value_counts() # final dataframe value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:43:44.272266Z",
     "start_time": "2019-12-02T00:43:40.804136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comments Counts by Personality Types')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.countplot(data=df_clean, x='MBTI', order = df_clean['MBTI'].value_counts().index)\n",
    "plt.xlabel('personality types')\n",
    "plt.ylabel('counts')\n",
    "plt.title('Comments Counts by Personality Types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:43:48.824279Z",
     "start_time": "2019-12-02T00:43:44.284615Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the comments length of each comment\n",
    "df_clean['comments length'] = df_clean['comments'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T23:32:42.843216Z",
     "start_time": "2019-12-01T23:32:42.422745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MBTI</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ESFJ</td>\n",
       "      <td>282.256160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ISTP</td>\n",
       "      <td>261.368930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ESTJ</td>\n",
       "      <td>248.995741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INTJ</td>\n",
       "      <td>245.320098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ISFP</td>\n",
       "      <td>245.061442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INFJ</td>\n",
       "      <td>234.872556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ENFJ</td>\n",
       "      <td>226.650664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ENTP</td>\n",
       "      <td>221.916367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ISFJ</td>\n",
       "      <td>221.864689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ISTJ</td>\n",
       "      <td>219.284897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ENTJ</td>\n",
       "      <td>216.265225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INTP</td>\n",
       "      <td>211.356448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ENFP</td>\n",
       "      <td>209.020263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INFP</td>\n",
       "      <td>199.533127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ESTP</td>\n",
       "      <td>187.690041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ESFP</td>\n",
       "      <td>184.487303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      comments length\n",
       "MBTI                 \n",
       "ESFJ       282.256160\n",
       "ISTP       261.368930\n",
       "ESTJ       248.995741\n",
       "INTJ       245.320098\n",
       "ISFP       245.061442\n",
       "INFJ       234.872556\n",
       "ENFJ       226.650664\n",
       "ENTP       221.916367\n",
       "ISFJ       221.864689\n",
       "ISTJ       219.284897\n",
       "ENTJ       216.265225\n",
       "INTP       211.356448\n",
       "ENFP       209.020263\n",
       "INFP       199.533127\n",
       "ESTP       187.690041\n",
       "ESFP       184.487303"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the avg length of the comments and sort from longest to shortest\n",
    "df_avglength = pd.DataFrame(df_clean.groupby(['MBTI'])['comments length'].mean())\n",
    "df_avglength = df_avglength.sort_values(['comments length'], ascending=False)\n",
    "df_avglength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T23:32:45.583413Z",
     "start_time": "2019-12-01T23:32:45.112288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise the comments length in bar graph\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot()\n",
    "plt.barh(df_avglength.index,df_avglength['comments length'])\n",
    "plt.xlabel('Average Comment Length')\n",
    "plt.ylabel('MBTI')\n",
    "for i, v in enumerate(df_avglength['comments length']):\n",
    "    ax.text(v-21, i - 0.1, f'{v:.3f}', color='white', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Redundant Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:44:01.858743Z",
     "start_time": "2019-12-02T00:44:01.689306Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the redundant columns \n",
    "df_clean_comments = df_clean.drop(['flair','subreddit','username','comments length'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:45:05.280888Z",
     "start_time": "2019-12-02T00:44:04.263225Z"
    }
   },
   "outputs": [],
   "source": [
    "# save it as new csv to be used later\n",
    "df_clean_comments.to_csv('comments_mbti.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:46:07.338622Z",
     "start_time": "2019-12-02T00:46:07.330904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000782, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:48:43.987030Z",
     "start_time": "2019-12-02T00:48:43.977396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI        object\n",
       "comments    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_comments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:13:56.463580Z",
     "start_time": "2019-12-02T01:13:56.458047Z"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk packages: stopwords, stemmer and tokenizer\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:49:46.864779Z",
     "start_time": "2019-12-02T00:49:46.654309Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Doylism/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:49:58.410381Z",
     "start_time": "2019-12-02T00:49:58.405283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T00:50:13.049389Z",
     "start_time": "2019-12-02T00:50:13.039446Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate a random sample df to test functions** \n",
    "\n",
    "Due to the size of the data, I usually generate a random sample df to test functions before applying it onto the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:55:05.758000Z",
     "start_time": "2019-12-02T01:55:05.343850Z"
    }
   },
   "outputs": [],
   "source": [
    "# subset a small amount of data to test the function \n",
    "df_test = df_clean_comments.sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:21:11.373751Z",
     "start_time": "2019-12-02T01:21:11.366683Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert comments to lower strings\n",
    "df_test['comments'] = df_test['comments'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:21:13.226632Z",
     "start_time": "2019-12-02T01:21:13.217420Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove numbers \n",
    "import re \n",
    "df_test['comments'] = df_test['comments'].apply(lambda x: re.sub(r'\\d+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:21:18.485109Z",
     "start_time": "2019-12-02T01:21:18.478891Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove punctuations \n",
    "def remove_punc(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:21:20.457853Z",
     "start_time": "2019-12-02T01:21:20.448371Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove punctuation \n",
    "df_test['comments'] = df_test['comments'].apply(lambda x: remove_punc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:21:24.081717Z",
     "start_time": "2019-12-02T01:21:24.061162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20945</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>heh heh dont worry im sure everyone will be re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>593841</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>like the others have been suggesting in this t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176580</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>i was reading a great collection of poe storie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173917</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>if you insist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1447863</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ah so thats what happened to my schools audito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59903</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>i just apologize after that it is a bad habit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94820</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ive been really interested in glitchy reality ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335732</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>and d sounds a lot more like te than ti so get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1222128</td>\n",
       "      <td>INFP</td>\n",
       "      <td>oh yeah all my color normal friends are strugg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65192</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ignorance is bliss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MBTI                                           comments\n",
       "20945    ISFP  heh heh dont worry im sure everyone will be re...\n",
       "593841   INFJ  like the others have been suggesting in this t...\n",
       "176580   ISTP  i was reading a great collection of poe storie...\n",
       "173917   ENFP                                      if you insist\n",
       "1447863  ENTJ  ah so thats what happened to my schools audito...\n",
       "...       ...                                                ...\n",
       "59903    ISFP  i just apologize after that it is a bad habit ...\n",
       "94820    ESTP  ive been really interested in glitchy reality ...\n",
       "1335732  INTJ  and d sounds a lot more like te than ti so get...\n",
       "1222128  INFP  oh yeah all my color normal friends are strugg...\n",
       "65192    ISTP                                 ignorance is bliss\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the output in sample set \n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:21:27.058292Z",
     "start_time": "2019-12-02T01:21:27.051965Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stop(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    text = [i for i in tokens if not i in stop_words]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:21:29.518457Z",
     "start_time": "2019-12-02T01:21:29.446963Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "df_test['comments'] = df_test['comments'].apply(lambda x: remove_stop(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:21:32.116482Z",
     "start_time": "2019-12-02T01:21:32.087131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20945</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>[heh, heh, dont, worry, im, sure, everyone, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>593841</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>[like, others, suggesting, thread, knowing, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176580</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>[reading, great, collection, poe, stories, rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173917</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>[insist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1447863</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>[ah, thats, happened, schools, auditorium, uth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59903</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>[apologize, bad, habit, mine, anal, random, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94820</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>[ive, really, interested, glitchy, reality, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335732</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>[sounds, lot, like, te, ti, get, way, peasants]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1222128</td>\n",
       "      <td>INFP</td>\n",
       "      <td>[oh, yeah, color, normal, friends, struggling,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65192</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>[ignorance, bliss]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MBTI                                           comments\n",
       "20945    ISFP  [heh, heh, dont, worry, im, sure, everyone, re...\n",
       "593841   INFJ  [like, others, suggesting, thread, knowing, fi...\n",
       "176580   ISTP  [reading, great, collection, poe, stories, rec...\n",
       "173917   ENFP                                           [insist]\n",
       "1447863  ENTJ  [ah, thats, happened, schools, auditorium, uth...\n",
       "...       ...                                                ...\n",
       "59903    ISFP  [apologize, bad, habit, mine, anal, random, fa...\n",
       "94820    ESTP  [ive, really, interested, glitchy, reality, st...\n",
       "1335732  INTJ    [sounds, lot, like, te, ti, get, way, peasants]\n",
       "1222128  INFP  [oh, yeah, color, normal, friends, struggling,...\n",
       "65192    ISTP                                 [ignorance, bliss]\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out sample set \n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A combined function \n",
    "\n",
    "Based on the test on the sample set, I combined the steps to 2 functions, and then apply it to the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:54:56.038741Z",
     "start_time": "2019-12-02T01:54:56.028389Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove punctuations \n",
    "def remove_punc(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "# everything else \n",
    "def preprocess(text):\n",
    "    # convert to lower case\n",
    "    text = text.lower()\n",
    "    # remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # remove stop words\n",
    "    text = ' '.join(word for word in text.split() if not word in stop_words)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:55:12.641223Z",
     "start_time": "2019-12-02T01:55:12.632124Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['comments'] = df_test['comments'].apply(lambda x: remove_punc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:55:14.589158Z",
     "start_time": "2019-12-02T01:55:14.566688Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['comments'] = df_test['comments'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:55:16.708555Z",
     "start_time": "2019-12-02T01:55:16.689121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20945</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>heh heh dont worry im sure everyone really imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>593841</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>like others suggesting thread knowing first si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176580</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>reading great collection poe stories recently ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173917</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>insist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1447863</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ah thats happened schools auditorium utheeman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59903</td>\n",
       "      <td>ISFP</td>\n",
       "      <td>apologize bad habit mine anal random facts num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94820</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>ive really interested glitchy reality stuff la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1335732</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>sounds lot like te ti get way peasants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1222128</td>\n",
       "      <td>INFP</td>\n",
       "      <td>oh yeah color normal friends struggling dark s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65192</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>ignorance bliss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MBTI                                           comments\n",
       "20945    ISFP  heh heh dont worry im sure everyone really imp...\n",
       "593841   INFJ  like others suggesting thread knowing first si...\n",
       "176580   ISTP  reading great collection poe stories recently ...\n",
       "173917   ENFP                                             insist\n",
       "1447863  ENTJ      ah thats happened schools auditorium utheeman\n",
       "...       ...                                                ...\n",
       "59903    ISFP  apologize bad habit mine anal random facts num...\n",
       "94820    ESTP  ive really interested glitchy reality stuff la...\n",
       "1335732  INTJ             sounds lot like te ti get way peasants\n",
       "1222128  INFP  oh yeah color normal friends struggling dark s...\n",
       "65192    ISTP                                    ignorance bliss\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T01:58:21.378457Z",
     "start_time": "2019-12-02T01:56:44.948254Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean_comments['comments'] = df_clean_comments['comments'].apply(lambda x: remove_punc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T02:09:45.356865Z",
     "start_time": "2019-12-02T01:58:21.417501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INFP</td>\n",
       "      <td>lol thats left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INTP</td>\n",
       "      <td>post try telling people time im always joking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFP</td>\n",
       "      <td>first thought pepsi something probably alcohol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>formula something like every time says add bpm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INTP</td>\n",
       "      <td>imply im five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MBTI                                           comments\n",
       "0  INFP                                     lol thats left\n",
       "1  INTP  post try telling people time im always joking ...\n",
       "2  INFP     first thought pepsi something probably alcohol\n",
       "3  ENTP  formula something like every time says add bpm...\n",
       "4  INTP                                      imply im five"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_comments['comments'] = df_clean_comments['comments'].apply(lambda x: preprocess(x))\n",
    "df_clean_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T02:17:05.999142Z",
     "start_time": "2019-12-02T02:16:50.617938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61310757"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_comments['comments'].apply(lambda x: len(x.split(' '))).sum()\n",
    "# 61 millions words!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:09:21.268102Z",
     "start_time": "2019-12-03T05:09:20.797571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI            0\n",
       "comments    23971\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_comments.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:16:33.121165Z",
     "start_time": "2019-12-03T05:16:32.407790Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the null values\n",
    "df_clean_comments = df_clean_comments.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:16:44.350871Z",
     "start_time": "2019-12-03T05:16:43.878347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI        0\n",
       "comments    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_comments.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:16:51.212977Z",
     "start_time": "2019-12-03T05:16:51.206414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2976811, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_comments.shape\n",
    "# now we are left with 2.97 million of comments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Simple Models\n",
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T02:20:37.921417Z",
     "start_time": "2019-12-02T02:20:35.453378Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_clean_comments['comments']\n",
    "y = df_clean_comments['MBTI']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:24:35.417839Z",
     "start_time": "2019-12-02T03:24:35.409902Z"
    }
   },
   "outputs": [],
   "source": [
    "mbti = ['INFP','INFJ','INTP','INTJ','ENTP','ENFP','ISTP','ISFP','ENTJ','ISTJ','ENFJ','ISFJ','ESTP','ESFP','ESFJ','ESTJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T02:28:51.453491Z",
     "start_time": "2019-12-02T02:25:26.383279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# build a pipeline for tfidf and clasify the data \n",
    "my_nb = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "my_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:27:03.673156Z",
     "start_time": "2019-12-02T03:24:39.147930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.169956733519581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFP       0.56      0.06      0.11     54722\n",
      "        INFJ       0.45      0.04      0.07     61954\n",
      "        INTP       0.24      0.14      0.18     77590\n",
      "        INTJ       0.35      0.06      0.10     67486\n",
      "        ENTP       0.95      0.01      0.02     18218\n",
      "        ENFP       0.78      0.01      0.01     19938\n",
      "        ISTP       0.76      0.03      0.05     28912\n",
      "        ISFP       0.63      0.09      0.15     48281\n",
      "        ENTJ       0.17      0.22      0.19     81229\n",
      "        ISTJ       0.13      0.58      0.21     93610\n",
      "        ENFJ       0.55      0.02      0.05     53255\n",
      "        ISFJ       0.14      0.40      0.21     90431\n",
      "        ESTP       0.62      0.05      0.09     47188\n",
      "        ESFP       0.72      0.07      0.14     42873\n",
      "        ESFJ       0.60      0.03      0.05     46841\n",
      "        ESTJ       0.45      0.17      0.25     67707\n",
      "\n",
      "   micro avg       0.17      0.17      0.17    900235\n",
      "   macro avg       0.51      0.12      0.12    900235\n",
      "weighted avg       0.41      0.17      0.14    900235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = my_nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % my_nb.score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that because of the imbalance of the data, the precision/recall are highly imbalanced, resulting in low f1-scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:38:47.083686Z",
     "start_time": "2019-12-02T03:32:40.755540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...dom_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SGDClassifier(loss='hinge', penalty='l2', \\\n",
    "                                random_state=42, max_iter=5, tol=None))\n",
    "])\n",
    "\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T03:41:29.356483Z",
     "start_time": "2019-12-02T03:38:47.649520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.18061172915960833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFP       0.18      0.23      0.20     54722\n",
      "        INFJ       0.17      0.14      0.15     61954\n",
      "        INTP       0.18      0.18      0.18     77590\n",
      "        INTJ       0.16      0.15      0.16     67486\n",
      "        ENTP       0.25      0.18      0.21     18218\n",
      "        ENFP       0.23      0.22      0.22     19938\n",
      "        ISTP       0.28      0.30      0.29     28912\n",
      "        ISFP       0.22      0.28      0.25     48281\n",
      "        ENTJ       0.16      0.18      0.17     81229\n",
      "        ISTJ       0.17      0.13      0.15     93610\n",
      "        ENFJ       0.15      0.12      0.13     53255\n",
      "        ISFJ       0.16      0.16      0.16     90431\n",
      "        ESTP       0.18      0.20      0.19     47188\n",
      "        ESFP       0.27      0.24      0.25     42873\n",
      "        ESFJ       0.17      0.18      0.17     46841\n",
      "        ESTJ       0.28      0.27      0.28     67707\n",
      "\n",
      "   micro avg       0.19      0.19      0.19    900235\n",
      "   macro avg       0.20      0.20      0.20    900235\n",
      "weighted avg       0.19      0.19      0.19    900235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % sgd.score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD Classifier performs a little better than Naive Bayes, but we still want to find out about other classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:48:09.390314Z",
     "start_time": "2019-12-02T03:45:55.674542Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-3e29c60f98be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ])\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmy_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "my_logit = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', LogisticRegression(solver='saga'))\n",
    "])\n",
    "my_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T04:48:09.485530Z",
     "start_time": "2019-12-02T03:46:23.266Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = my_logit.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % my_logit.score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression result is keyboard interrupted because it's taking some time to process, and at this point, I was researching into SpaCy and decided to use SpaCy to reprocess the text and then fit in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy Text Processing\n",
    "\n",
    "To use SpaCy, I re-imported a version of the dataset before it's processed using NLTK. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:45:44.658600Z",
     "start_time": "2019-12-06T16:45:31.242928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# import data \n",
    "df_punc = pd.read_csv('../../clean_data/with_punc.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T18:43:36.440096Z",
     "start_time": "2019-12-06T18:43:36.235724Z"
    }
   },
   "outputs": [],
   "source": [
    "# as I did before, I created a sample set from the complete set to test the functions. \n",
    "df_sample = df_punc.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:45:52.898209Z",
     "start_time": "2019-12-06T16:45:52.874607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1533251</td>\n",
       "      <td>INFP</td>\n",
       "      <td>Also, this is availble on jailbroken iPhones a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489172</td>\n",
       "      <td>INFP</td>\n",
       "      <td>Damn spices eating all my jeans!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1434585</td>\n",
       "      <td>INFP</td>\n",
       "      <td>When my friend first showed me a picture of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>979964</td>\n",
       "      <td>INFP</td>\n",
       "      <td>Lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50650</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>I have impressed the guy who taught me not to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1265</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>Asian American History: Movement and Dislocati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122703</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>I'm not saying that all media is bad all of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1101969</td>\n",
       "      <td>INTP</td>\n",
       "      <td>Carthage. Spam cities and pick up that +2 Scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61720</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>Redditors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305117</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>So other than just get the Trump administratio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MBTI                                           comments\n",
       "1533251  INFP  Also, this is availble on jailbroken iPhones a...\n",
       "489172   INFP                   Damn spices eating all my jeans!\n",
       "1434585  INFP  When my friend first showed me a picture of th...\n",
       "979964   INFP                                             Lovely\n",
       "50650    ENFJ  I have impressed the guy who taught me not to ...\n",
       "...       ...                                                ...\n",
       "1265     ESTP  Asian American History: Movement and Dislocati...\n",
       "122703   ENTJ  I'm not saying that all media is bad all of th...\n",
       "1101969  INTP  Carthage. Spam cities and pick up that +2 Scie...\n",
       "61720    ESTJ                                          Redditors\n",
       "1305117  ENTP  So other than just get the Trump administratio...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T06:32:35.838231Z",
     "start_time": "2019-12-04T06:32:35.290292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI        0\n",
       "comments    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "df_punc.isna().sum()\n",
    "\n",
    "# good there is no null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T06:33:19.730814Z",
     "start_time": "2019-12-04T06:33:19.726761Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_punc.comments\n",
    "y = df_punc.MBTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T06:33:23.286153Z",
     "start_time": "2019-12-04T06:33:22.026152Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing in SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:46:04.099722Z",
     "start_time": "2019-12-06T16:46:01.690779Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# function to return tokens that are not punctuation, space, \n",
    "# stop-words, url, emails and are longer than 2 letters.\n",
    "def token_filter(token):\n",
    "    return not (token.is_punct | token.is_space | token.is_stop | len(token.text) <= 2 | token.like_email | token.like_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T19:47:17.013562Z",
     "start_time": "2019-12-06T19:47:17.002825Z"
    }
   },
   "outputs": [],
   "source": [
    "# function for text processing \n",
    "def clean_text(docs): \n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for doc in nlp.pipe(docs):\n",
    "        # lemmatisation \n",
    "        tokens = [token.lemma_ for token in doc if token_filter(token) ]\n",
    "        # lower case\n",
    "        tokens = [word.lower() for word in tokens]\n",
    "        # delete all the lemmatised pronoun placeholder\n",
    "        tokens = [word for word in tokens if word != '-pron-']\n",
    "        # remove urls \n",
    "        tokens = [re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', 'url', word) for word in tokens]\n",
    "        # keep only words\n",
    "        tokens = [re.sub(\"[^a-zA-Z]\", \" \", word) for word in tokens]\n",
    "        # remove extra white spaces\n",
    "        tokens = [re.sub(' +', ' ', word) for word in tokens]\n",
    "        filtered_tokens.append(tokens)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try on the sample set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T19:44:39.789293Z",
     "start_time": "2019-12-06T19:44:28.022198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118e64b1047b43c493c81b28497a74b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample['text_lemma'] = clean_text(df_sample['comments'])\n",
    "df_sample['text_lemma'] = df_sample['text_lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T18:45:08.018255Z",
     "start_time": "2019-12-06T18:45:07.986457Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>787840</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>It's not quite that simple. The \"test taking\" environment is completely different to day-to-day stuff. Dead silence, no referencing/quick checks which I do constantly (to reaffirm my knowledge), the stress of trying to get a good grade, being tested on the spot, having a time limit, etc. It impairs (at least my) ability to remember things.  But just get me out of the blue when I'm completely relaxed and there's no stress or anything? Sure, I could easily tell you.  Also, the questions on exams are usually different than how you'd usually use the knowledge as well as different from how you learned it.  Also, some people are just shit at thoroughly making sure that the knowledge is down on paper. Sometimes you forget to mention something that the other person would simply just follow up on and ask about, which you'd then respond. On a test, that doesn't happen, you just get points knocked off.</td>\n",
       "      <td>be not quite that simple the test take environment be completely different to day to day stuff dead silence no referencing quick check which do constantly to reaffirm knowledge the stress of try to get good grade be test on the spot have time limit etc impair at least ability to remember thing but just get out of the blue when be completely relaxed and there be no stress or anything sure could easily tell also the question on exam be usually different than how would usually use the knowledge as well as different from how learn also some people be just shit at thoroughly make sure that the knowledge be down on paper sometimes forget to mention something that the other person would simply just follow up on and ask about which would then respond on test that do not happen just get point knock off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46144</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>For those who haven't been in touch with the game for long or very closely (including the creator of this video I assume), in the past we have had multiple news agencies blow up at Arma 3 for being an \"ISIS training simulator\" because of a mod that added ISIS units. Don't let this happen again. Please remove this for the sake of the game.</td>\n",
       "      <td>for those who have not be in touch with the game for long or very closely include the creator of this video assume in the past have have multiple news agency blow up at arma for be an isis training simulator because of mod that add isis unit do not let this happen again please remove this for the sake of the game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321942</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>The fat toothless kid from *Stranger Things*.    He seems to be the only one of the kids who has a grasp of the bigger picture.  He starts off as more  of a sidekick until the other two kids start to lose it, then he steps from out of the shadows, smacks them around until they see sense, and gets everything back on track.</td>\n",
       "      <td>the fat toothless kid from stranger things    seem to be the only one of the kid who have grasp of the big picture start off as more of sidekick until the other two kid start to lose then step from out of the shadow smack around until see sense and get everything back on track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123281</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>I wasn't allowed to wear nail polish, get natural-colored highlights, wear makeup (even to cover a zit), or have any piercing besides one normal-sized love at my school.</td>\n",
       "      <td>be not allow to wear nail polish get natural color highlight wear makeup even to cover zit or have any piercing besides one normal sized love at school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263516</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>She's been off the grid for what...like a month? Two months? No one in the fandom knows where she is or what she's doing right now. It doesn't surprise me that she didn't go and I'm not sure why everyone is so upset about it. I feel like if she did go, it would have been all over the news (because the media is obsessed with her), then people would be saying \"Ugh, why is Taylor Swift making the women's march all about her?\" Girl can't win.  Not to mention the fact that she has all kinds of psychos who stalk her and doesn't go anywhere without security...all that plus the paparazzi would have created a huge spectacle and detracted from the importance of the march.  Beyonce uses feminism to promote her brand way more than Taylor does, and no one's salty about her not going. I'll never understand why people have such a stick up their ass about Taylor.</td>\n",
       "      <td>be be off the grid for what   like month two month no one in the fandom know where be or what be do right now do not surprise that do not go and be not sure why everyone be so upset about feel like if did go would have be all over the news because the medium be obsess with then people would be say ugh why be taylor swift make the woman  s march all about girl can not win not to mention the fact that have all kind of psychos who stalk and do not go anywhere without security   all that plus the paparazzi would have create huge spectacle and detract from the importance of the march beyonce use feminism to promote brand way more than taylor do and no one  s salty about not go will never understand why people have such stick up ass about taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>689063</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>This isn't about respect this is about ending suffering, hatred has never in all of human history conquered hate and until we decide to tackle the problems at their roots instead of dehumanizing people hate will never end.</td>\n",
       "      <td>this be not about respect this be about end suffering hatred have never in all of human history conquer hate and until decide to tackle the problem at root instead of dehumanize people hate will never end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288663</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>I can help you out personally :) I know a lot about python and have even made a bot in python (/u/dogetipchecker). PM me if you are interested, and I can recommend some books and also answer specific questions about python. I can give you my skype number, and we can chat with skype too if you are OK with that.</td>\n",
       "      <td>can help out personally   know lot about python and have even make bot in python dogetipchecker if be interested and can recommend some book and also answer specific question about python can give skype number and can chat with skype too if be with that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996000</td>\n",
       "      <td>INFP</td>\n",
       "      <td>TIL that the fires of Hell are blue! O_O</td>\n",
       "      <td>til that the fire of hell be blue o o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20057</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>Doesn't spoofing require kernel? Hype?</td>\n",
       "      <td>do not spoof require kernel hype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1127354</td>\n",
       "      <td>INFP</td>\n",
       "      <td>&amp;gt;Trust me on the sunscreen.    Not the sunscreen song?</td>\n",
       "      <td>gt trust on the sunscreen   not the sunscreen song</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MBTI  \\\n",
       "787840   ISTP   \n",
       "46144    ISTJ   \n",
       "321942   ENTP   \n",
       "123281   ENFP   \n",
       "263516   ISFJ   \n",
       "...       ...   \n",
       "689063   ISTP   \n",
       "288663   ENTP   \n",
       "996000   INFP   \n",
       "20057    ISTP   \n",
       "1127354  INFP   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         comments  \\\n",
       "787840   It's not quite that simple. The \"test taking\" environment is completely different to day-to-day stuff. Dead silence, no referencing/quick checks which I do constantly (to reaffirm my knowledge), the stress of trying to get a good grade, being tested on the spot, having a time limit, etc. It impairs (at least my) ability to remember things.  But just get me out of the blue when I'm completely relaxed and there's no stress or anything? Sure, I could easily tell you.  Also, the questions on exams are usually different than how you'd usually use the knowledge as well as different from how you learned it.  Also, some people are just shit at thoroughly making sure that the knowledge is down on paper. Sometimes you forget to mention something that the other person would simply just follow up on and ask about, which you'd then respond. On a test, that doesn't happen, you just get points knocked off.   \n",
       "46144    For those who haven't been in touch with the game for long or very closely (including the creator of this video I assume), in the past we have had multiple news agencies blow up at Arma 3 for being an \"ISIS training simulator\" because of a mod that added ISIS units. Don't let this happen again. Please remove this for the sake of the game.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "321942   The fat toothless kid from *Stranger Things*.    He seems to be the only one of the kids who has a grasp of the bigger picture.  He starts off as more  of a sidekick until the other two kids start to lose it, then he steps from out of the shadows, smacks them around until they see sense, and gets everything back on track.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "123281   I wasn't allowed to wear nail polish, get natural-colored highlights, wear makeup (even to cover a zit), or have any piercing besides one normal-sized love at my school.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "263516   She's been off the grid for what...like a month? Two months? No one in the fandom knows where she is or what she's doing right now. It doesn't surprise me that she didn't go and I'm not sure why everyone is so upset about it. I feel like if she did go, it would have been all over the news (because the media is obsessed with her), then people would be saying \"Ugh, why is Taylor Swift making the women's march all about her?\" Girl can't win.  Not to mention the fact that she has all kinds of psychos who stalk her and doesn't go anywhere without security...all that plus the paparazzi would have created a huge spectacle and detracted from the importance of the march.  Beyonce uses feminism to promote her brand way more than Taylor does, and no one's salty about her not going. I'll never understand why people have such a stick up their ass about Taylor.                                                \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...                                            \n",
       "689063   This isn't about respect this is about ending suffering, hatred has never in all of human history conquered hate and until we decide to tackle the problems at their roots instead of dehumanizing people hate will never end.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "288663   I can help you out personally :) I know a lot about python and have even made a bot in python (/u/dogetipchecker). PM me if you are interested, and I can recommend some books and also answer specific questions about python. I can give you my skype number, and we can chat with skype too if you are OK with that.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "996000   TIL that the fires of Hell are blue! O_O                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "20057    Doesn't spoofing require kernel? Hype?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "1127354  &gt;Trust me on the sunscreen.    Not the sunscreen song?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text_lemma  \n",
       "787840   be not quite that simple the test take environment be completely different to day to day stuff dead silence no referencing quick check which do constantly to reaffirm knowledge the stress of try to get good grade be test on the spot have time limit etc impair at least ability to remember thing but just get out of the blue when be completely relaxed and there be no stress or anything sure could easily tell also the question on exam be usually different than how would usually use the knowledge as well as different from how learn also some people be just shit at thoroughly make sure that the knowledge be down on paper sometimes forget to mention something that the other person would simply just follow up on and ask about which would then respond on test that do not happen just get point knock off  \n",
       "46144    for those who have not be in touch with the game for long or very closely include the creator of this video assume in the past have have multiple news agency blow up at arma for be an isis training simulator because of mod that add isis unit do not let this happen again please remove this for the sake of the game                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "321942   the fat toothless kid from stranger things    seem to be the only one of the kid who have grasp of the big picture start off as more of sidekick until the other two kid start to lose then step from out of the shadow smack around until see sense and get everything back on track                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "123281   be not allow to wear nail polish get natural color highlight wear makeup even to cover zit or have any piercing besides one normal sized love at school                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "263516   be be off the grid for what   like month two month no one in the fandom know where be or what be do right now do not surprise that do not go and be not sure why everyone be so upset about feel like if did go would have be all over the news because the medium be obsess with then people would be say ugh why be taylor swift make the woman  s march all about girl can not win not to mention the fact that have all kind of psychos who stalk and do not go anywhere without security   all that plus the paparazzi would have create huge spectacle and detract from the importance of the march beyonce use feminism to promote brand way more than taylor do and no one  s salty about not go will never understand why people have such stick up ass about taylor                                                         \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...                                                       \n",
       "689063   this be not about respect this be about end suffering hatred have never in all of human history conquer hate and until decide to tackle the problem at root instead of dehumanize people hate will never end                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "288663   can help out personally   know lot about python and have even make bot in python dogetipchecker if be interested and can recommend some book and also answer specific question about python can give skype number and can chat with skype too if be with that                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "996000   til that the fire of hell be blue o o                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "20057    do not spoof require kernel hype                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "1127354  gt trust on the sunscreen   not the sunscreen song                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample\n",
    "#pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply on the complete set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the complete set \n",
    "df_punc['comments_lemma'] = clean_text(df_punc['comments'])\n",
    "df_punc['comments_lemma'] = df_punc['comments_lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_punc.to_csv('spacy_clean.csv') # cleaned data saved as checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above 2 commands were executed on AWS and a cleaned data file was generated in the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Bag of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:03:03.217134Z",
     "start_time": "2019-12-05T20:02:41.483264Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Load in the cleaned data into a dataframe\n",
    "df_clean = pd.read_csv('../../clean_data/spacy_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:03:03.243491Z",
     "start_time": "2019-12-05T20:03:03.222348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INFP</td>\n",
       "      <td>Lol that's why I left.</td>\n",
       "      <td>lol that be why leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INTP</td>\n",
       "      <td>I was just about to post \"I try telling people...</td>\n",
       "      <td>be just about to post try tell people all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFP</td>\n",
       "      <td>My first thought was Pepsi or something. Proba...</td>\n",
       "      <td>first thought be pepsi or something probably n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>Not if the formula is something like \"every ti...</td>\n",
       "      <td>not if the formula be something like every tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INTP</td>\n",
       "      <td>Does this imply I'm a five now?</td>\n",
       "      <td>do this imply be five now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MBTI                                           comments  \\\n",
       "0  INFP                            Lol that's why I left.    \n",
       "1  INTP  I was just about to post \"I try telling people...   \n",
       "2  INFP  My first thought was Pepsi or something. Proba...   \n",
       "3  ENTP  Not if the formula is something like \"every ti...   \n",
       "4  INTP                    Does this imply I'm a five now?   \n",
       "\n",
       "                                      comments_lemma  \n",
       "0                              lol that be why leave  \n",
       "1  be just about to post try tell people all the ...  \n",
       "2  first thought be pepsi or something probably n...  \n",
       "3  not if the formula be something like every tim...  \n",
       "4                          do this imply be five now  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:03:04.143479Z",
     "start_time": "2019-12-05T20:03:03.247791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI                  0\n",
       "comments              0\n",
       "comments_lemma    23125\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:03:05.426909Z",
     "start_time": "2019-12-05T20:03:04.150414Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean = df_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:07:33.957772Z",
     "start_time": "2019-12-05T20:07:16.918016Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove the digits and replace with white space \n",
    "pattern = '[0-9]'\n",
    "\n",
    "df_clean['comments_lemma'] = df_clean['comments_lemma'].apply(lambda x: re.sub(pattern,' ', x))\n",
    "\n",
    "# remove underscore \n",
    "df_clean['comments_lemma'] = df_clean['comments_lemma'].apply(lambda x: x.replace('_',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:12:11.754652Z",
     "start_time": "2019-12-05T20:12:03.902002Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the data \n",
    "X = df_clean['comments_lemma']\n",
    "y = df_clean['MBTI']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:15:56.679543Z",
     "start_time": "2019-12-05T20:12:16.094603Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "bagofwords = CountVectorizer(min_df=50, stop_words='english')\n",
    "bagofwords.fit(X_train)\n",
    "X_train_dtm = bagofwords.transform(X_train)\n",
    "X_test_dtm = bagofwords.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:15:56.695425Z",
     "start_time": "2019-12-05T20:15:56.682355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2084359, 23766)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:15:56.732754Z",
     "start_time": "2019-12-05T20:15:56.698935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaaaaand',\n",
       " 'aaaaand',\n",
       " 'aaaand',\n",
       " 'aaah',\n",
       " 'aaand',\n",
       " 'aac',\n",
       " 'aah',\n",
       " 'aan',\n",
       " 'aang',\n",
       " 'aaron',\n",
       " 'aaryn',\n",
       " 'aas',\n",
       " 'ab',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abandonment',\n",
       " 'abbey',\n",
       " 'abbott',\n",
       " 'abbreviate',\n",
       " 'abbreviation',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdoman',\n",
       " 'abdominal',\n",
       " 'abduct',\n",
       " 'abduction',\n",
       " 'abe',\n",
       " 'abed',\n",
       " 'abel',\n",
       " 'aber',\n",
       " 'aberration',\n",
       " 'abh',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abide',\n",
       " 'abilify',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'ableist',\n",
       " 'ableton',\n",
       " 'abnormal',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'aboard',\n",
       " 'abolish',\n",
       " 'abolition']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagofwords.get_feature_names()[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models & Grid Search \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:32:28.993420Z",
     "start_time": "2019-12-03T05:17:16.482354Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...penalty='l2', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_logit = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', LogisticRegression(solver='saga'))\n",
    "])\n",
    "my_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:32:29.021918Z",
     "start_time": "2019-12-03T05:18:09.666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.21202443081703978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFP       0.29      0.19      0.23     54111\n",
      "        INFJ       0.24      0.13      0.16     61347\n",
      "        INTP       0.19      0.22      0.21     76910\n",
      "        INTJ       0.22      0.15      0.17     67002\n",
      "        ENTP       0.32      0.16      0.21     18045\n",
      "        ENFP       0.39      0.14      0.20     20097\n",
      "        ISTP       0.40      0.24      0.30     28820\n",
      "        ISFP       0.31      0.23      0.26     47966\n",
      "        ENTJ       0.18      0.23      0.20     80672\n",
      "        ISTJ       0.15      0.30      0.20     93057\n",
      "        ENFJ       0.26      0.10      0.15     53023\n",
      "        ISFJ       0.16      0.29      0.20     89188\n",
      "        ESTP       0.30      0.15      0.20     47095\n",
      "        ESFP       0.38      0.21      0.27     42376\n",
      "        ESFJ       0.29      0.14      0.19     46437\n",
      "        ESTJ       0.26      0.32      0.29     67152\n",
      "\n",
      "   micro avg       0.21      0.21      0.21    893298\n",
      "   macro avg       0.27      0.20      0.22    893298\n",
      "weighted avg       0.24      0.21      0.21    893298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = my_logit.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % my_logit.score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are much better than before when we had the messier data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - n-gram\n",
    "\n",
    "Trying to use n-gram but my computer could not handle this, I will be use n-grams later directly in TFIDFVecotrizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:32:28.993420Z",
     "start_time": "2019-12-03T05:17:16.482354Z"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-194f3c55c957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saga'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ])\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmy_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    229\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1031\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0;31m# disable defaultdict behaviour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_logit = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=20, stop_words='english',ngram_range = (1,3))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', LogisticRegression(solver='saga'))\n",
    "])\n",
    "my_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:32:29.021918Z",
     "start_time": "2019-12-03T05:18:09.666Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = my_logit.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % my_logit.score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:36:28.717298Z",
     "start_time": "2019-12-03T05:34:38.108051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a pipeline for vectorise, transform and clasify the data \n",
    "my_nb = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "my_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:42:42.152448Z",
     "start_time": "2019-12-03T05:41:36.202828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.1685495769608798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFP       0.57      0.06      0.11     54111\n",
      "        INFJ       0.43      0.04      0.08     61347\n",
      "        INTP       0.23      0.14      0.17     76910\n",
      "        INTJ       0.36      0.05      0.09     67002\n",
      "        ENTP       0.90      0.01      0.01     18045\n",
      "        ENFP       0.74      0.01      0.01     20097\n",
      "        ISTP       0.73      0.03      0.05     28820\n",
      "        ISFP       0.58      0.08      0.14     47966\n",
      "        ENTJ       0.17      0.22      0.19     80672\n",
      "        ISTJ       0.13      0.56      0.21     93057\n",
      "        ENFJ       0.53      0.03      0.05     53023\n",
      "        ISFJ       0.14      0.42      0.21     89188\n",
      "        ESTP       0.59      0.04      0.08     47095\n",
      "        ESFP       0.69      0.07      0.13     42376\n",
      "        ESFJ       0.59      0.03      0.06     46437\n",
      "        ESTJ       0.43      0.16      0.24     67152\n",
      "\n",
      "   micro avg       0.17      0.17      0.17    893298\n",
      "   macro avg       0.49      0.12      0.11    893298\n",
      "weighted avg       0.40      0.17      0.14    893298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = my_nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % my_nb.score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:48:25.661298Z",
     "start_time": "2019-12-03T05:45:20.142531Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...dom_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SGDClassifier(loss='hinge', penalty='l2', \\\n",
    "                                random_state=42, max_iter=5, tol=None))\n",
    "])\n",
    "\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:49:29.582925Z",
     "start_time": "2019-12-03T05:48:25.664326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.1781633900445316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFP       0.18      0.22      0.20     54111\n",
      "        INFJ       0.18      0.12      0.14     61347\n",
      "        INTP       0.18      0.15      0.16     76910\n",
      "        INTJ       0.14      0.17      0.16     67002\n",
      "        ENTP       0.19      0.18      0.18     18045\n",
      "        ENFP       0.20      0.19      0.19     20097\n",
      "        ISTP       0.23      0.29      0.26     28820\n",
      "        ISFP       0.19      0.26      0.22     47966\n",
      "        ENTJ       0.15      0.16      0.16     80672\n",
      "        ISTJ       0.15      0.18      0.16     93057\n",
      "        ENFJ       0.16      0.11      0.13     53023\n",
      "        ISFJ       0.16      0.10      0.13     89188\n",
      "        ESTP       0.16      0.20      0.18     47095\n",
      "        ESFP       0.24      0.21      0.22     42376\n",
      "        ESFJ       0.20      0.14      0.16     46437\n",
      "        ESTJ       0.23      0.29      0.25     67152\n",
      "\n",
      "   micro avg       0.18      0.18      0.18    893298\n",
      "   macro avg       0.18      0.19      0.18    893298\n",
      "weighted avg       0.18      0.18      0.18    893298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % sgd.score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search \n",
    "\n",
    "Following the results from the above models, I decided to use Grid Search to test more models and find best parameters.\n",
    "\n",
    "Because of the size of the data, the computation, even on a high power AWS instance, it still took a long time, therefore I decided to use a sample set to find the parameters for best models and then fit to the complete set. I understand this might not be the best practice here, I would love to improve this in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try on a sample set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_clean.sample(n=2000)\n",
    "X_trial = df_test['comments_lemma']\n",
    "y_trial = df_test['MBTI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trial_train, X_trial_test, y_trial_train, y_trial_test = train_test_split(X_trial, y_trial, test_size=0.3, stratify=y_trial, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2904 candidates, totalling 14520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 421 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 493 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 530 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 569 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 608 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 649 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 733 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 821 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 913 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1058 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1109 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1160 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1213 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1266 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1321 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1376 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1433 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1490 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1549 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1608 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1669 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1730 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1793 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1856 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1921 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1986 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2053 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2120 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2189 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2258 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2329 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2400 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2473 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2546 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2621 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2696 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2773 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2850 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2929 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3008 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3089 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3170 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3253 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3336 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3421 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3506 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3593 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3680 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3769 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3858 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3949 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4040 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4133 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4226 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4321 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4416 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4513 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4610 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4709 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4808 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4909 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5010 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5113 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5216 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5321 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5426 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5533 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5640 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5749 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5858 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5969 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6080 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6193 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6306 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6421 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6536 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6653 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6770 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6889 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7008 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7129 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7250 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7373 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7496 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7621 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7746 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7873 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8000 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8129 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8258 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8389 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8520 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8653 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8786 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8921 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9056 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9193 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9330 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 9469 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 9608 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9749 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9890 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 10033 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 10176 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10321 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10466 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 10613 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10760 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 10909 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 11058 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11209 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 11360 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 11513 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 11666 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 11821 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 11976 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12133 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 12290 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 12449 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12608 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 12769 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 12930 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 13093 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 13256 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 13421 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 13586 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 13753 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 13920 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14089 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14258 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14520 out of 14520 | elapsed:  7.7min finished\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bestmodel.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([ ('vect', CountVectorizer()),('model', LogisticRegression())])\n",
    "\n",
    "param_grid = [\n",
    "    # Logistic Regression\n",
    "    {'vect':[TfidfVectorizer()], 'model':[LogisticRegression(solver='saga')],\n",
    "    'model__penalty':['l1','l2'], 'model__C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "     'vect__min_df':[50, 100, 300, 500], 'vect__smooth_idf': (True, False),\n",
    "     'vect__norm': ('l1', 'l2', None)},\n",
    "    \n",
    "    # Random Forest\n",
    "    {'vect':[TfidfVectorizer()], 'model':[RandomForestClassifier()],\n",
    "     'vect__min_df':[50, 100, 300, 500], \n",
    "     'model__n_estimators': [50, 100, 150, 200], 'model__max_depth':[2, 5, 10, 15, 20],\n",
    "     'vect__smooth_idf': (True, False), 'vect__norm': ('l1', 'l2', None)},\n",
    "    \n",
    "    # XG Boost\n",
    "    {'vect':[TfidfVectorizer()], 'model':[XGBClassifier()],\n",
    "     'vect__min_df':[50, 100, 300, 500], 'model__learning_rate': [0.1, 0.5, 1, 2],\n",
    "     'model__n_estimators': [50, 100, 150, 200], 'model__max_depth':[2, 5, 10, 15, 20],\n",
    "     'vect__smooth_idf': (True, False), 'vect__norm': ('l1', 'l2', None)},\n",
    "    \n",
    "    # SGD Classifier\n",
    "    {'vect':[TfidfVectorizer()], \n",
    "     'model':[SGDClassifier(n_iter=1000, loss='hinge',penalty='l2',random_state=42, max_iter=5, tol=None)],\n",
    "     'vect__min_df':[50, 100, 300, 500],'model__alpha': [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "     'vect__smooth_idf': (True, False), 'vect__norm': ('l1', 'l2', None)}\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, verbose=10, n_jobs=-1)\n",
    "fittedgrid = grid.fit(X_trial_train, y_trial_train)\n",
    "\n",
    "fittedgrid.score(X_trial_test, y_trial_test)\n",
    "\n",
    "# save the best model as a pkl\n",
    "joblib.dump(fittedgrid.best_estimator_, 'bestmodel.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=50,\n",
       "        ngram_range=(1, 1), norm='l1', preprocessor=None, smooth_idf=False...penalty='l2', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the parameters of the best model\n",
    "fittedgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the grid results into a dataframe\n",
    "grid_results = pd.concat([pd.DataFrame(fittedgrid.cv_results_[\"params\"]),pd.DataFrame(fittedgrid.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1).sort_values(by='Accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model__C</th>\n",
       "      <th>model__alpha</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__n_estimators</th>\n",
       "      <th>model__penalty</th>\n",
       "      <th>vect</th>\n",
       "      <th>vect__min_df</th>\n",
       "      <th>vect__norm</th>\n",
       "      <th>vect__smooth_idf</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>LogisticRegression(C=1, class_weight=None, dua...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.119286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>LogisticRegression(C=1, class_weight=None, dua...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.119286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.117143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.117143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>LogisticRegression(C=1, class_weight=None, dua...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.117143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>LogisticRegression(C=1, class_weight=None, dua...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.117143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.117143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>RandomForestClassifier(bootstrap=True, class_w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.115714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model  model__C  \\\n",
       "434  RandomForestClassifier(bootstrap=True, class_w...       NaN   \n",
       "169  LogisticRegression(C=1, class_weight=None, dua...       1.0   \n",
       "339  RandomForestClassifier(bootstrap=True, class_w...       NaN   \n",
       "168  LogisticRegression(C=1, class_weight=None, dua...       1.0   \n",
       "410  RandomForestClassifier(bootstrap=True, class_w...       NaN   \n",
       "362  RandomForestClassifier(bootstrap=True, class_w...       NaN   \n",
       "150  LogisticRegression(C=1, class_weight=None, dua...       1.0   \n",
       "151  LogisticRegression(C=1, class_weight=None, dua...       1.0   \n",
       "504  RandomForestClassifier(bootstrap=True, class_w...       NaN   \n",
       "483  RandomForestClassifier(bootstrap=True, class_w...       NaN   \n",
       "\n",
       "     model__alpha  model__learning_rate  model__max_depth  \\\n",
       "434           NaN                   NaN               5.0   \n",
       "169           NaN                   NaN               NaN   \n",
       "339           NaN                   NaN               2.0   \n",
       "168           NaN                   NaN               NaN   \n",
       "410           NaN                   NaN               2.0   \n",
       "362           NaN                   NaN               2.0   \n",
       "150           NaN                   NaN               NaN   \n",
       "151           NaN                   NaN               NaN   \n",
       "504           NaN                   NaN               5.0   \n",
       "483           NaN                   NaN               5.0   \n",
       "\n",
       "     model__n_estimators model__penalty  \\\n",
       "434                 50.0            NaN   \n",
       "169                  NaN             l2   \n",
       "339                 50.0            NaN   \n",
       "168                  NaN             l2   \n",
       "410                200.0            NaN   \n",
       "362                100.0            NaN   \n",
       "150                  NaN             l1   \n",
       "151                  NaN             l1   \n",
       "504                200.0            NaN   \n",
       "483                150.0            NaN   \n",
       "\n",
       "                                                  vect  vect__min_df  \\\n",
       "434  TfidfVectorizer(analyzer='word', binary=False,...            50   \n",
       "169  TfidfVectorizer(analyzer='word', binary=False,...            50   \n",
       "339  TfidfVectorizer(analyzer='word', binary=False,...            50   \n",
       "168  TfidfVectorizer(analyzer='word', binary=False,...            50   \n",
       "410  TfidfVectorizer(analyzer='word', binary=False,...            50   \n",
       "362  TfidfVectorizer(analyzer='word', binary=False,...            50   \n",
       "150  TfidfVectorizer(analyzer='word', binary=False,...           100   \n",
       "151  TfidfVectorizer(analyzer='word', binary=False,...           100   \n",
       "504  TfidfVectorizer(analyzer='word', binary=False,...            50   \n",
       "483  TfidfVectorizer(analyzer='word', binary=False,...            50   \n",
       "\n",
       "    vect__norm  vect__smooth_idf  Accuracy  \n",
       "434         l2              True  0.120000  \n",
       "169         l1             False  0.120000  \n",
       "339         l2             False  0.119286  \n",
       "168         l1              True  0.119286  \n",
       "410         l2              True  0.117143  \n",
       "362         l2              True  0.117143  \n",
       "150         l1              True  0.117143  \n",
       "151         l1             False  0.117143  \n",
       "504         l1              True  0.117143  \n",
       "483         l2             False  0.115714  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(fittedgrid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model no.1 \n",
    "results['param_model'].iloc[434]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model no.2\n",
    "results['param_model'].iloc[169]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the 2 best models on complete set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  40 | elapsed:  4.2min remaining: 38.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  40 | elapsed:  4.7min remaining: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed:  5.2min remaining:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  40 | elapsed:  5.6min remaining:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  40 | elapsed: 11.9min remaining:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  40 | elapsed: 12.2min remaining:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  40 | elapsed: 13.1min remaining:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 14.1min finished\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# use 2 best models to form a new pipeline and fit to the train set \n",
    "\n",
    "pipeline1 = Pipeline([ ('vect', CountVectorizer()),('model', LogisticRegression())])\n",
    "\n",
    "param_grid1 = [\n",
    "    # Logistic Regression\n",
    "    {'vect':[TfidfVectorizer(smooth_idf=False, norm='l1')], \n",
    "     'model':[LogisticRegression(solver='saga', penalty='l2', C=1.0)],\n",
    "     'vect__min_df':[100, 500, 1000, 2500]},\n",
    "    \n",
    "    # Random Forest\n",
    "    {'vect':[TfidfVectorizer(smooth_idf=True, norm='l2')], \n",
    "     'model':[RandomForestClassifier(n_estimators=50, max_depth=5)],\n",
    "     'vect__min_df':[100, 500, 1000, 2500]},\n",
    "]\n",
    "\n",
    "grid1 = GridSearchCV(pipeline1, param_grid1, cv=5, verbose=10, n_jobs=-1)\n",
    "fittedgrid1 = grid1.fit(X_train, y_train)\n",
    "\n",
    "fittedgrid1.score(X_test, y_test)\n",
    "\n",
    "# save the best model to file\n",
    "joblib.dump(fittedgrid1.best_estimator_, 'bestmodel1.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the model\n",
    "best_model = joblib.load('bestmodel1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1551844961032041"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score\n",
    "score = best_model.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFP       0.24      0.05      0.09     54285\n",
      "        INFJ       0.21      0.04      0.07     61493\n",
      "        INTP       0.16      0.17      0.17     76631\n",
      "        INTJ       0.23      0.06      0.10     66850\n",
      "        ENTP       0.18      0.01      0.02     18089\n",
      "        ENFP       0.31      0.02      0.04     19968\n",
      "        ISTP       0.31      0.04      0.07     28800\n",
      "        ISFP       0.31      0.11      0.16     47842\n",
      "        ENTJ       0.14      0.20      0.17     81078\n",
      "        ISTJ       0.13      0.43      0.20     92909\n",
      "        ENFJ       0.31      0.03      0.05     52665\n",
      "        ISFJ       0.13      0.35      0.19     89567\n",
      "        ESTP       0.30      0.05      0.08     46968\n",
      "        ESFP       0.44      0.07      0.12     42411\n",
      "        ESFJ       0.24      0.02      0.04     46478\n",
      "        ESTJ       0.24      0.19      0.21     67264\n",
      "\n",
      "   micro avg       0.16      0.16      0.16    893298\n",
      "   macro avg       0.24      0.12      0.11    893298\n",
      "weighted avg       0.22      0.16      0.13    893298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly the result is worse than Logistic Regression... \n",
    "\n",
    "To classify user comments to personality types are difficult, with 16 classes, random guessing would have an accuracy about 7%, the best model we tried is Logistic Regression, with precision/recall/f1 score all above 20%. \n",
    "\n",
    "However, I was not satisfied at that time, so I tried more approaches, including balancing the data, buillding LDA topic models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Imbalanced Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove more stop words!\n",
    "\n",
    "While I was working on building dictionary using Gensim, I found out that there are actually more stop words and spaces that are not cleaned in the documents, so I performed more cleaning steps here (*sigh*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T23:48:48.691915Z",
     "start_time": "2019-12-06T23:48:48.685395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lol that be why leave']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of posts \n",
    "[p.split('|||') for p in df_clean.head(1).comments_lemma.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T03:03:18.017750Z",
     "start_time": "2019-12-07T03:03:17.373762Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert columns to list \n",
    "\n",
    "list_personality = df_clean['MBTI'].tolist()\n",
    "list_posts = df_clean['comments_lemma'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# remove more stop words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop = ['to', 'of', 'the', 'be', 'for', 'that', 'do', 'have', 'this', 'and']\n",
    "stop_words = stop_words + stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove double and leading space \n",
    "dataset = [re.sub(' +', ' ', wd) for wd in list_posts]\n",
    "dataset = [wd.strip(' ') for wd in list_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the sentences \n",
    "sentence_steam = [doc.split(' ') for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the empty strings\n",
    "sentence_steam = [[x for x in string if x] for string in sentence_steam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extra stop words\n",
    "data_processed = [[wd for wd in doc if not wd in stop_words] for doc in sentence_steam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejoin the data_processed as list for TFIDF\n",
    "data_processed = [' '.join(doc) for doc in data_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['comments_lemma'] = data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>lol leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTP</td>\n",
       "      <td>post try tell people time always joke unless s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>first thought pepsi something probably alcohol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>formula something like every time say add bpm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTP</td>\n",
       "      <td>imply five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INTP</td>\n",
       "      <td>well would know think lot potential technology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>sine support director actor people behind film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INFP</td>\n",
       "      <td>use enough vacation day lose time roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INTP</td>\n",
       "      <td>angle devil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTP</td>\n",
       "      <td>mean much influence crow ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many people guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>INFP</td>\n",
       "      <td>go third date exactly breakup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>want nes classic controller since already game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>maybe tongue cheek wreck body enjoy use drug e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>INFP</td>\n",
       "      <td>agree consistant position support way think go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>INTP</td>\n",
       "      <td>alor pas balise integr e faut faire que par css</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>kind strange lump vague reference religion ont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>INFP</td>\n",
       "      <td>wow fuck woman kind worried child unlike fianc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>psychotic tire kill people dark comedy edgy we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>hella dank dude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>stat mean relatively little attempt counteract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INFP</td>\n",
       "      <td>never subreddit even british drink enough tea ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>make original comic random place see find site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>hmmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>INTP</td>\n",
       "      <td>blue cheese smell taste exactly like vomit und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>sure also check bjorn nyland youtube channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>INTP</td>\n",
       "      <td>help friend mine purchase two honda civic grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>white kinght become princess zulul megazulul w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>INFP</td>\n",
       "      <td>face sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61887</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>cutie land whale like way jose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61888</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>talk social hierarchy issue talk issue relate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61889</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>aventus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61890</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>would need unleash true power verbal deception...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61891</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>writing character good rest show drag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61892</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>true hero blooregard kazoo type confirm w estp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61893</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>definitely pride individuality sure would cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61894</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>ever issue nihilism avoid conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61895</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>know want know want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61896</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>well least plan rwby evo thank god</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61897</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>bullshit anyway would care high type brag woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61898</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61899</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>grasp point tripe view post call someone gun m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61900</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>real stop lie make shit scare people edit dele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61901</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>uni would study economic year prior go uni stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61902</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>use anything projectile base like arrow bolt t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61903</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>wow hate koala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61904</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>florida tennessee lsu georgia semifinal yes pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61905</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>big annoyance disease mean sometimes helpful f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61906</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>try explain stuff lab partner chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61907</th>\n",
       "      <td>ESTJ</td>\n",
       "      <td>good clever title well whole post work well to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61908</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>look like red tailed hawk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61909</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>congrat graduate though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61910</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>could maybe keep tooth white white snowflake l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61911</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>fruit salad think wash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61912</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>league legends recently uninstalle release hug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61913</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>take easy need come gun blaze hostility downvo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61914</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>let remember country still gain million people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61915</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>cfb bigxii time man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61916</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>fam w know common guess could see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2987373 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MBTI                                     comments_lemma\n",
       "0      INFP                                          lol leave\n",
       "1      INTP  post try tell people time always joke unless s...\n",
       "2      INFP     first thought pepsi something probably alcohol\n",
       "3      ENTP  formula something like every time say add bpm ...\n",
       "4      INTP                                         imply five\n",
       "5      INTP  well would know think lot potential technology...\n",
       "6      INFJ     sine support director actor people behind film\n",
       "7      INFP             use enough vacation day lose time roll\n",
       "8      INTP                                        angle devil\n",
       "9      INTP                      mean much influence crow ruby\n",
       "10     INTP                                  many people guess\n",
       "11     INFP                      go third date exactly breakup\n",
       "12     INFJ  want nes classic controller since already game...\n",
       "13     ENTP  maybe tongue cheek wreck body enjoy use drug e...\n",
       "14     INFP  agree consistant position support way think go...\n",
       "15     INTP    alor pas balise integr e faut faire que par css\n",
       "16     INTJ  kind strange lump vague reference religion ont...\n",
       "17     INFP  wow fuck woman kind worried child unlike fianc...\n",
       "18     ISTJ  psychotic tire kill people dark comedy edgy we...\n",
       "19     ENTP                                               like\n",
       "20     ENTP                                    hella dank dude\n",
       "21     ENTP  stat mean relatively little attempt counteract...\n",
       "22     INFP  never subreddit even british drink enough tea ...\n",
       "23     INTJ  make original comic random place see find site...\n",
       "24     INFJ                                               hmmm\n",
       "25     INTP  blue cheese smell taste exactly like vomit und...\n",
       "26     INFJ       sure also check bjorn nyland youtube channel\n",
       "27     INTP  help friend mine purchase two honda civic grea...\n",
       "28     ENTP  white kinght become princess zulul megazulul w...\n",
       "29     INFP                                          face sure\n",
       "...     ...                                                ...\n",
       "61887  ISTJ                     cutie land whale like way jose\n",
       "61888  ISTJ  talk social hierarchy issue talk issue relate ...\n",
       "61889  ISTJ                                            aventus\n",
       "61890  ISTJ  would need unleash true power verbal deception...\n",
       "61891  ISFP              writing character good rest show drag\n",
       "61892  ESTP  true hero blooregard kazoo type confirm w estp...\n",
       "61893  ISFP  definitely pride individuality sure would cons...\n",
       "61894  ESTJ                 ever issue nihilism avoid conflict\n",
       "61895  ESFJ                                know want know want\n",
       "61896  ISFJ                 well least plan rwby evo thank god\n",
       "61897  ISFP  bullshit anyway would care high type brag woul...\n",
       "61898  ESTP                                               meme\n",
       "61899  ISTJ  grasp point tripe view post call someone gun m...\n",
       "61900  ESTP  real stop lie make shit scare people edit dele...\n",
       "61901  ISFJ  uni would study economic year prior go uni stu...\n",
       "61902  ESTP  use anything projectile base like arrow bolt t...\n",
       "61903  ISFJ                                     wow hate koala\n",
       "61904  ISTJ  florida tennessee lsu georgia semifinal yes pl...\n",
       "61905  ESTJ  big annoyance disease mean sometimes helpful f...\n",
       "61906  ESFJ            try explain stuff lab partner chemistry\n",
       "61907  ESTJ  good clever title well whole post work well to...\n",
       "61908  ISFJ                          look like red tailed hawk\n",
       "61909  ESFP                            congrat graduate though\n",
       "61910  ESTP  could maybe keep tooth white white snowflake l...\n",
       "61911  ISFJ                             fruit salad think wash\n",
       "61912  ISFJ  league legends recently uninstalle release hug...\n",
       "61913  ISTJ  take easy need come gun blaze hostility downvo...\n",
       "61914  ESFP  let remember country still gain million people...\n",
       "61915  ESTP                                cfb bigxii time man\n",
       "61916  ESTP                  fam w know common guess could see\n",
       "\n",
       "[2987373 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save as a new file for future use\n",
    "df_clean.to_csv('token_voc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T06:46:53.713654Z",
     "start_time": "2019-12-09T06:46:53.055772Z"
    }
   },
   "outputs": [],
   "source": [
    "# remember to drop na\n",
    "data = df_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T06:46:56.137542Z",
     "start_time": "2019-12-09T06:46:55.712090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI              0\n",
       "comments_lemma    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset to 2 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T06:53:35.502863Z",
     "start_time": "2019-12-09T06:53:28.106743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split train and set dataframes and save as separate files \n",
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42, stratify=data.MBTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T06:53:36.391633Z",
     "start_time": "2019-12-09T06:53:36.386865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2665071, 2)\n",
      "(296119, 2)\n"
     ]
    }
   ],
   "source": [
    "# Look at the shape of the separate datasets\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T06:54:35.499059Z",
     "start_time": "2019-12-09T06:54:14.935859Z"
    }
   },
   "outputs": [],
   "source": [
    "# save files to csv for future use \n",
    "train_data.to_csv('train_data.csv')\n",
    "test_data.to_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T23:41:30.125438Z",
     "start_time": "2019-12-09T23:41:23.304944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T23:41:37.844672Z",
     "start_time": "2019-12-09T23:41:37.841390Z"
    }
   },
   "outputs": [],
   "source": [
    "# From this moment on, we will only deal with train dataset, and will not touch test data until it's time \n",
    "# to evaluate the performance of the models, so we set train data as df \n",
    "df = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T23:41:40.061549Z",
     "start_time": "2019-12-09T23:41:40.027641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1166243</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>like boss get shitbag estj even bad esfj real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521404</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>netflix use downloaded version chromecast chro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261951</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>dude sit next bus lot double seat leave edit w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758217</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>connect parent trans folk important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945670</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>c users yourname appdata local packages micros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556009</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>cheese melty bite hard messy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958092</th>\n",
       "      <td>INFP</td>\n",
       "      <td>lebron close elite skip bayless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17866</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>one rectify something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>see issue base trailer border good seem hard f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500654</th>\n",
       "      <td>INFP</td>\n",
       "      <td>joke tall woman welcome club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MBTI                                     comments_lemma\n",
       "1166243  ENTP  like boss get shitbag estj even bad esfj real ...\n",
       "1521404  ISTJ  netflix use downloaded version chromecast chro...\n",
       "261951   ENTJ  dude sit next bus lot double seat leave edit w...\n",
       "758217   INFJ                connect parent trans folk important\n",
       "945670   ENFJ  c users yourname appdata local packages micros...\n",
       "556009   ENTP                       cheese melty bite hard messy\n",
       "958092   INFP                    lebron close elite skip bayless\n",
       "17866    ESTP                              one rectify something\n",
       "3928     ISFP  see issue base trailer border good seem hard f...\n",
       "1500654  INFP                       joke tall woman welcome club"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the Data \n",
    "\n",
    "Although I have already done some upsampling when I first import the data, the imbalanced dataset still proves to be a problem, in my opinion, when fitting the data into the classifier. In addition, the 3 million - observation dataset has become a problem when doing computation-heavy modelling or functions. My hope is that a reduce-sized dataset at this point could help with the accuracy (How wrong I was!!) and computation time (time is precious before Demo day). Therefore, I made the judgement call of undersampling the complete dataset to match the minority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T23:42:00.945342Z",
     "start_time": "2019-12-09T23:42:00.641088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    276739\n",
       "INTP    266706\n",
       "INFJ    242212\n",
       "ENTJ    228588\n",
       "ISTP    201421\n",
       "ENTP    199207\n",
       "ENFP    183483\n",
       "ENFJ    161366\n",
       "INTJ    157322\n",
       "ESTP    142569\n",
       "ISFJ    140225\n",
       "ISTJ    138619\n",
       "ISFP    126794\n",
       "ESTJ     86058\n",
       "ESFP     59558\n",
       "ESFJ     54204\n",
       "Name: MBTI, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overview of data distribution \n",
    "df['MBTI'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T23:42:06.324488Z",
     "start_time": "2019-12-09T23:42:03.768396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot out the distribution of data \n",
    "plt.figure(figsize=(12,8))\n",
    "plt.xticks(fontsize=12, rotation=0)\n",
    "plt.yticks(fontsize=12, rotation=0)\n",
    "sns.countplot(data=df, x=df['MBTI'],order=df['MBTI'].value_counts().index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph we can see that the classes are highly imbalanced and they are causing a big problem to the classification models. Although the distribution reflects the personalities' distribution among the population, for this project's sake, I will have to introduce some bias - manually balancing the data. I will undersample the majorities to the same level as the minority class.\n",
    "\n",
    "A much reduced dataset will also help with the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T23:45:43.465447Z",
     "start_time": "2019-12-09T23:45:43.366376Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-daeca9ba3a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MBTI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \"\"\"\n\u001b[1;32m     74\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# store information to build a series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# use imblearn's randomundersampler \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "X = df[['comments_lemma']]\n",
    "y = df[['MBTI']]\n",
    "\n",
    "X_resampled, y_resampled = rus.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:17:47.514426Z",
     "start_time": "2019-12-10T00:17:46.195696Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert resamped X and y to series and join back together as a new df \n",
    "X_resampled = pd.Series(X_resampled.tolist()).apply(lambda x: ' '.join(x))\n",
    "y_resampled = pd.Series(y_resampled.tolist()).apply(lambda x: ' '.join(x))\n",
    "\n",
    "# put the X_resample and y_resampled back together to a df \n",
    "df_resampled = pd.concat([X_resampled,y_resampled],axis=1).reset_index(drop=True)\n",
    "df_resampled.columns = ['text', 'MBTI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:18:05.172058Z",
     "start_time": "2019-12-10T00:18:05.158539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>MBTI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>video like particular downvote show tutorial r...</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tolkien middle earth book especially silnarill...</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>halfway inferno shut amazing</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>must precise eye color green neutral l oreal p...</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>dunno expert acquisition work assume big role ...</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>geez totally miss fact mean literally win thin...</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>really fucking old</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>volunteer tribute</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>enfp</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>nope go freewill</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  MBTI\n",
       "0  video like particular downvote show tutorial r...  ENFJ\n",
       "1  tolkien middle earth book especially silnarill...  ENFJ\n",
       "2                       halfway inferno shut amazing  ENFJ\n",
       "3  must precise eye color green neutral l oreal p...  ENFJ\n",
       "4  dunno expert acquisition work assume big role ...  ENFJ\n",
       "5  geez totally miss fact mean literally win thin...  ENFJ\n",
       "6                                 really fucking old  ENFJ\n",
       "7                                  volunteer tribute  ENFJ\n",
       "8                                               enfp  ENFJ\n",
       "9                                   nope go freewill  ENFJ"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:17:52.400031Z",
     "start_time": "2019-12-10T00:17:52.286471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENTJ    54204\n",
       "ENTP    54204\n",
       "ESTP    54204\n",
       "INFJ    54204\n",
       "ENFJ    54204\n",
       "ISTJ    54204\n",
       "ESTJ    54204\n",
       "ISTP    54204\n",
       "ISFJ    54204\n",
       "ESFJ    54204\n",
       "INFP    54204\n",
       "ISFP    54204\n",
       "INTJ    54204\n",
       "ENFP    54204\n",
       "INTP    54204\n",
       "ESFP    54204\n",
       "Name: MBTI, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the values again \n",
    "df_resampled['MBTI'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:19:04.536190Z",
     "start_time": "2019-12-10T00:18:57.844754Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the resampled dataset as csv file for future use\n",
    "df_resampled.to_csv('../../clean_data/resampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizer - Find the top words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T05:11:29.175169Z",
     "start_time": "2019-12-11T05:11:29.171344Z"
    }
   },
   "outputs": [],
   "source": [
    "list_personality = df_resampled['MBTI']\n",
    "list_posts = df_resampled['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T05:39:08.676612Z",
     "start_time": "2019-12-11T05:39:08.601556Z"
    }
   },
   "outputs": [],
   "source": [
    "list_posts_enfj = df_resampled.loc[df_resampled['MBTI']=='ENFJ', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T05:16:51.182946Z",
     "start_time": "2019-12-11T05:14:43.701634Z"
    }
   },
   "outputs": [],
   "source": [
    "# vectorize with count vectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "cnvectorizer = CountVectorizer(tokenizer=None,    \n",
    "                             preprocessor=None, \n",
    "                             stop_words=None,  \n",
    "                             ngram_range=(1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T05:45:51.655362Z",
     "start_time": "2019-12-11T05:43:35.811549Z"
    }
   },
   "outputs": [],
   "source": [
    "MBTI_list = ['ENFJ', 'ENFP', 'ENTJ', 'ENTP', 'ESFJ', 'ESFP', 'ESTJ', 'ESTP', 'INFJ', 'INFP', 'INTJ','INTP','ISFJ','ISFP','ISTJ','ISTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-11T05:47:40.407Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vectorize with count and tf-idf\n",
    "# keep the words appearing in 1000 to 90% of the posts.\n",
    "# ngram is set to 2\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "tfidfizer = TfidfVectorizer(tokenizer=None,    \n",
    "                             preprocessor=None, \n",
    "                             stop_words=None,  \n",
    "                             ngram_range=(1,2),\n",
    "                             max_df=0.9,\n",
    "                             min_df=1000) \n",
    "                           \n",
    "#X_cnt = cntizer.fit_transform(list_posts).toarray()                                 \n",
    "X_tfidf = tfidfizer.fit_transform(list_posts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Most Frequently Used Words for ENFJ is:  ['google', 'love', 'sure', 'zone', 'forward']\n",
      "The Most Frequently Used Bigrams for ENFJ is:  ['find way', 'first place', 'first time', 'good job', 'good idea']\n",
      "The Most Frequently Used Words for ENFP is:  ['good', 'recall', 'tree', 'ground', 'exact']\n",
      "The Most Frequently Used Bigrams for ENFP is:  ['last night', 'find way', 'first place', 'first time', 'good friend']\n",
      "The Most Frequently Used Words for ENTJ is:  ['lie', 'cheat', 'website', 'put', 'person']\n",
      "The Most Frequently Used Bigrams for ENTJ is:  ['find way', 'first time', 'first place', 'good idea', 'good friend']\n",
      "The Most Frequently Used Words for ENTP is:  ['alternative', 'see', 'really', 'zone', 'forum']\n",
      "The Most Frequently Used Bigrams for ENTP is:  ['find way', 'first place', 'first time', 'good luck', 'good job']\n",
      "The Most Frequently Used Words for ESFJ is:  ['please', 'zone', 'forward', 'french', 'freedom']\n",
      "The Most Frequently Used Bigrams for ESFJ is:  ['find way', 'first time', 'first place', 'good one', 'good luck']\n",
      "The Most Frequently Used Words for ESFP is:  ['like', 'keep', 'yeah', 'back', 'feel']\n",
      "The Most Frequently Used Bigrams for ESFP is:  ['feel like', 'like good', 'go back', 'find way', 'first place']\n",
      "The Most Frequently Used Words for ESTJ is:  ['faster', 'role', 'make', 'come', 'pro']\n",
      "The Most Frequently Used Bigrams for ESTJ is:  ['would still', 'would make', 'first time', 'first place', 'find way']\n",
      "The Most Frequently Used Words for ESTP is:  ['step', 'take', 'zone', 'foot', 'free']\n",
      "The Most Frequently Used Bigrams for ESTP is:  ['find way', 'first place', 'first time', 'good job', 'good idea']\n",
      "The Most Frequently Used Words for INFJ is:  ['funny', 'sub', 'also', 'people', 'one']\n",
      "The Most Frequently Used Bigrams for INFJ is:  ['first time', 'first place', 'find way', 'good one', 'good luck']\n",
      "The Most Frequently Used Words for INFP is:  ['training', 'destroy', 'anti', 'five', 'minute']\n",
      "The Most Frequently Used Bigrams for INFP is:  ['good friend', 'first time', 'first place', 'find way', 'good luck']\n",
      "The Most Frequently Used Words for INTJ is:  ['low', 'also', 'dinner', 'food', 'include']\n",
      "The Most Frequently Used Bigrams for INTJ is:  ['find way', 'first time', 'first place', 'good job', 'good idea']\n",
      "The Most Frequently Used Words for INTP is:  ['zone', 'gt', 'french', 'freedom', 'free']\n",
      "The Most Frequently Used Bigrams for INTP is:  ['find way', 'first place', 'first time', 'good one', 'good luck']\n",
      "The Most Frequently Used Words for ISFJ is:  ['rich', 'smart', 'zone', 'forum', 'freedom']\n",
      "The Most Frequently Used Bigrams for ISFJ is:  ['find way', 'first place', 'first time', 'good luck', 'good job']\n",
      "The Most Frequently Used Words for ISFP is:  ['hello', 'url', 'forward', 'french', 'freedom']\n",
      "The Most Frequently Used Bigrams for ISFP is:  ['find way', 'first time', 'first place', 'good one', 'good luck']\n",
      "The Most Frequently Used Words for ISTJ is:  ['personal', 'hope', 'first', 'something', 'french']\n",
      "The Most Frequently Used Bigrams for ISTJ is:  ['find way', 'first place', 'first time', 'good job', 'good idea']\n",
      "The Most Frequently Used Words for ISTP is:  ['laugh', 'concerned', 'smile', 'people', 'easily']\n",
      "The Most Frequently Used Bigrams for ISTP is:  ['think could', 'people would', 'would make', 'feel like', 'find way']\n"
     ]
    }
   ],
   "source": [
    "# Find out the top 5 words/phrases for each personalities\n",
    "n = 5\n",
    "\n",
    "for personality in MBTI_list:\n",
    "    list_post_type = df_resampled.loc[df_resampled['MBTI'] == personality, 'text']\n",
    "    list_tfidf = tfidfizer.transform(list_post_type)\n",
    "    \n",
    "    feature_array = np.array(tfidfizer.get_feature_names())\n",
    "    tfidf_sorting = np.argsort(list_tfidf.toarray()).flatten()[::-1]\n",
    "    \n",
    "    sorted_feature =feature_array[tfidf_sorting]\n",
    "    \n",
    "    unigrams = [v for v in sorted_feature if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in sorted_feature if len(v.split(' ')) == 2]\n",
    "\n",
    "    \n",
    "    print('The Most Frequently Used Words for', personality, 'is: ', unigrams[:n])\n",
    "    print('The Most Frequently Used Bigrams for', personality, 'is: ', bigrams[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:20:33.330205Z",
     "start_time": "2019-12-10T00:20:33.290166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video': 2170,\n",
       " 'like': 1113,\n",
       " 'particular': 1414,\n",
       " 'downvote': 535,\n",
       " 'show': 1803,\n",
       " 'really': 1614,\n",
       " 'helpful': 903,\n",
       " 'steal': 1898,\n",
       " 'waste': 2195,\n",
       " 'people': 1430,\n",
       " 'time': 2057,\n",
       " 'generally': 798,\n",
       " 'wrong': 2292,\n",
       " 'dick': 502,\n",
       " 'also': 63,\n",
       " 'one': 1369,\n",
       " 'actually': 26,\n",
       " 'make': 1182,\n",
       " 'personal': 1455,\n",
       " 'attack': 140,\n",
       " 'waste time': 2196,\n",
       " 'middle': 1249,\n",
       " 'earth': 559,\n",
       " 'book': 225,\n",
       " 'especially': 618,\n",
       " 'write': 2289,\n",
       " 'love': 1166,\n",
       " 'old': 1367,\n",
       " 'influence': 983,\n",
       " 'want': 2186,\n",
       " 'create': 432,\n",
       " 'explain': 666,\n",
       " 'know': 1060,\n",
       " 'language': 1073,\n",
       " 'develop': 499,\n",
       " 'change': 294,\n",
       " 'focus': 753,\n",
       " 'lot': 1161,\n",
       " 'fine': 733,\n",
       " 'find': 731,\n",
       " 'need': 1314,\n",
       " 'story': 1910,\n",
       " 'child': 304,\n",
       " 'kid': 1053,\n",
       " 'connect': 382,\n",
       " 'main': 1177,\n",
       " 'work': 2252,\n",
       " 'shut': 1805,\n",
       " 'amazing': 71,\n",
       " 'must': 1298,\n",
       " 'eye': 677,\n",
       " 'color': 340,\n",
       " 'green': 859,\n",
       " 'neutral': 1321,\n",
       " 'match': 1211,\n",
       " 'perfectly': 1449,\n",
       " 'dunno': 553,\n",
       " 'expert': 665,\n",
       " 'assume': 136,\n",
       " 'big': 203,\n",
       " 'role': 1702,\n",
       " 'since': 1815,\n",
       " 'high': 908,\n",
       " 'member': 1237,\n",
       " 'speak': 1867,\n",
       " 'highly': 910,\n",
       " 'totally': 2080,\n",
       " 'miss': 1262,\n",
       " 'fact': 680,\n",
       " 'mean': 1225,\n",
       " 'literally': 1135,\n",
       " 'win': 2238,\n",
       " 'think': 2021,\n",
       " 'could': 412,\n",
       " 'fucking': 782,\n",
       " 'enfp': 595,\n",
       " 'nope': 1338,\n",
       " 'go': 828,\n",
       " 'guy': 871,\n",
       " 'play': 1482,\n",
       " 'sex': 1783,\n",
       " 'therapist': 2007,\n",
       " 'okay': 1366,\n",
       " 'question': 1577,\n",
       " 'somewhat': 1854,\n",
       " 'related': 1651,\n",
       " 'topic': 2078,\n",
       " 'hand': 878,\n",
       " 'engage': 596,\n",
       " 'discussion': 520,\n",
       " 'frame': 769,\n",
       " 'vary': 2165,\n",
       " 'depend': 486,\n",
       " 'person': 1454,\n",
       " 'generation': 799,\n",
       " 'current': 448,\n",
       " 'stage': 1885,\n",
       " 'life': 1110,\n",
       " 'marry': 1207,\n",
       " 'etc': 624,\n",
       " 'social': 1838,\n",
       " 'status': 1896,\n",
       " 'gender': 796,\n",
       " 'certain': 289,\n",
       " 'tend': 1994,\n",
       " 'best': 197,\n",
       " 'type': 2123,\n",
       " 'lol': 1147,\n",
       " 'comment': 351,\n",
       " 'someone': 1848,\n",
       " 'else': 580,\n",
       " 'separate': 1771,\n",
       " 'post': 1509,\n",
       " 'copy': 406,\n",
       " 'hate': 890,\n",
       " 'thing': 2011,\n",
       " 'dominant': 530,\n",
       " 'example': 649,\n",
       " 'say': 1728,\n",
       " 'value': 2162,\n",
       " 'opinion': 1385,\n",
       " 'almost': 57,\n",
       " 'every': 634,\n",
       " 'decision': 473,\n",
       " 'without': 2247,\n",
       " 'clearly': 325,\n",
       " 'something': 1850,\n",
       " 'disagree': 517,\n",
       " 'someone else': 1849,\n",
       " 'could say': 417,\n",
       " 'feel': 710,\n",
       " 'front': 779,\n",
       " 'lack': 1069,\n",
       " 'detail': 497,\n",
       " 'rest': 1682,\n",
       " 'image': 960,\n",
       " 'good': 839,\n",
       " 'job': 1038,\n",
       " 'feel like': 714,\n",
       " 'really like': 1621,\n",
       " 'like good': 1116,\n",
       " 'good job': 843,\n",
       " 'tbh': 1980,\n",
       " 'enfj': 594,\n",
       " 'take': 1969,\n",
       " 'home': 923,\n",
       " 'school': 1743,\n",
       " 'strong': 1922,\n",
       " 'around': 123,\n",
       " 'see': 1757,\n",
       " 'pretty': 1526,\n",
       " 'much': 1290,\n",
       " 'everything': 642,\n",
       " 'consider': 387,\n",
       " 'opposite': 1388,\n",
       " 'different': 506,\n",
       " 'gt': 865,\n",
       " 'idea': 949,\n",
       " 'interest': 1005,\n",
       " 'future': 789,\n",
       " 'imagine': 961,\n",
       " 'user': 2156,\n",
       " 'explore': 668,\n",
       " 'information': 985,\n",
       " 'seem': 1761,\n",
       " 'rather': 1598,\n",
       " 'manner': 1198,\n",
       " 'enjoy': 601,\n",
       " 'useful': 2154,\n",
       " 'ridiculous': 1693,\n",
       " 'source': 1864,\n",
       " 'theme': 2005,\n",
       " 'store': 1909,\n",
       " 'apply': 113,\n",
       " 'elsewhere': 581,\n",
       " 'understand': 2131,\n",
       " 'well': 2218,\n",
       " 'enough': 603,\n",
       " 'move': 1287,\n",
       " 'maybe': 1222,\n",
       " 'exactly': 648,\n",
       " 'get': 805,\n",
       " 'obsess': 1353,\n",
       " 'brain': 238,\n",
       " 'culture': 444,\n",
       " 'interesting': 1007,\n",
       " 'individual': 979,\n",
       " 'boring': 229,\n",
       " 'usually': 2159,\n",
       " 'talk': 1972,\n",
       " 'easy': 562,\n",
       " 'put': 1574,\n",
       " 'context': 396,\n",
       " 'tho': 2039,\n",
       " 'small': 1832,\n",
       " 'town': 2085,\n",
       " 'family': 691,\n",
       " 'bring': 242,\n",
       " 'attract': 145,\n",
       " 'statement': 1894,\n",
       " 'necessarily': 1312,\n",
       " 'experience': 663,\n",
       " 'laugh': 1083,\n",
       " 'introvert': 1016,\n",
       " 'parent': 1411,\n",
       " 'probably': 1540,\n",
       " 'sometimes': 1853,\n",
       " 'remember': 1663,\n",
       " 'refer': 1640,\n",
       " 'many': 1199,\n",
       " 'friend': 776,\n",
       " 'stay': 1897,\n",
       " 'room': 1705,\n",
       " 'recently': 1633,\n",
       " 'force': 759,\n",
       " 'bad': 163,\n",
       " 'avoid': 154,\n",
       " 'right': 1694,\n",
       " 'normal': 1339,\n",
       " 'christian': 312,\n",
       " 'mature': 1216,\n",
       " 'either': 576,\n",
       " 'read': 1604,\n",
       " 'fiction': 721,\n",
       " 'classic': 322,\n",
       " 'hold': 919,\n",
       " 'sound': 1862,\n",
       " 'infj': 982,\n",
       " 'hard': 884,\n",
       " 'male': 1193,\n",
       " 'affect': 40,\n",
       " 'include': 971,\n",
       " 'however': 937,\n",
       " 'plan': 1479,\n",
       " 'suggest': 1942,\n",
       " 'charge': 297,\n",
       " 'host': 933,\n",
       " 'care': 274,\n",
       " 'look': 1152,\n",
       " 'mind': 1254,\n",
       " 'happiness': 882,\n",
       " 'positive': 1505,\n",
       " 'emotion': 583,\n",
       " 'would': 2259,\n",
       " 'negative': 1316,\n",
       " 'ruin': 1712,\n",
       " 'everybody': 638,\n",
       " 'mood': 1278,\n",
       " 'sell': 1765,\n",
       " 'aware': 155,\n",
       " 'everyone': 640,\n",
       " 'power': 1513,\n",
       " 'terrible': 1997,\n",
       " 'memory': 1239,\n",
       " 'past': 1422,\n",
       " 'definitely': 480,\n",
       " 'try': 2113,\n",
       " 'although': 68,\n",
       " 'overly': 1401,\n",
       " 'several': 1781,\n",
       " 'always': 69,\n",
       " 'sure': 1953,\n",
       " 'happy': 883,\n",
       " 'haha': 874,\n",
       " 'trouble': 2107,\n",
       " 'loud': 1165,\n",
       " 'college': 339,\n",
       " 'note': 1342,\n",
       " 'ability': 0,\n",
       " 'group': 862,\n",
       " 'use': 2153,\n",
       " 'come': 345,\n",
       " 'naturally': 1306,\n",
       " 'least': 1092,\n",
       " 'difference': 505,\n",
       " 'form': 763,\n",
       " 'structure': 1924,\n",
       " 'subject': 1933,\n",
       " 'input': 989,\n",
       " 'datum': 463,\n",
       " 'conclusion': 373,\n",
       " 'completely': 365,\n",
       " 'obvious': 1354,\n",
       " 'anyway': 100,\n",
       " 'give': 824,\n",
       " 'url': 2148,\n",
       " 'content': 395,\n",
       " 'php': 1464,\n",
       " 'mbti': 1223,\n",
       " 'inferior': 981,\n",
       " 'pretty much': 1528,\n",
       " 'good one': 845,\n",
       " 'lot people': 1162,\n",
       " 'people want': 1443,\n",
       " 'feel good': 713,\n",
       " 'make feel': 1184,\n",
       " 'feel bad': 711,\n",
       " 'good thing': 847,\n",
       " 'want get': 2187,\n",
       " 'sound like': 1863,\n",
       " 'look like': 1155,\n",
       " 'would rather': 2278,\n",
       " 'everyone else': 641,\n",
       " 'make sure': 1189,\n",
       " 'think really': 2033,\n",
       " 'bad thing': 164,\n",
       " 'fuck': 781,\n",
       " 'discover': 518,\n",
       " 'fantastic': 693,\n",
       " 'damn': 458,\n",
       " 'reasonable': 1628,\n",
       " 'back': 161,\n",
       " 'specific': 1869,\n",
       " 'provide': 1563,\n",
       " 'evidence': 645,\n",
       " 'point': 1490,\n",
       " 'deny': 485,\n",
       " 'nothing': 1343,\n",
       " 'worth': 2258,\n",
       " 'live': 1138,\n",
       " 'level': 1106,\n",
       " 'cold': 336,\n",
       " 'realise': 1610,\n",
       " 'common': 354,\n",
       " 'argument': 119,\n",
       " 'website': 2210,\n",
       " 'trump': 2110,\n",
       " 'organization': 1392,\n",
       " 'trust': 2111,\n",
       " 'even': 626,\n",
       " 'way': 2200,\n",
       " 'first': 737,\n",
       " 'date': 462,\n",
       " 'test': 1998,\n",
       " 'anyone': 96,\n",
       " 'score': 1746,\n",
       " 'anything': 98,\n",
       " 'anything else': 99,\n",
       " 'tone': 2073,\n",
       " 'may': 1218,\n",
       " 'though': 2040,\n",
       " 'intj': 1013,\n",
       " 'tendency': 1995,\n",
       " 'compliment': 368,\n",
       " 'ear': 555,\n",
       " 'fast': 698,\n",
       " 'hour': 935,\n",
       " 'death': 468,\n",
       " 'share': 1790,\n",
       " 'road': 1699,\n",
       " 'dad': 455,\n",
       " 'five': 742,\n",
       " 'figure': 724,\n",
       " 'cream': 431,\n",
       " 'important': 966,\n",
       " 'part': 1413,\n",
       " 'whole': 2229,\n",
       " 'wall': 2184,\n",
       " 'behind': 190,\n",
       " 'taste': 1978,\n",
       " 'would good': 2268,\n",
       " 'hell': 900,\n",
       " 'able': 1,\n",
       " 'would able': 2260,\n",
       " 'wow': 2288,\n",
       " 'act': 18,\n",
       " 'year': 2297,\n",
       " 'act like': 19,\n",
       " 'year old': 2299,\n",
       " 'useless': 2155,\n",
       " 'side': 1807,\n",
       " 'character': 296,\n",
       " 'strange': 1912,\n",
       " 'business': 256,\n",
       " 'long': 1148,\n",
       " 'relevant': 1658,\n",
       " 'remind': 1664,\n",
       " 'reason': 1627,\n",
       " 'hahaha': 875,\n",
       " 'curious': 447,\n",
       " 'thank': 2002,\n",
       " 'response': 1679,\n",
       " 'us': 2152,\n",
       " 'concern': 371,\n",
       " 'program': 1552,\n",
       " 'approach': 115,\n",
       " 'proper': 1557,\n",
       " 'obviously': 1355,\n",
       " 'debate': 469,\n",
       " 'trend': 2102,\n",
       " 'like lot': 1118,\n",
       " 'still': 1904,\n",
       " 'sign': 1808,\n",
       " 'yeah': 2296,\n",
       " 'another': 88,\n",
       " 'cat': 282,\n",
       " 'similar': 1811,\n",
       " 'design': 493,\n",
       " 'house': 936,\n",
       " 'accidentally': 10,\n",
       " 'somehow': 1847,\n",
       " 'outside': 1399,\n",
       " 'door': 531,\n",
       " 'run': 1714,\n",
       " 'inside': 991,\n",
       " 'pretty sure': 1529,\n",
       " 'pink': 1474,\n",
       " 'think one': 2031,\n",
       " 'regard': 1644,\n",
       " 'stereotype': 1902,\n",
       " 'believe': 192,\n",
       " 'automatically': 151,\n",
       " 'real': 1608,\n",
       " 'infp': 986,\n",
       " 'end': 591,\n",
       " 'relationship': 1653,\n",
       " 'criticism': 438,\n",
       " 'towards': 2084,\n",
       " 'forum': 766,\n",
       " 'due': 551,\n",
       " 'intuitive': 1019,\n",
       " 'bias': 201,\n",
       " 'notice': 1344,\n",
       " 'nearly': 1310,\n",
       " 'online': 1381,\n",
       " 'large': 1074,\n",
       " 'portion': 1503,\n",
       " 'community': 357,\n",
       " 'self': 1763,\n",
       " 'visit': 2175,\n",
       " 'better': 199,\n",
       " 'theory': 2006,\n",
       " 'argue': 118,\n",
       " 'society': 1840,\n",
       " 'estj': 622,\n",
       " 'man': 1194,\n",
       " 'seek': 1760,\n",
       " 'attitude': 144,\n",
       " 'stuff': 1928,\n",
       " 'trait': 2092,\n",
       " 'woman': 2248,\n",
       " 'let': 1102,\n",
       " 'sensitive': 1768,\n",
       " 'sweet': 1962,\n",
       " 'passive': 1421,\n",
       " 'yes': 2303,\n",
       " 'agree': 47,\n",
       " 'issue': 1028,\n",
       " 'dynamic': 554,\n",
       " 'incredibly': 975,\n",
       " 'complex': 366,\n",
       " 'whatever': 2223,\n",
       " 'problem': 1543,\n",
       " 'strength': 1917,\n",
       " 'real life': 1609,\n",
       " 'many people': 1200,\n",
       " 'seriously': 1774,\n",
       " 'month': 1276,\n",
       " 'never': 1322,\n",
       " 'claim': 319,\n",
       " 'nation': 1302,\n",
       " 'amount': 77,\n",
       " 'little': 1136,\n",
       " 'slow': 1830,\n",
       " 'effort': 573,\n",
       " 'lose': 1159,\n",
       " 'hope': 927,\n",
       " 'difficult': 509,\n",
       " 'twice': 2119,\n",
       " 'threat': 2045,\n",
       " 'rid': 1691,\n",
       " 'harm': 888,\n",
       " 'young': 2306,\n",
       " 'guilty': 869,\n",
       " 'ever': 632,\n",
       " 'may get': 1219,\n",
       " 'get rid': 817,\n",
       " 'burn': 254,\n",
       " 'bitch': 210,\n",
       " 'thought': 2042,\n",
       " 'close': 327,\n",
       " 'remove': 1665,\n",
       " 'fear': 706,\n",
       " 'hurt': 946,\n",
       " 'fully': 784,\n",
       " 'open': 1383,\n",
       " 'close friend': 328,\n",
       " 'think may': 2029,\n",
       " 'dollar': 528,\n",
       " 'black': 212,\n",
       " 'plain': 1478,\n",
       " 'paper': 1410,\n",
       " 'special': 1868,\n",
       " 'solid': 1843,\n",
       " 'fix': 743,\n",
       " 'stress': 1918,\n",
       " 'kinda': 1056,\n",
       " 'jump': 1045,\n",
       " 'silly': 1810,\n",
       " 'nervous': 1318,\n",
       " 'worry': 2257,\n",
       " 'sort': 1860,\n",
       " 'head': 891,\n",
       " 'together': 2070,\n",
       " 'please': 1485,\n",
       " 'take time': 1971,\n",
       " 'happen': 881,\n",
       " 'shit': 1794,\n",
       " 'album': 52,\n",
       " 'pant': 1409,\n",
       " 'welcome': 2217,\n",
       " 'fashion': 697,\n",
       " 'length': 1098,\n",
       " 'link': 1132,\n",
       " 'immediately': 962,\n",
       " 'properly': 1558,\n",
       " 'along': 59,\n",
       " 'joke': 1041,\n",
       " 'anyways': 101,\n",
       " 'go get': 831,\n",
       " 'series': 1772,\n",
       " 'rock': 1701,\n",
       " 'mechanic': 1230,\n",
       " 'depth': 489,\n",
       " 'universe': 2138,\n",
       " 'follow': 755,\n",
       " 'two': 2121,\n",
       " 'game': 791,\n",
       " 'combat': 342,\n",
       " 'bit': 209,\n",
       " 'crap': 428,\n",
       " 'gear': 795,\n",
       " 'choose': 310,\n",
       " 'amp': 78,\n",
       " 'top': 2077,\n",
       " 'spot': 1880,\n",
       " 'honestly': 925,\n",
       " 'jpg': 1042,\n",
       " 'original': 1395,\n",
       " 'process': 1544,\n",
       " 'increase': 973,\n",
       " 'become': 184,\n",
       " 'reality': 1612,\n",
       " 'stand': 1886,\n",
       " 'matter': 1215,\n",
       " 'contact': 393,\n",
       " 'express': 669,\n",
       " 'feeling': 717,\n",
       " 'action': 20,\n",
       " 'overall': 1400,\n",
       " 'would say': 2281,\n",
       " 'function': 786,\n",
       " 'lead': 1087,\n",
       " 'day': 465,\n",
       " 'one day': 1370,\n",
       " 'confident': 376,\n",
       " 'party': 1417,\n",
       " 'tired': 2065,\n",
       " 'mad': 1175,\n",
       " 'internet': 1009,\n",
       " 'jealous': 1035,\n",
       " 'lately': 1080,\n",
       " 'meme': 1238,\n",
       " 'indeed': 976,\n",
       " 'weird': 2216,\n",
       " 'combination': 343,\n",
       " 'skin': 1824,\n",
       " 'soon': 1858,\n",
       " 'clear': 324,\n",
       " 'necessary': 1313,\n",
       " 'would like': 2270,\n",
       " 'brother': 244,\n",
       " 'movie': 1289,\n",
       " 'watch': 2197,\n",
       " 'summer': 1946,\n",
       " 'week': 2213,\n",
       " 'half': 877,\n",
       " 'like say': 1123,\n",
       " 'total': 2079,\n",
       " 'loss': 1160,\n",
       " 'eat': 563,\n",
       " 'word': 2251,\n",
       " 'humor': 944,\n",
       " 'husband': 947,\n",
       " 'tell': 1991,\n",
       " 'interested': 1006,\n",
       " 'previous': 1532,\n",
       " 'grow': 863,\n",
       " 'ton': 2072,\n",
       " 'beautiful': 183,\n",
       " 'complete': 364,\n",
       " 'asshole': 134,\n",
       " 'intp': 1014,\n",
       " 'quite': 1582,\n",
       " 'unit': 2136,\n",
       " 'quite bit': 1583,\n",
       " 'even though': 629,\n",
       " 'really want': 1625,\n",
       " 'great': 858,\n",
       " 'king': 1057,\n",
       " 'dr': 536,\n",
       " 'doctor': 526,\n",
       " 'patient': 1425,\n",
       " 'feed': 708,\n",
       " 'via': 2167,\n",
       " 'term': 1996,\n",
       " 'bottle': 233,\n",
       " 'adult': 35,\n",
       " 'could see': 418,\n",
       " 'long term': 1149,\n",
       " 'drive': 544,\n",
       " 'dog': 527,\n",
       " 'team': 1984,\n",
       " 'distance': 525,\n",
       " 'exercise': 656,\n",
       " 'prepare': 1520,\n",
       " 'hair': 876,\n",
       " 'would want': 2285,\n",
       " 'get one': 813,\n",
       " 'lock': 1144,\n",
       " 'teach': 1982,\n",
       " 'basic': 175,\n",
       " 'economic': 564,\n",
       " 'high school': 909,\n",
       " 'face': 678,\n",
       " 'hang': 880,\n",
       " 'sport': 1879,\n",
       " 'tie': 2052,\n",
       " 'four': 768,\n",
       " 'porn': 1502,\n",
       " 'female': 719,\n",
       " 'enemy': 592,\n",
       " 'dude': 550,\n",
       " 'press': 1523,\n",
       " 'shitty': 1795,\n",
       " 'fault': 702,\n",
       " 'go back': 830,\n",
       " 'mention': 1242,\n",
       " 'already': 60,\n",
       " 'meaning': 1226,\n",
       " 'personally': 1457,\n",
       " 'gift': 821,\n",
       " 'ago': 46,\n",
       " 'sense': 1767,\n",
       " 'hobby': 918,\n",
       " 'funny': 788,\n",
       " 'moment': 1272,\n",
       " 'spend': 1874,\n",
       " 'say want': 1734,\n",
       " 'say like': 1730,\n",
       " 'month ago': 1277,\n",
       " 'make sense': 1188,\n",
       " 'go way': 835,\n",
       " 'way get': 2201,\n",
       " 'direction': 514,\n",
       " 'across': 17,\n",
       " 'makeup': 1192,\n",
       " 'style': 1931,\n",
       " 'much well': 1293,\n",
       " 'china': 307,\n",
       " 'cost': 411,\n",
       " 'emotional': 584,\n",
       " 'robot': 1700,\n",
       " 'chinese': 308,\n",
       " 'money': 1273,\n",
       " 'player': 1484,\n",
       " 'wage': 2180,\n",
       " 'people use': 1442,\n",
       " 'night': 1333,\n",
       " 'confused': 380,\n",
       " 'attention': 143,\n",
       " 'reach': 1601,\n",
       " 'help': 902,\n",
       " 'last': 1075,\n",
       " 'forget': 762,\n",
       " 'sub': 1932,\n",
       " 'page': 1404,\n",
       " 'ask': 130,\n",
       " 'stop': 1908,\n",
       " 'new': 1327,\n",
       " 'discuss': 519,\n",
       " 'learn': 1091,\n",
       " 'guess': 867,\n",
       " 'last night': 1076,\n",
       " 'sorry': 1859,\n",
       " 'suck': 1938,\n",
       " 'body': 222,\n",
       " 'apple': 111,\n",
       " 'glass': 827,\n",
       " 'picture': 1471,\n",
       " 'beer': 186,\n",
       " 'fill': 726,\n",
       " 'exist': 657,\n",
       " 'communication': 356,\n",
       " 'deeply': 475,\n",
       " 'call': 262,\n",
       " 'dislike': 522,\n",
       " 'keep': 1049,\n",
       " 'peace': 1429,\n",
       " 'relate': 1650,\n",
       " 'comfort': 348,\n",
       " 'address': 30,\n",
       " 'cause': 285,\n",
       " 'truth': 2112,\n",
       " 'likely': 1128,\n",
       " 'drag': 537,\n",
       " 'chance': 293,\n",
       " 'advice': 38,\n",
       " 'sit': 1818,\n",
       " 'away': 156,\n",
       " 'easily': 560,\n",
       " 'motivation': 1284,\n",
       " 'uncomfortable': 2130,\n",
       " 'angry': 83,\n",
       " 'relax': 1656,\n",
       " 'less': 1100,\n",
       " 'phrase': 1465,\n",
       " 'non': 1336,\n",
       " 'google': 850,\n",
       " 'tip': 2064,\n",
       " 'magic': 1176,\n",
       " 'situation': 1820,\n",
       " 'respond': 1678,\n",
       " 'benefit': 194,\n",
       " 'control': 400,\n",
       " 'conversation': 401,\n",
       " 'threaten': 2046,\n",
       " 'safe': 1720,\n",
       " 'comfortable': 349,\n",
       " 'anxiety': 92,\n",
       " 'third': 2038,\n",
       " 'let go': 1103,\n",
       " 'seem like': 1762,\n",
       " 'really hard': 1619,\n",
       " 'know would': 1066,\n",
       " 'would really': 2279,\n",
       " 'get people': 814,\n",
       " 'really really': 1623,\n",
       " 'really well': 1626,\n",
       " 'let know': 1104,\n",
       " 'yup': 2308,\n",
       " 'check': 301,\n",
       " 'tea': 1981,\n",
       " 'final': 729,\n",
       " 'sample': 1725,\n",
       " 'letter': 1105,\n",
       " 'possible': 1507,\n",
       " 'government': 852,\n",
       " 'blame': 213,\n",
       " 'natural': 1305,\n",
       " 'willing': 2237,\n",
       " 'pre': 1517,\n",
       " 'png': 1489,\n",
       " 'search': 1750,\n",
       " 'faith': 686,\n",
       " 'far': 695,\n",
       " 'selfish': 1764,\n",
       " 'communicate': 355,\n",
       " 'perfect': 1448,\n",
       " 'thinking': 2037,\n",
       " 'lt': 1170,\n",
       " 'except': 651,\n",
       " 'yet': 2305,\n",
       " 'annoying': 87,\n",
       " 'fair': 684,\n",
       " 'feel way': 715,\n",
       " 'people like': 1436,\n",
       " 'build': 250,\n",
       " 'boat': 221,\n",
       " 'efficient': 572,\n",
       " 'cheap': 299,\n",
       " 'longer': 1151,\n",
       " 'die': 503,\n",
       " 'pro': 1539,\n",
       " 'choice': 309,\n",
       " 'logic': 1145,\n",
       " 'deep': 474,\n",
       " 'partner': 1416,\n",
       " 'limit': 1129,\n",
       " 'serve': 1775,\n",
       " 'defense': 478,\n",
       " 'admit': 33,\n",
       " 'ideal': 950,\n",
       " 'save': 1727,\n",
       " 'decide': 472,\n",
       " 'light': 1112,\n",
       " 'armor': 121,\n",
       " 'buy': 259,\n",
       " 'exact': 647,\n",
       " 'name': 1301,\n",
       " 'second': 1753,\n",
       " 'heavy': 899,\n",
       " 'state': 1893,\n",
       " 'car': 272,\n",
       " 'illegal': 958,\n",
       " 'cute': 453,\n",
       " 'lovely': 1167,\n",
       " 'rush': 1715,\n",
       " 'wait': 2181,\n",
       " 'next': 1329,\n",
       " 'think go': 2024,\n",
       " 'driver': 545,\n",
       " 'straight': 1911,\n",
       " 'switch': 1963,\n",
       " 'wanna': 2185,\n",
       " 'environment': 609,\n",
       " 'bored': 228,\n",
       " 'quickly': 1579,\n",
       " 'something else': 1851,\n",
       " 'kill': 1054,\n",
       " 'tear': 1985,\n",
       " 'excuse': 655,\n",
       " 'justify': 1047,\n",
       " 'like go': 1115,\n",
       " 'hey': 906,\n",
       " 'article': 126,\n",
       " 'join': 1040,\n",
       " 'church': 314,\n",
       " 'busy': 257,\n",
       " 'personality': 1456,\n",
       " 'meet': 1235,\n",
       " 'perhaps': 1452,\n",
       " 'get along': 806,\n",
       " 'enneagram': 602,\n",
       " 'creepy': 435,\n",
       " 'kind': 1055,\n",
       " 'minded': 1255,\n",
       " 'perspective': 1458,\n",
       " 'reasoning': 1629,\n",
       " 'basically': 176,\n",
       " 'assumption': 137,\n",
       " 'like people': 1121,\n",
       " 'music': 1297,\n",
       " 'research': 1675,\n",
       " 'wiki': 2234,\n",
       " 'subjective': 1934,\n",
       " 'prove': 1562,\n",
       " 'impossible': 967,\n",
       " 'novel': 1345,\n",
       " 'philosophy': 1461,\n",
       " 'human': 942,\n",
       " 'science': 1744,\n",
       " 'superior': 1949,\n",
       " 'knowledge': 1067,\n",
       " 'valid': 2161,\n",
       " 'path': 1424,\n",
       " 'url wiki': 2151,\n",
       " 'people feel': 1432,\n",
       " 'nah': 1299,\n",
       " 'heat': 897,\n",
       " 'html': 938,\n",
       " 'cake': 260,\n",
       " 'reply': 1669,\n",
       " 'damage': 457,\n",
       " 'floor': 750,\n",
       " 'really need': 1622,\n",
       " 'band': 170,\n",
       " 'deserve': 492,\n",
       " 'credit': 434,\n",
       " 'edit': 567,\n",
       " 'god': 837,\n",
       " 'mistake': 1264,\n",
       " 'course': 424,\n",
       " 'encounter': 589,\n",
       " 'good point': 846,\n",
       " 'thread': 2044,\n",
       " 'hit': 916,\n",
       " 'get lot': 812,\n",
       " 'late': 1079,\n",
       " 'serious': 1773,\n",
       " 'today': 2069,\n",
       " 'pretty good': 1527,\n",
       " 'essentially': 619,\n",
       " 'even know': 628,\n",
       " 'none': 1337,\n",
       " 'event': 630,\n",
       " 'advance': 36,\n",
       " 'empty': 588,\n",
       " 'bible': 202,\n",
       " 'description': 491,\n",
       " 'answer': 89,\n",
       " 'leave': 1093,\n",
       " 'heart': 896,\n",
       " 'super': 1948,\n",
       " 'absolutely': 3,\n",
       " 'alone': 58,\n",
       " 'start': 1890,\n",
       " 'depressed': 487,\n",
       " 'position': 1504,\n",
       " 'start get': 1891,\n",
       " 'like make': 1119,\n",
       " 'number': 1347,\n",
       " 'nice': 1332,\n",
       " 'still get': 1905,\n",
       " 'guide': 868,\n",
       " 'turn': 2118,\n",
       " 'dragon': 538,\n",
       " 'involve': 1022,\n",
       " 'pretend': 1525,\n",
       " 'try make': 2116,\n",
       " 'bar': 172,\n",
       " 'instead': 995,\n",
       " 'somewhere': 1855,\n",
       " 'say something': 1731,\n",
       " 'racist': 1586,\n",
       " 'song': 1857,\n",
       " 'bomb': 223,\n",
       " 'obama': 1348,\n",
       " 'average': 153,\n",
       " 'expect': 660,\n",
       " 'survive': 1959,\n",
       " 'mess': 1244,\n",
       " 'little bit': 1137,\n",
       " 'prevent': 1531,\n",
       " 'free': 771,\n",
       " 'expand': 659,\n",
       " 'trip': 2105,\n",
       " 'jerk': 1036,\n",
       " 'think people': 2032,\n",
       " 'feel free': 712,\n",
       " 'people say': 1439,\n",
       " 'troll': 2106,\n",
       " 'ignore': 955,\n",
       " 'steam': 1899,\n",
       " 'thousand': 2043,\n",
       " 'tag': 1968,\n",
       " 'would think': 2284,\n",
       " 'girl': 822,\n",
       " 'much time': 1292,\n",
       " 'could get': 414,\n",
       " 'stick': 1903,\n",
       " 'confirm': 377,\n",
       " 'section': 1755,\n",
       " 'attach': 139,\n",
       " 'medical': 1232,\n",
       " 'baby': 160,\n",
       " 'receive': 1631,\n",
       " 'fire': 736,\n",
       " 'mom': 1271,\n",
       " 'repeat': 1667,\n",
       " 'already know': 61,\n",
       " 'piece': 1472,\n",
       " 'offer': 1361,\n",
       " 'area': 117,\n",
       " 'next time': 1330,\n",
       " 'thank much': 2003,\n",
       " 'title': 2066,\n",
       " 'birthday': 208,\n",
       " 'yea': 2295,\n",
       " 'nail': 1300,\n",
       " 'internal': 1008,\n",
       " 'walk': 2183,\n",
       " 'soul': 1861,\n",
       " 'continue': 397,\n",
       " 'confidence': 375,\n",
       " 'allow': 56,\n",
       " 'intelligence': 998,\n",
       " 'dream': 541,\n",
       " 'travel': 2098,\n",
       " 'country': 422,\n",
       " 'currently': 449,\n",
       " 'concerned': 372,\n",
       " 'practice': 1516,\n",
       " 'sexual': 1784,\n",
       " 'habit': 873,\n",
       " 'daily': 456,\n",
       " 'freak': 770,\n",
       " 'everyday': 639,\n",
       " 'realize': 1613,\n",
       " 'center': 287,\n",
       " 'energy': 593,\n",
       " 'set': 1778,\n",
       " 'upon': 2145,\n",
       " 'thus': 2050,\n",
       " 'recognize': 1634,\n",
       " 'mother': 1283,\n",
       " 'fly': 752,\n",
       " 'leg': 1095,\n",
       " 'physical': 1466,\n",
       " 'wise': 2243,\n",
       " 'often': 1364,\n",
       " 'beyond': 200,\n",
       " 'spirit': 1876,\n",
       " 'application': 112,\n",
       " 'world': 2255,\n",
       " 'land': 1071,\n",
       " 'reading': 1606,\n",
       " 'appreciate': 114,\n",
       " 'every day': 635,\n",
       " 'pass': 1419,\n",
       " 'simple': 1813,\n",
       " 'french': 773,\n",
       " 'english': 600,\n",
       " 'sentence': 1770,\n",
       " 'correct': 409,\n",
       " 'app': 106,\n",
       " 'majority': 1181,\n",
       " 'cool': 404,\n",
       " 'bernie': 195,\n",
       " 'low': 1168,\n",
       " ...}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T01:43:49.647979Z",
     "start_time": "2019-12-09T01:43:48.766787Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_resampled['text'], df_resampled['MBTI'], random_state = 42, stratify=df_resampled['MBTI'])\n",
    "X_train_tfidf = tfidfizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T01:43:49.647979Z",
     "start_time": "2019-12-09T01:43:48.766787Z"
    }
   },
   "outputs": [],
   "source": [
    "mynb = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T01:43:52.208953Z",
     "start_time": "2019-12-09T01:43:52.082779Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidfizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T01:43:54.211287Z",
     "start_time": "2019-12-09T01:43:54.205886Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = mynb.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T01:45:07.871669Z",
     "start_time": "2019-12-09T01:45:07.823902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.13466257102796841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.10      0.12      0.11     13551\n",
      "        ENFP       0.11      0.04      0.06     13551\n",
      "        ENTJ       0.11      0.08      0.10     13551\n",
      "        ENTP       0.15      0.07      0.10     13551\n",
      "        ESFJ       0.15      0.35      0.21     13551\n",
      "        ESFP       0.16      0.22      0.19     13551\n",
      "        ESTJ       0.17      0.27      0.21     13551\n",
      "        ESTP       0.13      0.18      0.15     13551\n",
      "        INFJ       0.11      0.05      0.07     13551\n",
      "        INFP       0.09      0.04      0.06     13551\n",
      "        INTJ       0.12      0.12      0.12     13551\n",
      "        INTP       0.10      0.05      0.07     13551\n",
      "        ISFJ       0.14      0.11      0.12     13551\n",
      "        ISFP       0.14      0.12      0.13     13551\n",
      "        ISTJ       0.12      0.13      0.12     13551\n",
      "        ISTP       0.15      0.20      0.17     13551\n",
      "\n",
      "    accuracy                           0.13    216816\n",
      "   macro avg       0.13      0.13      0.12    216816\n",
      "weighted avg       0.13      0.13      0.12    216816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score: ', mynb.score(X_test_tfidf, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13693596740717964"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try Logistic Regression\n",
    "\n",
    "mylogit = LogisticRegression(max_iter=100)\n",
    "mylogit.fit(X_train_tfidf, y_train)\n",
    "mylogit.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Tuning\n",
    "\n",
    "I decide to manually tune C value for logistic regression to see if it will help with the accuracy... well, not really. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_value = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "test_scores = []\n",
    "\n",
    "for c in c_value:\n",
    "    mylogit=LogisticRegression(solver='saga',penalty='l2',C=c)\n",
    "    mylogit.fit(X_train_tfidf,y_train)\n",
    "    score = mylogit.score(X_test_tfidf, y_test)\n",
    "    \n",
    "    test_scores.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot out the test scores\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(c_value, test_scores)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick c value = 0.1, refit the model \n",
    "mylogit = LogisticRegression(solver='saga', penalty='l2', C=0.1)\n",
    "mylogit.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I try to fit the model on the test data set which I set aside, there are some errors which I haven't got time to figure out yet. That's for the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = df_test['comments_lemma']\n",
    "y_test_final = df_test['MBTI']\n",
    "\n",
    "X_test_final_tfidf = tfidfizer.transform(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 3 features per sample; expecting 1681",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9660132e31c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmylogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \"\"\"\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 262\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3 features per sample; expecting 1681"
     ]
    }
   ],
   "source": [
    "mylogit.score(X_test_final_tfidf, y_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it actually did worse than all the models before balancing the data. Now I have started to questioning myself... but I still want to try a GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch 2.0\n",
    "\n",
    "As I did before, I sampled a subset of the data to perform GridSearch. I made the judgement call to do that because of the time restraints at the time. I will need to review Hadoop and MapReduce to see if there are better ways to handle the parameter tuning/gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sample set of data and run GridSearch \n",
    "df_sample = df_resampled.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = df_sample['text']\n",
    "y_sample = df_sample['MBTI']\n",
    "\n",
    "X_sample_train, X_sample_test, y_sample_train, y_sample_test = train_test_split(X_sample, y_sample, test_size=0.3, random_state = 42, stratify=y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample_tfidf=tfidfizer.fit_transform(X_sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample_tfidf_test=tfidfizer.transform(X_sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 173 candidates, totalling 865 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 386 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 421 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 493 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 530 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 569 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 608 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 649 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done 761 out of 865 | elapsed:   44.7s remaining:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 848 out of 865 | elapsed:   51.8s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 865 out of 865 | elapsed:   54.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bestmodel_1210.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('model', LogisticRegression())])\n",
    "\n",
    "param_grid = [\n",
    "    # Logistic Regression\n",
    "    {'model':[LogisticRegression(solver='saga')],\n",
    "    'model__penalty':['l1','l2'], 'model__C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "    \n",
    "    # Random Forest\n",
    "    {'model':[RandomForestClassifier()],\n",
    "     'model__n_estimators': [50, 100, 150, 200], 'model__max_depth':[2, 5, 10, 15, 20]},\n",
    "    \n",
    "    # XG Boost\n",
    "    {'model':[XGBClassifier()], 'model__learning_rate': [0.1, 0.5, 1, 2],\n",
    "     'model__n_estimators': [50, 100, 150, 200], 'model__max_depth':[2, 5, 10, 15, 20]},\n",
    "    \n",
    "    # SGDClassfier\n",
    "    {'model':[SGDClassifier(loss='hinge',penalty='l2',random_state=42, max_iter=5, tol=None)],\n",
    "     'model__alpha': [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]},\n",
    "    \n",
    "    \n",
    "    # MLP Classifier - SKlearn's Neural Network \n",
    "    {'model':[MLPClassifier(solver='adam')], 'model__max_iter':[10, 50, 100, 150, 200],\n",
    "     'model__hidden_layer_sizes':[50, 100, 150, 200, 250, 300, 350, 400, 450, 500]},\n",
    "    \n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, verbose=10, n_jobs=-1)\n",
    "fittedgrid = grid.fit(X_sample_tfidf, y_sample_train)\n",
    "\n",
    "fittedgrid.score(X_sample_tfidf_test, y_sample_test)\n",
    "\n",
    "# Save the model \n",
    "joblib.dump(grid.best_estimator_, 'bestmodel_1210.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('model', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = pd.concat([pd.DataFrame(fittedgrid.cv_results_[\"params\"]),pd.DataFrame(fittedgrid.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1).sort_values(by='Accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model__C</th>\n",
       "      <th>model__alpha</th>\n",
       "      <th>model__hidden_layer_sizes</th>\n",
       "      <th>model__learning_rate</th>\n",
       "      <th>model__max_depth</th>\n",
       "      <th>model__max_iter</th>\n",
       "      <th>model__n_estimators</th>\n",
       "      <th>model__penalty</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.072857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.072857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.072857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.072857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model  model__C  \\\n",
       "15   LogisticRegression(C=100, class_weight=None, d...    1000.0   \n",
       "14   LogisticRegression(C=100, class_weight=None, d...    1000.0   \n",
       "13   LogisticRegression(C=100, class_weight=None, d...     100.0   \n",
       "12   LogisticRegression(C=100, class_weight=None, d...     100.0   \n",
       "10   LogisticRegression(C=100, class_weight=None, d...      10.0   \n",
       "11   LogisticRegression(C=100, class_weight=None, d...      10.0   \n",
       "8    LogisticRegression(C=100, class_weight=None, d...       1.0   \n",
       "9    LogisticRegression(C=100, class_weight=None, d...       1.0   \n",
       "128  MLPClassifier(activation='relu', alpha=0.0001,...       NaN   \n",
       "126  MLPClassifier(activation='relu', alpha=0.0001,...       NaN   \n",
       "\n",
       "     model__alpha  model__hidden_layer_sizes  model__learning_rate  \\\n",
       "15            NaN                        NaN                   NaN   \n",
       "14            NaN                        NaN                   NaN   \n",
       "13            NaN                        NaN                   NaN   \n",
       "12            NaN                        NaN                   NaN   \n",
       "10            NaN                        NaN                   NaN   \n",
       "11            NaN                        NaN                   NaN   \n",
       "8             NaN                        NaN                   NaN   \n",
       "9             NaN                        NaN                   NaN   \n",
       "128           NaN                      100.0                   NaN   \n",
       "126           NaN                       50.0                   NaN   \n",
       "\n",
       "     model__max_depth  model__max_iter  model__n_estimators model__penalty  \\\n",
       "15                NaN              NaN                  NaN             l2   \n",
       "14                NaN              NaN                  NaN             l1   \n",
       "13                NaN              NaN                  NaN             l2   \n",
       "12                NaN              NaN                  NaN             l1   \n",
       "10                NaN              NaN                  NaN             l1   \n",
       "11                NaN              NaN                  NaN             l2   \n",
       "8                 NaN              NaN                  NaN             l1   \n",
       "9                 NaN              NaN                  NaN             l2   \n",
       "128               NaN             10.0                  NaN            NaN   \n",
       "126               NaN            150.0                  NaN            NaN   \n",
       "\n",
       "     Accuracy  \n",
       "15   0.073000  \n",
       "14   0.073000  \n",
       "13   0.073000  \n",
       "12   0.073000  \n",
       "10   0.072857  \n",
       "11   0.072857  \n",
       "8    0.072857  \n",
       "9    0.072857  \n",
       "128  0.072571  \n",
       "126  0.072286  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are all so pretty bad...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 2 best models on complete set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:   20.4s remaining:   47.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   22.6s remaining:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  1.9min remaining:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bestmodel1210b.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 2 best models to form a new pipeline and fit to the train set - just try it out \n",
    "\n",
    "pipeline1 = Pipeline([('model', LogisticRegression())])\n",
    "\n",
    "param_grid1 = [\n",
    "    # Logistic Regression\n",
    "    {'model':[LogisticRegression(solver='saga', penalty='l2', C=1.0)]},\n",
    "    \n",
    "    # Random Forest\n",
    "    {'model':[RandomForestClassifier(n_estimators=50, max_depth=5)]},\n",
    "]\n",
    "\n",
    "grid1 = GridSearchCV(pipeline1, param_grid1, cv=5, verbose=10, n_jobs=-1)\n",
    "fittedgrid1 = grid1.fit(X_train_tfidf, y_train)\n",
    "\n",
    "fittedgrid1.score(X_test_tfidf, y_test)\n",
    "\n",
    "joblib.dump(fittedgrid1.best_estimator_, 'bestmodel1210b.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the model\n",
    "best_model = joblib.load('bestmodel1210b.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1374471519717119"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score\n",
    "score = best_model.score(X_test_tfidf, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.12      0.08      0.09     16261\n",
      "        ENFP       0.11      0.06      0.07     16261\n",
      "        ENTJ       0.11      0.07      0.08     16261\n",
      "        ENTP       0.13      0.08      0.10     16262\n",
      "        ESFJ       0.18      0.37      0.24     16261\n",
      "        ESFP       0.16      0.24      0.19     16261\n",
      "        ESTJ       0.17      0.27      0.21     16262\n",
      "        ESTP       0.14      0.16      0.15     16261\n",
      "        INFJ       0.11      0.05      0.07     16261\n",
      "        INFP       0.08      0.03      0.05     16261\n",
      "        INTJ       0.12      0.10      0.11     16262\n",
      "        INTP       0.08      0.11      0.10     16261\n",
      "        ISFJ       0.13      0.11      0.12     16262\n",
      "        ISFP       0.14      0.15      0.14     16261\n",
      "        ISTJ       0.11      0.11      0.11     16261\n",
      "        ISTP       0.15      0.20      0.18     16261\n",
      "\n",
      "   micro avg       0.14      0.14      0.14    260180\n",
      "   macro avg       0.13      0.14      0.13    260180\n",
      "weighted avg       0.13      0.14      0.13    260180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model from GridSearch did so bad, the average for the newly balanced set are all much worse than before. I think at this moment, I have come to the conclusion that downsampling is a bad idea! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: Facebook's FastText "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I heard FastText has a great classifier tool, so I want to give it a try. It actually gave the best result for the balanced dataset. I would definitely try to play with it on the original set when I got more AWS credits. You are welcome to skip this section and go straight to the Topic Modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/61/2e01f1397ec533756c1d893c22d9d5ed3fce3a6e4af1976e0d86bb13ea97/fasttext-0.9.1.tar.gz (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.3MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from fasttext) (2.4.3)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from fasttext) (39.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from fasttext) (1.17.4)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2113890 sha256=d357596b666ad8ffe106196bc93b22e96663ee9162475892fef0d403ed856efc\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/9f/f0/04/caa82c912aee89ce76358ff954f3f0729b7577c8ff23a292e3\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.9.1\n"
     ]
    }
   ],
   "source": [
    "! pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T18:04:04.445204Z",
     "start_time": "2019-12-08T18:04:04.375645Z"
    }
   },
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Convert the data to FastText format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled = pd.read_csv('resampled.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T18:45:10.659386Z",
     "start_time": "2019-12-08T18:45:10.354336Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert input file to FastText format: __label__ sentence 1\n",
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "col = ['MBTI', 'text']\n",
    "\n",
    "df_fasttext = df_resampled[col]\n",
    "df_fasttext['MBTI']=['__label__'+ s for s in df_fasttext['MBTI']]\n",
    "#data_sample['comments_lemma']= data_sample['comments_lemma'].replace('\\n',' ', regex=True).replace('\\t',' ', regex=True)\n",
    "df_fasttext.to_csv(r'fasttextsample.txt', index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T18:20:13.318856Z",
     "start_time": "2019-12-08T18:20:13.305798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__ENFJ</td>\n",
       "      <td>video like particular downvote show tutorial r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__ENFJ</td>\n",
       "      <td>tolkien middle earth book especially silnarill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__ENFJ</td>\n",
       "      <td>halfway inferno shut amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__ENFJ</td>\n",
       "      <td>must precise eye color green neutral l oreal p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__ENFJ</td>\n",
       "      <td>dunno expert acquisition work assume big role ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MBTI                                               text\n",
       "0  __label__ENFJ  video like particular downvote show tutorial r...\n",
       "1  __label__ENFJ  tolkien middle earth book especially silnarill...\n",
       "2  __label__ENFJ                       halfway inferno shut amazing\n",
       "3  __label__ENFJ  must precise eye color green neutral l oreal p...\n",
       "4  __label__ENFJ  dunno expert acquisition work assume big role ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fasttext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T18:20:16.258884Z",
     "start_time": "2019-12-08T18:20:16.247559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>867259</th>\n",
       "      <td>__label__ISTP</td>\n",
       "      <td>anthony taylor cunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867260</th>\n",
       "      <td>__label__ISTP</td>\n",
       "      <td>well pretty amazing understand completely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867261</th>\n",
       "      <td>__label__ISTP</td>\n",
       "      <td>also digital copy sure save often card get rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867262</th>\n",
       "      <td>__label__ISTP</td>\n",
       "      <td>weeaboo generally consider someone waaaaaay an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867263</th>\n",
       "      <td>__label__ISTP</td>\n",
       "      <td>yeah think could laugh easily people would mak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MBTI                                               text\n",
       "867259  __label__ISTP                                anthony taylor cunt\n",
       "867260  __label__ISTP          well pretty amazing understand completely\n",
       "867261  __label__ISTP  also digital copy sure save often card get rea...\n",
       "867262  __label__ISTP  weeaboo generally consider someone waaaaaay an...\n",
       "867263  __label__ISTP  yeah think could laugh easily people would mak..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fasttext.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T18:45:14.879057Z",
     "start_time": "2019-12-08T18:45:14.649938Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the data to two files\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_fasttext.text\n",
    "y = df_fasttext.MBTI\n",
    "\n",
    "X_rest, X_test, y_rest, y_test = train_test_split(X, y, test_size = 0.3, stratify = y, random_state = 42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_rest, y_rest, test_size = 0.3, stratify=y_rest, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T18:45:17.327831Z",
     "start_time": "2019-12-08T18:45:16.970750Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis = 1)\n",
    "valid_df = pd.concat([y_valid, X_valid], axis = 1)\n",
    "test_df = pd.concat([y_test, X_test], axis = 1)\n",
    "train_df.to_csv(r'fasttextsample_train.txt', index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "valid_df.to_csv(r'fasttextsample_valid.txt', index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "test_df.to_csv(r'fasttextsample_test.txt', index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the data into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T18:54:53.627783Z",
     "start_time": "2019-12-08T18:50:31.608791Z"
    }
   },
   "outputs": [],
   "source": [
    "#  train the model \n",
    "# adjust epochs\n",
    "epochs = range(1,51)\n",
    "test_scores = []\n",
    "\n",
    "for epoch in epochs: \n",
    "    model = fasttext.train_supervised(input='fasttextsample_train.txt', epoch = epoch, lr= 1.0, \n",
    "                                      wordNgrams = 2, bucket = 200000, dim=50, loss='hs')\n",
    "    score = model.test('fasttextsample_valid.txt')[1]\n",
    "    test_scores.append(score)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T18:56:31.467072Z",
     "start_time": "2019-12-08T18:56:31.248650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs, test_scores)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1428900870825692,\n",
       " 0.16335943248081,\n",
       " 0.17308896039005964,\n",
       " 0.17230378968406487,\n",
       " 0.17713560941326334,\n",
       " 0.17590569166401282,\n",
       " 0.15999912148732195,\n",
       " 0.16721939755993104,\n",
       " 0.15287218738675423,\n",
       " 0.10632199685931717,\n",
       " 0.1698549355940393,\n",
       " 0.1558536397878392,\n",
       " 0.16924546742365176,\n",
       " 0.1258524318329069,\n",
       " 0.1314200059299606,\n",
       " 0.1276808363440695,\n",
       " 0.13888187298902957,\n",
       " 0.1452510899047912,\n",
       " 0.1494679507593644,\n",
       " 0.14694771751424837,\n",
       " 0.1528666966825165,\n",
       " 0.14942951582970032,\n",
       " 0.15343223921900223,\n",
       " 0.15250980090706434,\n",
       " 0.15208701668075947,\n",
       " 0.1567760780997771,\n",
       " 0.1571933716218442,\n",
       " 0.15721533443879512,\n",
       " 0.15894490627367866,\n",
       " 0.15848917782194744,\n",
       " 0.1517685558349714,\n",
       " 0.1555736138717152,\n",
       " 0.14730461328970054,\n",
       " 0.14677201497864117,\n",
       " 0.15348165555714177,\n",
       " 0.15524417161745166,\n",
       " 0.14866081723641875,\n",
       " 0.152476856681638,\n",
       " 0.14713989216256876,\n",
       " 0.15973007697967342,\n",
       " 0.1516422696375037,\n",
       " 0.1409903034163162,\n",
       " 0.16176163754763187,\n",
       " 0.14592644652603143,\n",
       " 0.15694079922690884,\n",
       " 0.15117555977729705,\n",
       " 0.15001702118313695,\n",
       " 0.16104784599672753,\n",
       " 0.14416393046572154,\n",
       " 0.1624973919154871]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T18:59:46.009585Z",
     "start_time": "2019-12-08T18:59:39.335678Z"
    }
   },
   "outputs": [],
   "source": [
    "# adjust learning rate\n",
    "\n",
    "learning_rates = np.arange(0.1,1.0,0.1)\n",
    "test_scores1 = []\n",
    "\n",
    "for learning_rate in learning_rates: \n",
    "    model = fasttext.train_supervised(input='fasttextsample_train.txt', epoch = 5, lr= learning_rate, \n",
    "                                      wordNgrams = 2, bucket = 200000, dim=50, loss='hs')\n",
    "    score = model.test('fasttextsample_valid.txt')[1]\n",
    "    test_scores1.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T19:00:02.998966Z",
     "start_time": "2019-12-08T19:00:02.739527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(learning_rates, test_scores1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18838606239636296,\n",
       " 0.19127966352964432,\n",
       " 0.19140045902287428,\n",
       " 0.18757892887341732,\n",
       " 0.18717810746406335,\n",
       " 0.18582190351734512,\n",
       " 0.1856626730944511,\n",
       " 0.18413076661212568,\n",
       " 0.182823979003547]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T19:02:04.357495Z",
     "start_time": "2019-12-08T19:02:03.568789Z"
    }
   },
   "outputs": [],
   "source": [
    "# final model \n",
    "model = fasttext.train_supervised(input='fasttextsample_train.txt', epoch = 5, lr= 0.3, \n",
    "                                      wordNgrams = 2, bucket = 200000, dim=50, loss='hs')\n",
    "# save the model \n",
    "model.save_model('fasttext_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T19:02:34.462712Z",
     "start_time": "2019-12-08T19:02:34.279479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260180, 0.1900799446537013, 0.1900799446537013)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on test set \n",
    "model.test('fasttextsample_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Topic Modelling with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:20:53.027498Z",
     "start_time": "2019-12-10T00:20:53.015410Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps: \n",
    "1. Import the data\n",
    "2. Lemmatize the data & remove stop words\n",
    "3. Create dictionary and corpus \n",
    "4. train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dictionary \n",
    "\n",
    "I picked two contrast personalties for topic modelling. I want to see if these people do talk about different topics online or they actually are interested in the same issues. Because the personalities are all self-identified, so it is also a way to see how accurate the personality types reflect their online interest/behaviours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:20:57.577142Z",
     "start_time": "2019-12-10T00:20:57.397741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate a df ESFJ & INTP for LDA topic modelling\n",
    "df_esfj = df_resampled[df_resampled['MBTI']=='ESFJ']\n",
    "df_intp = df_resampled[df_resampled['MBTI']=='INTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esfj = pd.read_csv('df_esfj.csv',index_col=0)\n",
    "df_intp = pd.read_csv('df_intp.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:20:59.753750Z",
     "start_time": "2019-12-10T00:20:59.746970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESFJ: (54204, 2)\n",
      "INTP: (54204, 2)\n"
     ]
    }
   ],
   "source": [
    "print('ESFJ:', df_esfj.shape)\n",
    "print('INTP:', df_intp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:21:25.067148Z",
     "start_time": "2019-12-10T00:21:25.051043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>MBTI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216816</th>\n",
       "      <td>enjoy ridiculous article affordable watch one ...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216817</th>\n",
       "      <td>yup exactly story grow mom would cook one mayb...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216818</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216819</th>\n",
       "      <td>wow time change back release match ghz believe...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216820</th>\n",
       "      <td>annoy want keep reading journal</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216821</th>\n",
       "      <td>would go around northeast usa visit big city</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216822</th>\n",
       "      <td>lewis write bit believe screwtape letters some...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216823</th>\n",
       "      <td>would runaway groom anything</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216824</th>\n",
       "      <td>refuse work chrome work fine safari</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216825</th>\n",
       "      <td>part reason one kid everyone else around like ...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216826</th>\n",
       "      <td>see could color class officer one point go gym...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216827</th>\n",
       "      <td>currently work grad school stuff make feel lik...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216828</th>\n",
       "      <td>esfj totally hit hurt jerk sorry mean come let...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216829</th>\n",
       "      <td>yes fail pursue friend want try win heart allow</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216830</th>\n",
       "      <td>heelllllllloooooo</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216831</th>\n",
       "      <td>week friend post picture kid rarely enough wan...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216832</th>\n",
       "      <td>anything burroughs write dozen tarzan book lea...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216833</th>\n",
       "      <td>absolutely amazing happy long</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216834</th>\n",
       "      <td>wake get ready camp good friend come watch jeo...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216835</th>\n",
       "      <td>personally find one say gold ugly look like pu...</td>\n",
       "      <td>ESFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  MBTI\n",
       "216816  enjoy ridiculous article affordable watch one ...  ESFJ\n",
       "216817  yup exactly story grow mom would cook one mayb...  ESFJ\n",
       "216818                                      unfortunately  ESFJ\n",
       "216819  wow time change back release match ghz believe...  ESFJ\n",
       "216820                    annoy want keep reading journal  ESFJ\n",
       "216821       would go around northeast usa visit big city  ESFJ\n",
       "216822  lewis write bit believe screwtape letters some...  ESFJ\n",
       "216823                       would runaway groom anything  ESFJ\n",
       "216824                refuse work chrome work fine safari  ESFJ\n",
       "216825  part reason one kid everyone else around like ...  ESFJ\n",
       "216826  see could color class officer one point go gym...  ESFJ\n",
       "216827  currently work grad school stuff make feel lik...  ESFJ\n",
       "216828  esfj totally hit hurt jerk sorry mean come let...  ESFJ\n",
       "216829    yes fail pursue friend want try win heart allow  ESFJ\n",
       "216830                                  heelllllllloooooo  ESFJ\n",
       "216831  week friend post picture kid rarely enough wan...  ESFJ\n",
       "216832  anything burroughs write dozen tarzan book lea...  ESFJ\n",
       "216833                      absolutely amazing happy long  ESFJ\n",
       "216834  wake get ready camp good friend come watch jeo...  ESFJ\n",
       "216835  personally find one say gold ugly look like pu...  ESFJ"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_esfj.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:25:17.438231Z",
     "start_time": "2019-12-10T00:25:17.426816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>MBTI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>596244</th>\n",
       "      <td>hear amd car driver crash</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596245</th>\n",
       "      <td>one sell tomato grocery store</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596246</th>\n",
       "      <td>nox definitely nox</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596247</th>\n",
       "      <td>yeah well fuck</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596248</th>\n",
       "      <td>society value man primarily base successful pe...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596249</th>\n",
       "      <td>tell anything would convey experience taste so...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596250</th>\n",
       "      <td>fair never actually house mate room mate live ...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596251</th>\n",
       "      <td>extremely entj maybe estp like season master s...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596252</th>\n",
       "      <td>want buy preyta seem really mana hungry right ...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596253</th>\n",
       "      <td>georgeous lt</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596254</th>\n",
       "      <td>many point twilight could brilliant though per...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596255</th>\n",
       "      <td>sorry know tell good selling guess could wrong...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596256</th>\n",
       "      <td>legitimate question legitimate point trolling ...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596257</th>\n",
       "      <td>man would kill tax live kommifornia think go p...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596258</th>\n",
       "      <td>hey dunkle play leah guy sound like hank hill ...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596259</th>\n",
       "      <td>sweden pretty terrifyingly broken country top ...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596260</th>\n",
       "      <td>claim tenable hide variable interpretation cla...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596261</th>\n",
       "      <td>remember matter could win without</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596262</th>\n",
       "      <td>really think fictional character personality type</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596263</th>\n",
       "      <td>say look nice allow nerd monastery anyways loo...</td>\n",
       "      <td>INTP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  MBTI\n",
       "596244                          hear amd car driver crash  INTP\n",
       "596245                      one sell tomato grocery store  INTP\n",
       "596246                                 nox definitely nox  INTP\n",
       "596247                                     yeah well fuck  INTP\n",
       "596248  society value man primarily base successful pe...  INTP\n",
       "596249  tell anything would convey experience taste so...  INTP\n",
       "596250  fair never actually house mate room mate live ...  INTP\n",
       "596251  extremely entj maybe estp like season master s...  INTP\n",
       "596252  want buy preyta seem really mana hungry right ...  INTP\n",
       "596253                                       georgeous lt  INTP\n",
       "596254  many point twilight could brilliant though per...  INTP\n",
       "596255  sorry know tell good selling guess could wrong...  INTP\n",
       "596256  legitimate question legitimate point trolling ...  INTP\n",
       "596257  man would kill tax live kommifornia think go p...  INTP\n",
       "596258  hey dunkle play leah guy sound like hank hill ...  INTP\n",
       "596259  sweden pretty terrifyingly broken country top ...  INTP\n",
       "596260  claim tenable hide variable interpretation cla...  INTP\n",
       "596261                  remember matter could win without  INTP\n",
       "596262  really think fictional character personality type  INTP\n",
       "596263  say look nice allow nerd monastery anyways loo...  INTP"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intp.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:27:37.119595Z",
     "start_time": "2019-12-10T00:27:31.309710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(30936 unique tokens: ['affordable', 'article', 'enjoy', 'gaudy', 'gold']...)\n",
      "Dictionary(53175 unique tokens: ['amd', 'car', 'crash', 'driver', 'hear']...)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# How to create a dictionary from a list of sentences\n",
    "documents_esfj = df_esfj['text'].tolist( )\n",
    "documents_intp = df_intp['text'].tolist( )\n",
    "\n",
    "\n",
    "# Tokenize(split) the sentences into words\n",
    "texts_esfj = [[text for text in doc.split()] for doc in documents_esfj]\n",
    "texts_intp = [[text for text in doc.split()] for doc in documents_intp]\n",
    "\n",
    "# Create dictionary\n",
    "dictionary_esfj = corpora.Dictionary(texts_esfj)\n",
    "dictionary_intp = corpora.Dictionary(texts_intp)\n",
    "\n",
    "\n",
    "# Get information about the dictionary\n",
    "print(dictionary_esfj)\n",
    "print(dictionary_intp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:33:07.292948Z",
     "start_time": "2019-12-10T00:33:01.513647Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the Corpus\n",
    "corpus_esfj = [dictionary_esfj.doc2bow(doc, allow_update=True) for doc in texts_esfj]\n",
    "corpus_intp = [dictionary_intp.doc2bow(doc, allow_update=True) for doc in texts_intp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:35:17.652254Z",
     "start_time": "2019-12-10T00:35:15.685876Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESFJ examples:  [[('affordable', 1), ('article', 1), ('enjoy', 1), ('gaudy', 1), ('gold', 1), ('one', 1), ('ridiculous', 1), ('watch', 1)], [('one', 3), ('watch', 1), ('actually', 1), ('ask', 1), ('away', 2), ('bet', 1), ('big', 1), ('boil', 1), ('bowl', 1), ('busy', 1), ('cook', 1), ('corn', 3), ('could', 2), ('country', 1), ('ear', 1), ('eat', 1), ('exactly', 1), ('first', 1), ('four', 1), ('front', 1), ('give', 1), ('go', 1), ('good', 1), ('grain', 1), ('grow', 2), ('handle', 1), ('happen', 1), ('hear', 1), ('horrify', 1), ('insult', 1), ('keep', 1), ('later', 1), ('leave', 1), ('leftover', 3), ('look', 1), ('maybe', 1), ('meal', 1), ('mom', 2), ('per', 1), ('puzzled', 1), ('really', 1), ('rest', 1), ('rice', 1), ('roommate', 1), ('see', 2), ('shocked', 1), ('starve', 1), ('story', 1), ('third', 1), ('throw', 2), ('time', 1), ('turn', 1), ('two', 1), ('week', 2), ('work', 2), ('world', 1), ('would', 3), ('yup', 1)], [('unfortunately', 1)], [('give', 1), ('time', 1), ('amd', 1), ('back', 1), ('beat', 1), ('believe', 1), ('change', 1), ('clock', 1), ('editon', 1), ('ghz', 2), ('guess', 1), ('help', 1), ('high', 1), ('match', 1), ('nvidia', 1), ('overclocke', 1), ('probably', 1), ('rebrand', 1), ('rebrande', 1), ('release', 1), ('slightly', 2), ('strong', 1), ('support', 1), ('ton', 1), ('wow', 1), ('x', 2), ('year', 1)], [('keep', 1), ('annoy', 1), ('journal', 1), ('reading', 1), ('want', 1)]]\n",
      "INTP examples: [[('amd', 1), ('car', 1), ('crash', 1), ('driver', 1), ('hear', 1)], [('grocery', 1), ('one', 1), ('sell', 1), ('store', 1), ('tomato', 1)], [('definitely', 1), ('nox', 2)], [('fuck', 1), ('well', 1), ('yeah', 1)], [('accomplish', 1), ('advancement', 1), ('also', 1), ('anything', 1), ('base', 1), ('become', 1), ('big', 1), ('career', 1), ('caveat', 1), ('early', 1), ('establish', 1), ('family', 1), ('field', 1), ('figure', 1), ('gain', 1), ('get', 1), ('kid', 1), ('life', 1), ('look', 1), ('magical', 1), ('man', 1), ('meanwhile', 1), ('much', 1), ('number', 1), ('people', 1), ('primarily', 1), ('professional', 1), ('raise', 1), ('relatively', 1), ('safe', 1), ('settle', 2), ('society', 1), ('still', 1), ('success', 1), ('successful', 2), ('suddenly', 1), ('take', 1), ('term', 1), ('time', 1), ('usually', 1), ('value', 2), ('want', 2), ('willing', 1), ('woman', 1), ('year', 1)]]\n"
     ]
    }
   ],
   "source": [
    "# print out the word count of first 6 comments\n",
    "word_counts_esfj = [[(dictionary_esfj[id], count) for id, count in line] for line in corpus_esfj]\n",
    "word_counts_intp = [[(dictionary_intp[id], count) for id, count in line] for line in corpus_intp]\n",
    "\n",
    "print('ESFJ examples: ', word_counts_esfj[:5])\n",
    "\n",
    "print('INTP examples:', word_counts_intp[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Dictionary and Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:37:23.575976Z",
     "start_time": "2019-12-10T00:37:18.227148Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the Dict and Corpus\n",
    "dictionary_esfj.save('dictionary_esfj.dict')\n",
    "dictionary_intp.save('dictionary_intp.dict')\n",
    "\n",
    "corpora.MmCorpus.serialize('corpus_esfj.mm', corpus_esfj)\n",
    "corpora.MmCorpus.serialize('corpus_intp.mm', corpus_intp)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:40:48.722685Z",
     "start_time": "2019-12-10T00:40:47.798835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['affordable', 0.44], ['article', 0.31], ['enjoy', 0.23], ['gaudy', 0.6], ['gold', 0.34], ['one', 0.11], ['ridiculous', 0.36], ['watch', 0.21]]\n",
      "[['amd', 0.57], ['car', 0.37], ['crash', 0.48], ['driver', 0.46], ['hear', 0.31]]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "# Create the TF-IDF model\n",
    "tfidf_esfj = models.TfidfModel(corpus_esfj, smartirs='ntc')\n",
    "tfidf_intp = models.TfidfModel(corpus_intp, smartirs='ntc')\n",
    "\n",
    "# Show the TF-IDF weights of the first lines of ESFJ and INTP\n",
    "for doc in tfidf_esfj[corpus_esfj[:1]]:\n",
    "    print([[dictionary_esfj[id], np.around(freq, decimals=2)] for id, freq in doc])\n",
    "\n",
    "for doc in tfidf_intp[corpus_intp[:1]]:\n",
    "    print([[dictionary_intp[id], np.around(freq, decimals=2)] for id, freq in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-grams and Tri-grams\n",
    "\n",
    "#### Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T00:54:02.836268Z",
     "start_time": "2019-12-10T00:53:32.902429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annoy', 'want', 'keep', 'reading_journal']\n",
      "['society', 'value', 'man', 'primarily_base', 'successful', 'people', 'accomplish_much', 'term', 'career_success', 'big', 'year', 'professional_advancement', 'also', 'gain', 'value', 'meanwhile_woman', 'look', 'settle', 'raise_family', 'usually', 'want', 'early', 'still', 'relatively', 'safe', 'kid', 'willing_settle', 'caveat', 'magical', 'number', 'anything', 'life', 'suddenly_become', 'successful', 'figure', 'want', 'get', 'establish', 'field', 'take', 'time']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "\n",
    "# remove double and leading space \n",
    "# dataset = [re.sub(' +', ' ', wd) for wd in dataset]\n",
    "# dataset = [wd.lstrip(' ') for wd in dataset]\n",
    "\n",
    "# split the sentences \n",
    "sentence_esfj = [doc.split(' ') for doc in documents_esfj]\n",
    "sentence_intp = [doc.split(' ') for doc in documents_intp]\n",
    "\n",
    "# Build the bigram models\n",
    "bigram_esfj = Phrases(sentence_esfj, min_count=1, threshold=10)\n",
    "bigram_intp = Phrases(sentence_intp, min_count=1, threshold=10)\n",
    "\n",
    "# faster way to get a sentene clubbed as a bigram\n",
    "bigram_model_esfj = gensim.models.phrases.Phraser(bigram_esfj)\n",
    "bigram_model_intp = gensim.models.phrases.Phraser(bigram_intp)\n",
    "\n",
    "# try on a sentence\n",
    "sent_esfj = sentence_esfj[4]\n",
    "sent_intp = sentence_intp[4]\n",
    "\n",
    "# try bigrammodel\n",
    "print(bigram_model_esfj[sent_esfj])\n",
    "print(bigram_model_intp[sent_intp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tri-grams\n",
    "\n",
    "Unfortunately in this case, I didn't find any trigrams..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:00:06.760891Z",
     "start_time": "2019-12-10T00:59:44.551580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annoy', 'want', 'keep', 'reading_journal']\n",
      "['society', 'value', 'man', 'primarily_base', 'successful', 'people', 'accomplish_much', 'term', 'career_success', 'big', 'year', 'professional_advancement', 'also', 'gain', 'value', 'meanwhile_woman', 'look', 'settle', 'raise_family', 'usually', 'want', 'early', 'still', 'relatively', 'safe', 'kid', 'willing_settle', 'caveat', 'magical', 'number', 'anything', 'life', 'suddenly_become', 'successful', 'figure', 'want', 'get', 'establish', 'field', 'take', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Build the trigram models - try to see if there is any \n",
    "trigram_esfj = Phrases(bigram_esfj[sentence_esfj], threshold=10)\n",
    "trigram_intp = Phrases(bigram_intp[sentence_esfj], threshold=10)\n",
    "\n",
    "# Construct trigram\n",
    "print(trigram_esfj[bigram_esfj[sent_esfj]])\n",
    "print(trigram_intp[bigram_intp[sent_intp]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling \n",
    "\n",
    "#### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:08:24.374484Z",
     "start_time": "2019-12-10T01:08:24.362791Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel, LdaMulticore\n",
    "import gensim.downloader as api\n",
    "from gensim.utils import simple_preprocess, lemmatize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop = ['to', 'of', 'the', 'be', 'for', 'that', 'do', 'have', 'this', 'and']\n",
    "stop_words = stop_words + stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T23:36:50.432579Z",
     "start_time": "2019-12-07T23:36:50.428260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'to', 'of', 'the', 'be', 'for', 'that', 'do', 'have', 'this', 'and']\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:03:44.242882Z",
     "start_time": "2019-12-10T01:03:33.881154Z"
    }
   },
   "outputs": [],
   "source": [
    "# create bi-grams\n",
    "processed_bigram_esfj = [bigram_model_esfj[doc] for doc in sentence_esfj]\n",
    "processed_bigram_intp = [bigram_model_intp[doc] for doc in sentence_intp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:04:51.420422Z",
     "start_time": "2019-12-10T01:04:51.415785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['enjoy', 'ridiculous', 'article', 'affordable', 'watch', 'one', 'gaudy', 'gold'], ['yup_exactly', 'story', 'grow', 'mom', 'would', 'cook', 'one', 'maybe', 'two', 'big', 'meal_per', 'week', 'would', 'work', 'leftover_rest', 'week', 'busy', 'work', 'mom', 'grow_starve', 'third', 'world', 'country', 'leave', 'one', 'grain_rice', 'bowl_bet', 'would', 'hear', 'later', 'see', 'shocked_horrify', 'see', 'insult_leftover', 'happen', 'front', 'first', 'time', 'roommate_boil', 'four_ear', 'corn_eat', 'one', 'go', 'throw_away', 'actually', 'ask', 'could', 'keep_leftover', 'corn', 'could_handle', 'watch', 'throw_away', 'look_puzzled', 'give', 'turn', 'really', 'good', 'corn'], ['unfortunately'], ['wow', 'time', 'change', 'back', 'release', 'match_ghz', 'believe', 'slightly', 'strong', 'x_x', 'slightly_overclocke', 'clock', 'high_ghz', 'editon_beat', 'rebrand_guess', 'year_amd', 'give', 'support_nvidia', 'probably', 'help_rebrande', 'ton'], ['annoy', 'want', 'keep', 'reading_journal']]\n",
      "[['hear', 'amd', 'car', 'driver_crash'], ['one', 'sell', 'tomato', 'grocery_store'], ['nox', 'definitely', 'nox'], ['yeah', 'well', 'fuck'], ['society', 'value', 'man', 'primarily_base', 'successful', 'people', 'accomplish_much', 'term', 'career_success', 'big', 'year', 'professional_advancement', 'also', 'gain', 'value', 'meanwhile_woman', 'look', 'settle', 'raise_family', 'usually', 'want', 'early', 'still', 'relatively', 'safe', 'kid', 'willing_settle', 'caveat', 'magical', 'number', 'anything', 'life', 'suddenly_become', 'successful', 'figure', 'want', 'get', 'establish', 'field', 'take', 'time']]\n"
     ]
    }
   ],
   "source": [
    "# see the examples \n",
    "print(processed_bigram_esfj[:5])\n",
    "print(processed_bigram_intp[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:07:34.489356Z",
     "start_time": "2019-12-10T01:07:26.473050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Create the Inputs of LDA model: Dictionary and Corpus\n",
    "dct_esfj = corpora.Dictionary(processed_bigram_esfj)\n",
    "dct_intp = corpora.Dictionary(processed_bigram_intp)\n",
    "\n",
    "corp_esfj = [dct_esfj.doc2bow(line) for line in processed_bigram_esfj]\n",
    "corp_intp = [dct_intp.doc2bow(line) for line in processed_bigram_intp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:41:23.360046Z",
     "start_time": "2019-12-10T01:37:14.888718Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-74:\n",
      "Process ForkPoolWorker-62:\n",
      "Process ForkPoolWorker-76:\n",
      "Process ForkPoolWorker-89:\n",
      "Process ForkPoolWorker-67:\n",
      "Process ForkPoolWorker-81:\n",
      "Process ForkPoolWorker-77:\n",
      "Process ForkPoolWorker-93:\n",
      "Process ForkPoolWorker-65:\n",
      "Process ForkPoolWorker-87:\n",
      "Process ForkPoolWorker-57:\n",
      "Process ForkPoolWorker-79:\n",
      "Process ForkPoolWorker-95:\n",
      "Process ForkPoolWorker-66:\n",
      "Process ForkPoolWorker-78:\n",
      "Process ForkPoolWorker-91:\n",
      "Process ForkPoolWorker-63:\n",
      "Process ForkPoolWorker-73:\n",
      "Process ForkPoolWorker-84:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-7866184ddd91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                          \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                          \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                          per_word_topics=True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \"\"\"\n\u001b[1;32m    267\u001b[0m             \u001b[0mmerged_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mempty\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-68:\n",
      "Process ForkPoolWorker-64:\n",
      "Process ForkPoolWorker-60:\n",
      "Process ForkPoolWorker-82:\n",
      "Process ForkPoolWorker-92:\n",
      "Process ForkPoolWorker-58:\n",
      "Process ForkPoolWorker-88:\n",
      "Process ForkPoolWorker-83:\n",
      "Process ForkPoolWorker-86:\n",
      "Process ForkPoolWorker-85:\n",
      "Process ForkPoolWorker-90:\n",
      "Process ForkPoolWorker-56:\n",
      "Process ForkPoolWorker-75:\n",
      "Process ForkPoolWorker-61:\n",
      "Process ForkPoolWorker-94:\n",
      "Process ForkPoolWorker-80:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "Process ForkPoolWorker-69:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-70:\n",
      "Process ForkPoolWorker-72:\n",
      "Process ForkPoolWorker-71:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/gensim/models/ldamulticore.py\", line 334, in worker_e_step\n",
      "    chunk_no, chunk, worker_lda = input_queue.get()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# train the model \n",
    "# Step 4: Train the LDA model\n",
    "lda_model_esfj = LdaMulticore(corpus=corp_esfj,\n",
    "                         id2word=dct_esfj,\n",
    "                         random_state=100,\n",
    "                         num_topics=10,\n",
    "                         passes=10,\n",
    "                         chunksize=1000,\n",
    "                         batch=False,\n",
    "                         alpha='asymmetric',\n",
    "                         decay=0.5,\n",
    "                         offset=64,\n",
    "                         eta=None,\n",
    "                         eval_every=0,\n",
    "                         iterations=100,\n",
    "                         gamma_threshold=0.001,\n",
    "                         per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:45:15.960123Z",
     "start_time": "2019-12-10T01:41:23.366193Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model_intp = LdaMulticore(corpus=corp_intp,\n",
    "                         id2word=dct_intp,\n",
    "                         random_state=100,\n",
    "                         num_topics=10,\n",
    "                         passes=10,\n",
    "                         chunksize=1000,\n",
    "                         batch=False,\n",
    "                         alpha='asymmetric',\n",
    "                         decay=0.5,\n",
    "                         offset=64,\n",
    "                         eta=None,\n",
    "                         eval_every=0,\n",
    "                         iterations=100,\n",
    "                         gamma_threshold=0.001,\n",
    "                         per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:47:49.636738Z",
     "start_time": "2019-12-10T01:47:49.442028Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"url\" + 0.013*\"thank\" + 0.010*\"one\" + 0.010*\"good\" + 0.009*\"love\" + 0.008*\"like\" + 0.007*\"look\" + 0.007*\"get\" + 0.005*\"go\" + 0.005*\"make\"'),\n",
       " (1,\n",
       "  '0.018*\"like\" + 0.017*\"get\" + 0.016*\"would\" + 0.013*\"think\" + 0.013*\"people\" + 0.012*\"go\" + 0.010*\"really\" + 0.010*\"know\" + 0.010*\"one\" + 0.009*\"make\"'),\n",
       " (2,\n",
       "  '0.003*\"decant_available\" + 0.002*\"uconn\" + 0.002*\"function\" + 0.002*\"look\" + 0.002*\"ice_cream\" + 0.001*\"tooth\" + 0.001*\"decant\" + 0.001*\"true\" + 0.001*\"fruit\" + 0.001*\"work\"'),\n",
       " (3,\n",
       "  '0.011*\"funner_funner\" + 0.003*\"disorder\" + 0.002*\"url_wiki\" + 0.002*\"isfp\" + 0.002*\"url\" + 0.002*\"makeupaddiction\" + 0.002*\"personality_disorder\" + 0.001*\"king_landing\" + 0.001*\"double_major\" + 0.001*\"borderline_personality\"'),\n",
       " (4,\n",
       "  '0.047*\"color\" + 0.021*\"look\" + 0.020*\"see\" + 0.015*\"blue\" + 0.015*\"red\" + 0.015*\"green\" + 0.013*\"white\" + 0.013*\"black\" + 0.010*\"light\" + 0.007*\"yellow\"'),\n",
       " (5,\n",
       "  '0.003*\"use\" + 0.002*\"get\" + 0.001*\"truth\" + 0.001*\"point\" + 0.001*\"sansa\" + 0.001*\"treatment\" + 0.001*\"fact\" + 0.001*\"two\" + 0.001*\"awful\" + 0.001*\"jaime\"'),\n",
       " (6,\n",
       "  '0.008*\"spell\" + 0.005*\"cleric\" + 0.003*\"dae_dae\" + 0.003*\"ability\" + 0.003*\"flower\" + 0.002*\"woman\" + 0.002*\"migraine\" + 0.002*\"need\" + 0.002*\"play\" + 0.002*\"wizard\"'),\n",
       " (7,\n",
       "  '0.007*\"people\" + 0.003*\"thing\" + 0.003*\"look\" + 0.002*\"trans_people\" + 0.002*\"url\" + 0.002*\"find\" + 0.002*\"even\" + 0.002*\"kaitlyn\" + 0.002*\"country\" + 0.002*\"mental_illness\"'),\n",
       " (8,\n",
       "  '0.002*\"boston\" + 0.002*\"exam\" + 0.001*\"copy\" + 0.001*\"almond\" + 0.001*\"wear_glass\" + 0.001*\"full_attack\" + 0.001*\"mouse\" + 0.001*\"diet\" + 0.001*\"country_music\" + 0.001*\"melee\"'),\n",
       " (9,\n",
       "  '0.012*\"phone\" + 0.006*\"moto\" + 0.004*\"may\" + 0.003*\"amp_x\" + 0.002*\"nexus\" + 0.002*\"also\" + 0.002*\"look\" + 0.001*\"issue\" + 0.001*\"furthermore\" + 0.001*\"thank_info\"')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "lda_model_esfj.save('lda_model_esfj.model')\n",
    "lda_model_intp.save('lda_model_intp.model')\n",
    "\n",
    "# See the topics\n",
    "lda_model_esfj.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:47:55.233249Z",
     "start_time": "2019-12-10T01:47:55.216232Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"would\" + 0.011*\"get\" + 0.010*\"like\" + 0.010*\"think\" + 0.010*\"people\" + 0.009*\"one\" + 0.008*\"make\" + 0.008*\"go\" + 0.008*\"say\" + 0.007*\"know\"'),\n",
       " (1,\n",
       "  '0.044*\"url\" + 0.019*\"thank\" + 0.008*\"lol\" + 0.007*\"yes\" + 0.006*\"gt\" + 0.006*\"look_like\" + 0.006*\"fuck\" + 0.005*\"cat\" + 0.005*\"jpg\" + 0.005*\"man\"'),\n",
       " (2,\n",
       "  '0.010*\"team\" + 0.007*\"play\" + 0.005*\"game\" + 0.004*\"like\" + 0.004*\"k\" + 0.004*\"win\" + 0.003*\"player\" + 0.003*\"gt\" + 0.003*\"think\" + 0.003*\"make\"'),\n",
       " (3,\n",
       "  '0.004*\"rape_drug\" + 0.004*\"ghb_date\" + 0.003*\"alright_alright\" + 0.003*\"hello\" + 0.002*\"shitpost\" + 0.002*\"ftfy\" + 0.002*\"holy_fuck\" + 0.002*\"ubuntu\" + 0.002*\"b\" + 0.002*\"der\"'),\n",
       " (4,\n",
       "  '0.012*\"nope\" + 0.005*\"entj\" + 0.005*\"esfp\" + 0.004*\"esfj\" + 0.004*\"estp\" + 0.004*\"w\" + 0.004*\"isfj\" + 0.004*\"irl\" + 0.003*\"isfp\" + 0.002*\"estj\"'),\n",
       " (5,\n",
       "  '0.005*\"horse\" + 0.005*\"welcome\" + 0.004*\"zip_gt\" + 0.003*\"gif\" + 0.003*\"ca\" + 0.003*\"rar_gt\" + 0.002*\"pony\" + 0.002*\"cum\" + 0.002*\"logo\" + 0.002*\"ebook\"'),\n",
       " (6,\n",
       "  '0.014*\"v\" + 0.012*\"url_watch\" + 0.008*\"l\" + 0.008*\"c_est\" + 0.007*\"que\" + 0.005*\"c\" + 0.005*\"les\" + 0.005*\"pas\" + 0.005*\"j_ai\" + 0.004*\"des\"'),\n",
       " (7,\n",
       "  '0.004*\"dat\" + 0.004*\"van\" + 0.003*\"wizard\" + 0.003*\"url_user\" + 0.003*\"url_channel\" + 0.002*\"die\" + 0.002*\"het\" + 0.002*\"euro\" + 0.002*\"satan\" + 0.002*\"hearthstone\"'),\n",
       " (8,\n",
       "  '0.003*\"cake\" + 0.003*\"mspapplebloom_spin\" + 0.003*\"b_cc\" + 0.002*\"chocolate\" + 0.002*\"amp\" + 0.002*\"namespace\" + 0.002*\"c\" + 0.002*\"use_namespace\" + 0.002*\"std\" + 0.001*\"std_min\"'),\n",
       " (9,\n",
       "  '0.004*\"card\" + 0.004*\"armor\" + 0.004*\"sword\" + 0.003*\"tier\" + 0.003*\"blade\" + 0.003*\"island\" + 0.002*\"board\" + 0.002*\"gpu\" + 0.002*\"adorable\" + 0.002*\"battery\"')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_intp.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:54:08.583192Z",
     "start_time": "2019-12-10T01:53:49.999683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.344*\"like\" + 0.281*\"would\" + 0.278*\"get\" + 0.246*\"people\" + 0.210*\"think\" '\n",
      "  '+ 0.205*\"thing\" + 0.196*\"go\" + 0.186*\"really\" + 0.163*\"make\" + 0.160*\"one\"'),\n",
      " (1,\n",
      "  '1.000*\"funner_funner\" + 0.008*\"funner\" + -0.000*\"everyone\" + 0.000*\"keep\" + '\n",
      "  '-0.000*\"type\" + -0.000*\"hate\" + -0.000*\"already\" + -0.000*\"pay\" + '\n",
      "  '0.000*\"gt\" + -0.000*\"hear\"'),\n",
      " (2,\n",
      "  '0.623*\"get\" + -0.603*\"like\" + 0.240*\"go\" + -0.218*\"people\" + -0.109*\"feel\" '\n",
      "  '+ -0.107*\"think\" + 0.102*\"time\" + 0.087*\"take\" + -0.084*\"thing\" + '\n",
      "  '0.075*\"want\"'),\n",
      " (3,\n",
      "  '-0.800*\"would\" + 0.419*\"people\" + 0.206*\"get\" + 0.165*\"thing\" + 0.092*\"lot\" '\n",
      "  '+ -0.082*\"think\" + -0.080*\"kid\" + -0.079*\"like\" + -0.079*\"go\" + '\n",
      "  '0.075*\"well\"'),\n",
      " (4,\n",
      "  '0.617*\"like\" + -0.458*\"people\" + 0.338*\"get\" + -0.298*\"would\" + '\n",
      "  '-0.219*\"think\" + 0.136*\"go\" + -0.128*\"see\" + -0.107*\"thing\" + 0.103*\"kid\" + '\n",
      "  '-0.078*\"well\"'),\n",
      " (5,\n",
      "  '0.529*\"people\" + 0.396*\"get\" + -0.317*\"see\" + 0.272*\"would\" + -0.248*\"one\" '\n",
      "  '+ -0.164*\"make\" + 0.149*\"like\" + -0.143*\"look\" + -0.142*\"well\" + '\n",
      "  '-0.140*\"thing\"'),\n",
      " (6,\n",
      "  '0.488*\"go\" + 0.380*\"think\" + -0.318*\"thing\" + -0.252*\"would\" + -0.216*\"get\" '\n",
      "  '+ -0.195*\"color\" + 0.189*\"want\" + 0.185*\"say\" + 0.173*\"know\" + 0.171*\"kid\"'),\n",
      " (7,\n",
      "  '0.591*\"go\" + -0.540*\"think\" + -0.271*\"get\" + -0.227*\"one\" + -0.204*\"really\" '\n",
      "  '+ 0.176*\"make\" + 0.155*\"thing\" + 0.139*\"people\" + -0.117*\"kid\" + '\n",
      "  '-0.095*\"see\"'),\n",
      " (8,\n",
      "  '0.563*\"one\" + -0.492*\"think\" + -0.376*\"thing\" + 0.271*\"people\" + '\n",
      "  '0.252*\"see\" + 0.106*\"kid\" + -0.101*\"something\" + -0.087*\"time\" + '\n",
      "  '-0.086*\"try\" + -0.085*\"feel\"'),\n",
      " (9,\n",
      "  '0.715*\"really\" + -0.289*\"see\" + 0.255*\"good\" + -0.248*\"think\" + -0.181*\"go\" '\n",
      "  '+ 0.163*\"want\" + -0.152*\"get\" + -0.135*\"thing\" + -0.135*\"one\" + '\n",
      "  '0.131*\"need\"')]\n",
      "[(0,\n",
      "  '0.276*\"would\" + 0.274*\"people\" + 0.252*\"get\" + 0.240*\"think\" + 0.240*\"like\" '\n",
      "  '+ 0.202*\"say\" + 0.198*\"thing\" + 0.189*\"make\" + 0.188*\"one\" + 0.162*\"know\"'),\n",
      " (1,\n",
      "  '-0.675*\"would\" + 0.521*\"get\" + -0.207*\"think\" + -0.198*\"people\" + '\n",
      "  '0.165*\"go\" + -0.136*\"say\" + 0.104*\"one\" + 0.084*\"game\" + 0.079*\"really\" + '\n",
      "  '0.079*\"good\"'),\n",
      " (2,\n",
      "  '-0.681*\"people\" + 0.553*\"would\" + 0.223*\"get\" + -0.164*\"think\" + '\n",
      "  '0.134*\"one\" + 0.093*\"go\" + -0.090*\"say\" + -0.084*\"thing\" + 0.083*\"could\" + '\n",
      "  '0.064*\"take\"'),\n",
      " (3,\n",
      "  '-0.564*\"get\" + -0.465*\"people\" + 0.309*\"like\" + -0.272*\"would\" + '\n",
      "  '0.230*\"one\" + 0.185*\"thing\" + 0.122*\"think\" + 0.120*\"know\" + 0.120*\"gt\" + '\n",
      "  '0.106*\"way\"'),\n",
      " (4,\n",
      "  '0.743*\"like\" + -0.314*\"one\" + -0.221*\"gt\" + -0.193*\"make\" + -0.185*\"say\" + '\n",
      "  '-0.182*\"use\" + 0.138*\"think\" + -0.116*\"good\" + 0.113*\"go\" + '\n",
      "  '-0.096*\"zip_gt\"'),\n",
      " (5,\n",
      "  '-0.749*\"think\" + 0.290*\"like\" + 0.261*\"people\" + 0.203*\"make\" + 0.190*\"use\" '\n",
      "  '+ -0.181*\"get\" + -0.144*\"know\" + -0.126*\"gt\" + 0.114*\"one\" + -0.101*\"go\"'),\n",
      " (6,\n",
      "  '-0.410*\"say\" + -0.402*\"gt\" + 0.369*\"think\" + -0.286*\"know\" + '\n",
      "  '-0.270*\"zip_gt\" + -0.199*\"rar_gt\" + 0.194*\"one\" + 0.175*\"make\" + '\n",
      "  '0.162*\"good\" + -0.157*\"like\"'),\n",
      " (7,\n",
      "  '-0.453*\"say\" + 0.390*\"make\" + 0.375*\"zip_gt\" + -0.341*\"one\" + '\n",
      "  '0.276*\"rar_gt\" + 0.224*\"gt\" + 0.165*\"pdf_gt\" + 0.132*\"ebook\" + '\n",
      "  '0.119*\"really\" + 0.115*\"think\"'),\n",
      " (8,\n",
      "  '0.489*\"one\" + -0.380*\"make\" + -0.314*\"go\" + 0.246*\"zip_gt\" + -0.229*\"know\" '\n",
      "  '+ 0.212*\"like\" + -0.211*\"thing\" + -0.209*\"want\" + 0.181*\"rar_gt\" + '\n",
      "  '0.143*\"people\"'),\n",
      " (9,\n",
      "  '0.448*\"say\" + 0.376*\"good\" + -0.312*\"thing\" + -0.308*\"one\" + -0.260*\"know\" '\n",
      "  '+ -0.259*\"go\" + -0.225*\"see\" + 0.145*\"like\" + -0.138*\"people\" + '\n",
      "  '0.124*\"also\"')]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LsiModel\n",
    "\n",
    "# Build the LSI Model\n",
    "lsi_model_esfj = LsiModel(corpus=corp_esfj, id2word=dct_esfj, num_topics=10, decay=0.5)\n",
    "lsi_model_intp = LsiModel(corpus=corp_intp, id2word=dct_intp, num_topics=10, decay=0.5)\n",
    "\n",
    "# View Topics\n",
    "pprint(lsi_model_esfj.print_topics(-1))\n",
    "pprint(lsi_model_intp.print_topics(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Model Perplexity and Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T01:59:11.834553Z",
     "start_time": "2019-12-10T01:57:38.633770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ESFJ Perplexity:  -8.376806543613682\n",
      "\n",
      "INTP Perplexity:  -8.912526472268127\n",
      "\n",
      "ESFJ Coherence Score:  0.5237966081240052\n",
      "\n",
      "INTP Coherence Score:  0.5570043489160339\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nESFJ Perplexity: ', lda_model_esfj.log_perplexity(corp_esfj))\n",
    "print('\\nINTP Perplexity: ', lda_model_intp.log_perplexity(corp_intp))\n",
    "\n",
    "# Compute Coherence Score \n",
    "coherence_model_esfj = CoherenceModel(model=lda_model_esfj, texts=processed_bigram_esfj, dictionary=dct_esfj, coherence='c_v')\n",
    "coherence_esfj = coherence_model_esfj.get_coherence()\n",
    "print('\\nESFJ Coherence Score: ', coherence_esfj)\n",
    "\n",
    "coherence_model_intp = CoherenceModel(model=lda_model_intp, texts=processed_bigram_intp, dictionary=dct_intp, coherence='c_v')\n",
    "coherence_intp = coherence_model_intp.get_coherence()\n",
    "print('\\nINTP Coherence Score: ', coherence_intp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best Number of Topics \n",
    "\n",
    "Before moving on to Mallet model and visualisations, I decided to find out the best number of topics for the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T02:24:42.258335Z",
     "start_time": "2019-12-10T02:24:42.250905Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T03:01:34.529281Z",
     "start_time": "2019-12-10T02:24:44.107575Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list_esfj, coherence_values_esfj = compute_coherence_values(dictionary=dct_esfj, corpus=corp_esfj, texts=processed_bigram_esfj, start=10, limit=100, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T03:03:36.569966Z",
     "start_time": "2019-12-10T03:03:36.306283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=100; start=10; step=10;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values_esfj)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T03:04:07.113986Z",
     "start_time": "2019-12-10T03:04:07.107030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 10  has Coherence Value of 0.5285\n",
      "Num Topics = 20  has Coherence Value of 0.5077\n",
      "Num Topics = 30  has Coherence Value of 0.4788\n",
      "Num Topics = 40  has Coherence Value of 0.4653\n",
      "Num Topics = 50  has Coherence Value of 0.4592\n",
      "Num Topics = 60  has Coherence Value of 0.4416\n",
      "Num Topics = 70  has Coherence Value of 0.4425\n",
      "Num Topics = 80  has Coherence Value of 0.4253\n",
      "Num Topics = 90  has Coherence Value of 0.426\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values_esfj):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T03:04:57.112102Z",
     "start_time": "2019-12-10T03:04:57.080585Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.049*\"kid\" + 0.027*\"year\" + 0.019*\"lol\" + 0.019*\"school\" + 0.018*\"mom\" + '\n",
      "  '0.016*\"parent\" + 0.013*\"class\" + 0.013*\"start\" + 0.013*\"husband\" + '\n",
      "  '0.013*\"family\"'),\n",
      " (1,\n",
      "  '0.051*\"friend\" + 0.041*\"time\" + 0.016*\"day\" + 0.015*\"place\" + 0.014*\"long\" '\n",
      "  '+ 0.013*\"end\" + 0.012*\"week\" + 0.011*\"live\" + 0.011*\"back\" + 0.010*\"month\"'),\n",
      " (2,\n",
      "  '0.040*\"love\" + 0.033*\"make\" + 0.032*\"good\" + 0.014*\"eat\" + 0.011*\"feel\" + '\n",
      "  '0.009*\"day\" + 0.009*\"pretty\" + 0.009*\"hear\" + 0.009*\"food\" + '\n",
      "  '0.008*\"listen\"'),\n",
      " (3,\n",
      "  '0.014*\"good\" + 0.013*\"run\" + 0.013*\"back\" + 0.011*\"happen\" + 0.011*\"turn\" + '\n",
      "  '0.010*\"phone\" + 0.009*\"game\" + 0.009*\"bad\" + 0.008*\"play\" + 0.008*\"car\"'),\n",
      " (4,\n",
      "  '0.090*\"people\" + 0.050*\"feel\" + 0.036*\"thing\" + 0.028*\"person\" + '\n",
      "  '0.027*\"life\" + 0.024*\"talk\" + 0.016*\"lot\" + 0.013*\"make\" + 0.011*\"friend\" + '\n",
      "  '0.010*\"bad\"'),\n",
      " (5,\n",
      "  '0.047*\"work\" + 0.041*\"good\" + 0.029*\"make\" + 0.029*\"thing\" + 0.027*\"time\" + '\n",
      "  '0.017*\"learn\" + 0.015*\"stuff\" + 0.015*\"love\" + 0.014*\"find\" + 0.011*\"give\"'),\n",
      " (6,\n",
      "  '0.037*\"guy\" + 0.024*\"show\" + 0.020*\"girl\" + 0.019*\"watch\" + 0.017*\"woman\" + '\n",
      "  '0.016*\"man\" + 0.015*\"date\" + 0.015*\"comment\" + 0.013*\"post\" + '\n",
      "  '0.011*\"boyfriend\"'),\n",
      " (7,\n",
      "  '0.034*\"people\" + 0.024*\"type\" + 0.014*\"thing\" + 0.011*\"idea\" + 0.011*\"lot\" '\n",
      "  '+ 0.011*\"find\" + 0.011*\"question\" + 0.010*\"understand\" + 0.010*\"esfj\" + '\n",
      "  '0.008*\"function\"'),\n",
      " (8,\n",
      "  '0.022*\"thing\" + 0.021*\"color\" + 0.017*\"lot\" + 0.016*\"url\" + 0.014*\"weird\" + '\n",
      "  '0.013*\"make\" + 0.012*\"change\" + 0.010*\"notice\" + 0.010*\"work\" + '\n",
      "  '0.009*\"wear\"'),\n",
      " (9,\n",
      "  '0.037*\"read\" + 0.022*\"book\" + 0.019*\"url\" + 0.012*\"write\" + 0.009*\"buy\" + '\n",
      "  '0.009*\"story\" + 0.007*\"great\" + 0.006*\"word\" + 0.006*\"list\" + 0.006*\"edit\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model_esfj = model_list_esfj[0]\n",
    "model_topics = optimal_model_esfj.show_topics(formatted=False)\n",
    "pprint(optimal_model_esfj.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mallet Model\n",
    "\n",
    "Use Mallet wrapper to find better topics, and it is indeed much better than plain LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T02:05:16.142134Z",
     "start_time": "2019-12-10T02:02:26.732244Z"
    }
   },
   "outputs": [],
   "source": [
    "mallet_path = '../../mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet_esfj = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corp_esfj, num_topics=10, id2word=dct_esfj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T02:10:53.465372Z",
     "start_time": "2019-12-10T02:08:31.339726Z"
    }
   },
   "outputs": [],
   "source": [
    "ldamallet_intp = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corp_intp, num_topics=10, id2word=dct_intp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T02:05:47.419267Z",
     "start_time": "2019-12-10T02:05:47.389681Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('people', 0.039644162267911856),\n",
      "   ('feel', 0.039434990710322),\n",
      "   ('guy', 0.035103909047285074),\n",
      "   ('girl', 0.0188746570201666),\n",
      "   ('woman', 0.017841103441487333),\n",
      "   ('make', 0.017447368744847612),\n",
      "   ('life', 0.017102850885287856),\n",
      "   ('person', 0.015995472050988644),\n",
      "   ('man', 0.01565095419142889),\n",
      "   ('date', 0.01459279219420964)]),\n",
      " (1,\n",
      "  [('friend', 0.05263593282832461),\n",
      "   ('people', 0.05121781160259516),\n",
      "   ('love', 0.042744537278861724),\n",
      "   ('time', 0.03396400335622023),\n",
      "   ('talk', 0.0322622578853449),\n",
      "   ('thing', 0.02993417553977239),\n",
      "   ('make', 0.025549817416892186),\n",
      "   ('feel', 0.021874519906876708),\n",
      "   ('good', 0.01916827190110968),\n",
      "   ('lot', 0.018092863304931518)]),\n",
      " (2,\n",
      "  [('work', 0.03111286363000369),\n",
      "   ('show', 0.020975107165116958),\n",
      "   ('year', 0.020644389890227304),\n",
      "   ('school', 0.01901624330615516),\n",
      "   ('good', 0.018939923935026776),\n",
      "   ('watch', 0.018863604563898392),\n",
      "   ('class', 0.018176730223742957),\n",
      "   ('make', 0.018100410852614573),\n",
      "   ('start', 0.013915565335741634),\n",
      "   ('end', 0.013432209318595215)]),\n",
      " (3,\n",
      "  [('read', 0.03687897679799473),\n",
      "   ('book', 0.02214795295327463),\n",
      "   ('comment', 0.01474387814126872),\n",
      "   ('post', 0.014396812134455941),\n",
      "   ('write', 0.012108747348801336),\n",
      "   ('story', 0.010874734880133685),\n",
      "   ('reddit', 0.008085352529082846),\n",
      "   ('character', 0.007339803329262806),\n",
      "   ('thread', 0.0069541744328041645),\n",
      "   ('word', 0.006941320136255543)]),\n",
      " (4,\n",
      "  [('eat', 0.014631607085074353),\n",
      "   ('haha', 0.0138718890248878),\n",
      "   ('love', 0.012394659463413948),\n",
      "   ('movie', 0.010973705313805765),\n",
      "   ('buy', 0.010270262665484883),\n",
      "   ('food', 0.00890558392774237),\n",
      "   ('sound', 0.007766006837462542),\n",
      "   ('awesome', 0.007386147807369265),\n",
      "   ('lt', 0.0070203576302424065),\n",
      "   ('song', 0.006190295305223765)]),\n",
      " (5,\n",
      "  [('thing', 0.029963602809247963),\n",
      "   ('color', 0.020120982211513816),\n",
      "   ('lot', 0.019851848054544523),\n",
      "   ('change', 0.01771159071102681),\n",
      "   ('work', 0.016532526785256574),\n",
      "   ('weird', 0.012046957502435023),\n",
      "   ('make', 0.011098579996924181),\n",
      "   ('problem', 0.01020146614035987),\n",
      "   ('time', 0.009893884246680678),\n",
      "   ('stuff', 0.009355615932742093)]),\n",
      " (6,\n",
      "  [('kid', 0.050022105728541655),\n",
      "   ('lol', 0.0208930714330828),\n",
      "   ('mom', 0.01813932924903682),\n",
      "   ('parent', 0.016572980483799658),\n",
      "   ('play', 0.015625592117728793),\n",
      "   ('husband', 0.014703467441419819),\n",
      "   ('family', 0.012922377313206593),\n",
      "   ('stop', 0.011469715151897935),\n",
      "   ('son', 0.011040232425945809),\n",
      "   ('cool', 0.009764416092970378)]),\n",
      " (7,\n",
      "  [('people', 0.0343382022101994),\n",
      "   ('thing', 0.02710621906653644),\n",
      "   ('type', 0.02274947049592309),\n",
      "   ('feel', 0.010568133182621292),\n",
      "   ('idea', 0.01054618482710183),\n",
      "   ('experience', 0.009734095672881709),\n",
      "   ('esfj', 0.009701173139602516),\n",
      "   ('understand', 0.00860375536362938),\n",
      "   ('lot', 0.008142839897720664),\n",
      "   ('find', 0.007912382164766306)]),\n",
      " (8,\n",
      "  [('time', 0.03620541335760326),\n",
      "   ('day', 0.028350933187048837),\n",
      "   ('back', 0.02584497998977671),\n",
      "   ('live', 0.017491802665536287),\n",
      "   ('long', 0.013003528282362328),\n",
      "   ('run', 0.012554700844044933),\n",
      "   ('place', 0.012442493984465584),\n",
      "   ('week', 0.01175678539814734),\n",
      "   ('move', 0.01168198082509444),\n",
      "   ('wait', 0.011008739667618348)]),\n",
      " (9,\n",
      "  [('good', 0.050521063078958976),\n",
      "   ('url', 0.029361490957212175),\n",
      "   ('make', 0.02606693868548743),\n",
      "   ('yeah', 0.02576367445963829),\n",
      "   ('pretty', 0.020870092633436258),\n",
      "   ('find', 0.020139501543890603),\n",
      "   ('give', 0.0125992501102779),\n",
      "   ('bad', 0.012337340097044552),\n",
      "   ('great', 0.0115929642699603),\n",
      "   ('guess', 0.010352337891486546)])]\n"
     ]
    }
   ],
   "source": [
    "# Show Topics - ESFJ\n",
    "pprint(ldamallet_esfj.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T02:12:12.306165Z",
     "start_time": "2019-12-10T02:12:12.276336Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('time', 0.03694628544437392),\n",
      "   ('day', 0.02163933458308117),\n",
      "   ('show', 0.018687174339823167),\n",
      "   ('year', 0.017653918254682863),\n",
      "   ('end', 0.016517336561028533),\n",
      "   ('start', 0.015956426114809512),\n",
      "   ('back', 0.013579937118986819),\n",
      "   ('watch', 0.011572468153571375),\n",
      "   ('great', 0.010347321652619304),\n",
      "   ('character', 0.009978301622212053)]),\n",
      " (1,\n",
      "  [('people', 0.055514534963218204),\n",
      "   ('man', 0.012306177701206006),\n",
      "   ('woman', 0.011950665900948943),\n",
      "   ('make', 0.009694533322394509),\n",
      "   ('state', 0.008040036098121256),\n",
      "   ('society', 0.007055541882024776),\n",
      "   ('problem', 0.007028194820466541),\n",
      "   ('call', 0.006535947712418301),\n",
      "   ('country', 0.005893291765799765),\n",
      "   ('government', 0.005852271173462411)]),\n",
      " (2,\n",
      "  [('money', 0.01270179055345891),\n",
      "   ('buy', 0.01073999567740112),\n",
      "   ('pay', 0.010606992634956524),\n",
      "   ('job', 0.008046684067898054),\n",
      "   ('car', 0.007414919616286222),\n",
      "   ('work', 0.00714891353139703),\n",
      "   ('gt', 0.0063342698964238804),\n",
      "   ('part', 0.005719130825117625),\n",
      "   ('company', 0.005569502402367454),\n",
      "   ('place', 0.0055196262614507306)]),\n",
      " (3,\n",
      "  [('url', 0.035913292749702064),\n",
      "   ('post', 0.021692917190066673),\n",
      "   ('yeah', 0.01893902792540342),\n",
      "   ('fuck', 0.01442973556221213),\n",
      "   ('shit', 0.013753341707733437),\n",
      "   ('read', 0.013382935549328437),\n",
      "   ('guy', 0.01165974168196605),\n",
      "   ('comment', 0.011289335523561053),\n",
      "   ('edit', 0.01109608013656714),\n",
      "   ('lol', 0.010033175508100622)]),\n",
      " (4,\n",
      "  [('people', 0.04774473495108065),\n",
      "   ('thing', 0.02249737438505334),\n",
      "   ('find', 0.02216571776021226),\n",
      "   ('good', 0.021239843015864242),\n",
      "   ('lot', 0.019139351058537393),\n",
      "   ('type', 0.0189873417721519),\n",
      "   ('intp', 0.014731081753358024),\n",
      "   ('make', 0.012893151290697031),\n",
      "   ('stuff', 0.01247858050964568),\n",
      "   ('learn', 0.011732353103753248)]),\n",
      " (5,\n",
      "  [('game', 0.028973438621679826),\n",
      "   ('play', 0.022124910265613782),\n",
      "   ('run', 0.01198851399856425),\n",
      "   ('good', 0.011213208901651112),\n",
      "   ('kill', 0.010653266331658291),\n",
      "   ('level', 0.00669059583632448),\n",
      "   ('player', 0.006288585786073223),\n",
      "   ('hit', 0.0062598707824838475),\n",
      "   ('lose', 0.006216798277099785),\n",
      "   ('team', 0.006101938262742283)]),\n",
      " (6,\n",
      "  [('thing', 0.03137610703355632),\n",
      "   ('work', 0.028112558567830348),\n",
      "   ('make', 0.026000054166779515),\n",
      "   ('change', 0.014476071825149636),\n",
      "   ('human', 0.010914606072095984),\n",
      "   ('life', 0.010779189123310674),\n",
      "   ('happen', 0.009709395227906726),\n",
      "   ('world', 0.008869810145437803),\n",
      "   ('time', 0.008788559976166618),\n",
      "   ('system', 0.007800016250033855)]),\n",
      " (7,\n",
      "  [('bad', 0.025014752659076843),\n",
      "   ('make', 0.021027936498798198),\n",
      "   ('talk', 0.019761366743908233),\n",
      "   ('love', 0.018091797521553276),\n",
      "   ('friend', 0.015069301515565854),\n",
      "   ('feel', 0.014954158810575857),\n",
      "   ('stop', 0.01368758905568589),\n",
      "   ('good', 0.013558053512572145),\n",
      "   ('life', 0.013442910807582148),\n",
      "   ('thing', 0.011888484290217188)]),\n",
      " (8,\n",
      "  [('gt', 0.03187969516990752),\n",
      "   ('point', 0.016353429338540396),\n",
      "   ('word', 0.01209557128522225),\n",
      "   ('fact', 0.010481924443359639),\n",
      "   ('agree', 0.010346323868413202),\n",
      "   ('god', 0.010183603178477477),\n",
      "   ('true', 0.010129362948498902),\n",
      "   ('wrong', 0.010075122718520327),\n",
      "   ('reason', 0.009817481626122095),\n",
      "   ('understand', 0.008502156049141648)]),\n",
      " (9,\n",
      "  [('make', 0.012484221544903175),\n",
      "   ('nice', 0.01154521104645793),\n",
      "   ('good', 0.01128351959607155),\n",
      "   ('put', 0.010606200548012683),\n",
      "   ('sound', 0.010359902712354915),\n",
      "   ('cool', 0.00891290292786552),\n",
      "   ('big', 0.008389520027092761),\n",
      "   ('pretty', 0.008035466888334718),\n",
      "   ('yeah', 0.007373541455004464),\n",
      "   ('bit', 0.006850158554231705)])]\n"
     ]
    }
   ],
   "source": [
    "# Show Topics - INTP\n",
    "pprint(ldamallet_intp.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T02:13:52.378405Z",
     "start_time": "2019-12-10T02:13:33.281582Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ESFJ Coherence Score:  0.49884616111697466\n",
      "\n",
      " ESFJ Coherence Score:  0.49884616111697466\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet_esfj = CoherenceModel(model=ldamallet_esfj, texts=processed_bigram_esfj, dictionary=dct_esfj, coherence='c_v')\n",
    "coherence_ldamallet_esfj = coherence_model_ldamallet_esfj.get_coherence()\n",
    "print('\\n ESFJ Coherence Score: ', coherence_ldamallet_esfj)\n",
    "\n",
    "coherence_model_ldamallet_intp = CoherenceModel(model=ldamallet_intp, texts=processed_bigram_intp, dictionary=dct_esfj, coherence='c_v')\n",
    "coherence_ldamallet_esfj = coherence_model_ldamallet_esfj.get_coherence()\n",
    "print('\\n ESFJ Coherence Score: ', coherence_ldamallet_esfj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because PyLDAvis only supports lda models, thus I used the function below to convert Mallet models to regular LDA models for visualisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T03:14:32.991856Z",
     "start_time": "2019-12-10T03:14:32.986493Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to convert Mallet model to LDA to be used in visualization \n",
    "\n",
    "def mallet_to_lda(mallet_model):\n",
    "    model_gensim = LdaModel(\n",
    "        id2word=mallet_model.id2word, num_topics=mallet_model.num_topics,\n",
    "        alpha=mallet_model.alpha, eta=0, iterations=1000,\n",
    "        gamma_threshold=0.001,\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    model_gensim.sync_state()\n",
    "    model_gensim.state.sstats = mallet_model.wordtopics\n",
    "    return model_gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T03:16:49.816860Z",
     "start_time": "2019-12-10T03:16:49.399706Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert ldamallet models to lda models for visualization \n",
    "lda_ldamallet_esfj = mallet_to_lda(ldamallet_esfj)\n",
    "lda_ldamallet_intp = mallet_to_lda(ldamallet_intp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:11:04.745872Z",
     "start_time": "2019-12-10T04:11:04.482332Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the converted model\n",
    "lda_ldamallet_esfj.save('lda_ldamallet_esfj.model')\n",
    "lda_ldamallet_intp.save('lda_ldamallet_intp.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Topics - keywords & topics\n",
    "\n",
    "These visualizations are amazing! And they provided useful insights into the user behaviours of INTP and ESFJ users. They do actually have different interests on Reddit. I have attached the two html visualisations in the zip file. The INTP people are the rational ones, they talk about money/gaming/psychology... on the other hand ESFJ people like to openly discuss relationship issues including dating life/friendship/family/appearces etc... This in a way proves that the self-identified personality indicators is at least a bit right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.1.2)\r\n",
      "Requirement already satisfied: pytest in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyLDAvis) (3.5.1)\r\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyLDAvis) (2.10)\r\n",
      "Requirement already satisfied: numexpr in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyLDAvis) (2.6.5)\r\n",
      "Requirement already satisfied: funcy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyLDAvis) (1.14)\r\n",
      "Requirement already satisfied: numpy>=1.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyLDAvis) (1.17.4)\r\n",
      "Requirement already satisfied: wheel>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyLDAvis) (0.31.1)\r\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyLDAvis) (0.18.2)\r\n",
      "Requirement already satisfied: pandas>=0.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyLDAvis) (0.24.2)\r\n",
      "Requirement already satisfied: scipy>=0.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyLDAvis) (1.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.8.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyLDAvis) (0.14.0)\r\n",
      "Requirement already satisfied: py>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.5.3)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->pyLDAvis) (1.11.0)\r\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->pyLDAvis) (39.1.0)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->pyLDAvis) (18.1.0)\r\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->pyLDAvis) (4.1.0)\r\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->pyLDAvis) (0.6.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.0)\r\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2018.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.17.0->pyLDAvis) (2.7.3)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:09:47.466429Z",
     "start_time": "2019-12-10T03:17:32.777000Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:223: RuntimeWarning: divide by zero encountered in log\n",
      "  kernel = (topic_given_term * np.log((topic_given_term.T / topic_proportion).T))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:240: RuntimeWarning: divide by zero encountered in log\n",
      "  log_lift = np.log(topic_term_dists / term_proportion)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:241: RuntimeWarning: divide by zero encountered in log\n",
      "  log_ttd = np.log(topic_term_dists)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis_esfj = pyLDAvis.gensim.prepare(lda_ldamallet_esfj, corp_esfj, dct_esfj)\n",
    "pyLDAvis.save_html(vis_esfj, 'lda_esfj.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T04:09:47.475107Z",
     "start_time": "2019-12-10T03:17:57.584Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:223: RuntimeWarning: divide by zero encountered in log\n",
      "  kernel = (topic_given_term * np.log((topic_given_term.T / topic_proportion).T))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:240: RuntimeWarning: divide by zero encountered in log\n",
      "  log_lift = np.log(topic_term_dists / term_proportion)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:241: RuntimeWarning: divide by zero encountered in log\n",
      "  log_ttd = np.log(topic_term_dists)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis_intp = pyLDAvis.gensim.prepare(lda_ldamallet_intp, corp_intp, dct_intp)\n",
    "pyLDAvis.save_html(vis_intp, 'lda_intp.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "There are many bias and subjective decisions in the process of this project, but  to be honest, the project is based on very biased and subjective data. I made some calls with the dataset, and one of the decisions end up hurting the performance of the models. \n",
    "\n",
    "There are limitations on the dataset too. User comments, especially reddit comments are extremely informal, the grammar and the spelling is poor, and there are often internet slang/emoji peppered throughout the documents. It proves to be difficult even after I processed it using different tools, almost bleached it in the end. \n",
    "\n",
    "\n",
    "## Future Improvements\n",
    "\n",
    "There are many improvements I can see happening here. \n",
    "First, I did not get a chance to work more on LSTM and word embedding which might help with the accuracy of the models. This is the next thing I’m going to learn and work on. \n",
    "\n",
    "Second, to be able to use Hadoop and MapReduce would help with the volume of the dataset. I know we touched upon this during class, however, more lessons are needed. \n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "### In response to hypothesised outcomes in proposal: \n",
    "\n",
    "1. Personality Classifier: The model would be able to take a comment and predict what personality the commenter is. However, due to the imbalance in the data and the number of classes, I don’t think the accuracy will be very high. \n",
    "\t\n",
    "**Reality:** Well,  at least I foresaw the terrible accuracy. But I was not able to build an input function for testing user real-time input.  The accuracy of the models are all relatively low. The best model is Logistic Regression before I under sample the data, it achieved 21% accuracy on precision/recall. Another promising model is FastText, even on the under sampled data, it achieved 19% accuracy. I will play with it more to see if it can go higher on original data. \n",
    "\n",
    "2. User segmentation: Ideally the model will be able to find some clear clusters using the text data and personalities. Then I would be able to relate them to the subreddit and build a persona for reddit users. \n",
    "\n",
    "**Reality:** I didn’t use unsupervised model for this, instead I used LDA topic modelling for different personality types. They actually came out great. I think it is possible to cross-reference the LDA topics / subreddits/ MBTI types to build a complete picture of the user behaviours. \n",
    "\n",
    "3. Overview of the Reddit: People with what kind of personalities like to use Reddit more? Is there any relationship between personalities and subreddits? \n",
    "\n",
    "**Reality:** I didn’t get a chance to explore anything related to subreddits. However, from the data, it’s plain to see that people with certain personalities ( INFP, INTP, INFJ, ENTJ..) like to post on Reddit more than others. Funny how internet is the playground of introverts.  \n",
    "\n",
    "### This NLP Journey\n",
    "\n",
    "Looking back, there are decisions I regret but in the end, these are valuable lessons. Even though NLP might not look as sophisticated as image recognition CNNs, it is one of the most important tools in tackling the largest format of unstructured data out there - text data. Users generate trillions of text everyday on the internet, it is one of the biggest data and it contains valuable information. I see NLP as gold panning, it’s a lot of hard work for those few nuggets that’s highly valuable. \n",
    "\n",
    "Well, in conclusion, no regrets. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
