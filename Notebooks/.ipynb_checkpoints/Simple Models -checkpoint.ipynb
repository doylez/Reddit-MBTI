{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Models \n",
    "\n",
    "### Import Packages and cleaned data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T22:02:14.603833Z",
     "start_time": "2019-12-05T22:02:14.370735Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Doylism/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# regular package \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re \n",
    "import os\n",
    "import string\n",
    "\n",
    "\n",
    "# nltk \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:04:43.567846Z",
     "start_time": "2019-12-03T05:04:34.056069Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# import cleaned data\n",
    "df = pd.read_csv('../../clean_data/clean_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:05:32.562352Z",
     "start_time": "2019-12-03T05:05:32.550431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INFP</td>\n",
       "      <td>lol thats left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INTP</td>\n",
       "      <td>post try telling people time im always joking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFP</td>\n",
       "      <td>first thought pepsi something probably alcohol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>formula something like every time says add bpm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INTP</td>\n",
       "      <td>imply im five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>INTP</td>\n",
       "      <td>well wouldnt know think theres lot potential t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>sine na support directors actors people behind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>INFP</td>\n",
       "      <td>use enough vacation days dont lose time rolls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>INTP</td>\n",
       "      <td>ur angle youre devil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>INTP</td>\n",
       "      <td>mean dont much influence crow ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>INTP</td>\n",
       "      <td>many fewer people im guessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>INFP</td>\n",
       "      <td>going third date isnt exactly breakup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>want nes classic controller since already game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>maybe tongue cheek dont wreck body enjoy using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>INFP</td>\n",
       "      <td>agree consistant position support way think go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>INTP</td>\n",
       "      <td>alors ya pas de balise integrée faut le faire ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>kind strange lump vague references religions o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>INFP</td>\n",
       "      <td>wow thats fucked woman im kind worried child u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>psychotic tire kills people youre dark comedy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MBTI                                           comments\n",
       "0   INFP                                     lol thats left\n",
       "1   INTP  post try telling people time im always joking ...\n",
       "2   INFP     first thought pepsi something probably alcohol\n",
       "3   ENTP  formula something like every time says add bpm...\n",
       "4   INTP                                      imply im five\n",
       "5   INTP  well wouldnt know think theres lot potential t...\n",
       "6   INFJ  sine na support directors actors people behind...\n",
       "7   INFP      use enough vacation days dont lose time rolls\n",
       "8   INTP                               ur angle youre devil\n",
       "9   INTP                 mean dont much influence crow ruby\n",
       "10  INTP                      many fewer people im guessing\n",
       "11  INFP              going third date isnt exactly breakup\n",
       "12  INFJ  want nes classic controller since already game...\n",
       "13  ENTP  maybe tongue cheek dont wreck body enjoy using...\n",
       "14  INFP  agree consistant position support way think go...\n",
       "15  INTP  alors ya pas de balise integrée faut le faire ...\n",
       "16  INTJ  kind strange lump vague references religions o...\n",
       "17  INFP  wow thats fucked woman im kind worried child u...\n",
       "18  ISTJ  psychotic tire kills people youre dark comedy ...\n",
       "19  ENTP                                               like"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:09:21.268102Z",
     "start_time": "2019-12-03T05:09:20.797571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI            0\n",
       "comments    23971\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:16:33.121165Z",
     "start_time": "2019-12-03T05:16:32.407790Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:16:44.350871Z",
     "start_time": "2019-12-03T05:16:43.878347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI        0\n",
       "comments    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:16:51.212977Z",
     "start_time": "2019-12-03T05:16:51.206414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2976811, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# now we are left with 2.97 million of comments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Models \n",
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:17:14.084930Z",
     "start_time": "2019-12-03T05:17:12.479173Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df['comments']\n",
    "y = df['MBTI']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:36:28.744482Z",
     "start_time": "2019-12-03T05:36:28.720921Z"
    }
   },
   "outputs": [],
   "source": [
    "mbti = ['INFP','INFJ','INTP','INTJ','ENTP','ENFP','ISTP','ISFP','ENTJ','ISTJ','ENFJ','ISFJ','ESTP','ESFP','ESFJ','ESTJ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:32:28.993420Z",
     "start_time": "2019-12-03T05:17:16.482354Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ae9c6b65cd92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ])\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmy_logit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1361\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1363\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[1;32m    756\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    326\u001b[0m         _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n\u001b[1;32m    327\u001b[0m                        \u001b[0mpgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                        isave, dsave, maxls)\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mtask_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'FG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_logit = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', LogisticRegression(solver='saga'))\n",
    "])\n",
    "my_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:32:29.021918Z",
     "start_time": "2019-12-03T05:18:09.666Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = my_logit.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % my_logit.score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:36:28.717298Z",
     "start_time": "2019-12-03T05:34:38.108051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a pipeline for vectorise, transform and clasify the data \n",
    "my_nb = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "my_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:42:42.152448Z",
     "start_time": "2019-12-03T05:41:36.202828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.1707676217521197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFP       0.59      0.06      0.11     54044\n",
      "        INFJ       0.45      0.04      0.08     61673\n",
      "        INTP       0.24      0.15      0.18     76574\n",
      "        INTJ       0.35      0.06      0.10     67098\n",
      "        ENTP       0.95      0.01      0.02     18187\n",
      "        ENFP       0.79      0.01      0.01     19948\n",
      "        ISTP       0.76      0.03      0.06     28917\n",
      "        ISFP       0.63      0.09      0.15     48215\n",
      "        ENTJ       0.17      0.22      0.19     81090\n",
      "        ISTJ       0.13      0.58      0.21     92517\n",
      "        ENFJ       0.53      0.02      0.05     52415\n",
      "        ISFJ       0.14      0.40      0.21     89301\n",
      "        ESTP       0.63      0.05      0.09     46995\n",
      "        ESFP       0.71      0.07      0.14     42366\n",
      "        ESFJ       0.60      0.03      0.05     46371\n",
      "        ESTJ       0.45      0.17      0.25     67333\n",
      "\n",
      "   micro avg       0.17      0.17      0.17    893044\n",
      "   macro avg       0.51      0.12      0.12    893044\n",
      "weighted avg       0.41      0.17      0.14    893044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = my_nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % my_nb.score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LInear SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:48:25.661298Z",
     "start_time": "2019-12-03T05:45:20.142531Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...dom_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SGDClassifier(loss='hinge', penalty='l2', \\\n",
    "                                random_state=42, max_iter=5, tol=None))\n",
    "])\n",
    "\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T05:49:29.582925Z",
     "start_time": "2019-12-03T05:48:25.664326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.16417220204155675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        INFP       0.19      0.24      0.21     54044\n",
      "        INFJ       0.18      0.14      0.16     61673\n",
      "        INTP       0.18      0.18      0.18     76574\n",
      "        INTJ       0.16      0.16      0.16     67098\n",
      "        ENTP       0.22      0.20      0.21     18187\n",
      "        ENFP       0.20      0.25      0.22     19948\n",
      "        ISTP       0.26      0.32      0.28     28917\n",
      "        ISFP       0.24      0.27      0.25     48215\n",
      "        ENTJ       0.17      0.17      0.17     81090\n",
      "        ISTJ       0.17      0.12      0.14     92517\n",
      "        ENFJ       0.15      0.13      0.14     52415\n",
      "        ISFJ       0.16      0.15      0.15     89301\n",
      "        ESTP       0.19      0.19      0.19     46995\n",
      "        ESFP       0.23      0.26      0.24     42366\n",
      "        ESFJ       0.18      0.18      0.18     46371\n",
      "        ESTJ       0.25      0.29      0.27     67333\n",
      "\n",
      "   micro avg       0.19      0.19      0.19    893044\n",
      "   macro avg       0.19      0.20      0.20    893044\n",
      "weighted avg       0.19      0.19      0.19    893044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % sgd.score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=mbti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:03:03.217134Z",
     "start_time": "2019-12-05T20:02:41.483264Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df_clean = pd.read_csv('../../clean_data/spacy_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:03:03.243491Z",
     "start_time": "2019-12-05T20:03:03.222348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "      <th>comments_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INFP</td>\n",
       "      <td>Lol that's why I left.</td>\n",
       "      <td>lol that be why leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INTP</td>\n",
       "      <td>I was just about to post \"I try telling people...</td>\n",
       "      <td>be just about to post try tell people all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFP</td>\n",
       "      <td>My first thought was Pepsi or something. Proba...</td>\n",
       "      <td>first thought be pepsi or something probably n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>Not if the formula is something like \"every ti...</td>\n",
       "      <td>not if the formula be something like every tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INTP</td>\n",
       "      <td>Does this imply I'm a five now?</td>\n",
       "      <td>do this imply be five now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MBTI                                           comments  \\\n",
       "0  INFP                            Lol that's why I left.    \n",
       "1  INTP  I was just about to post \"I try telling people...   \n",
       "2  INFP  My first thought was Pepsi or something. Proba...   \n",
       "3  ENTP  Not if the formula is something like \"every ti...   \n",
       "4  INTP                    Does this imply I'm a five now?   \n",
       "\n",
       "                                      comments_lemma  \n",
       "0                              lol that be why leave  \n",
       "1  be just about to post try tell people all the ...  \n",
       "2  first thought be pepsi or something probably n...  \n",
       "3  not if the formula be something like every tim...  \n",
       "4                          do this imply be five now  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:03:04.143479Z",
     "start_time": "2019-12-05T20:03:03.247791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI                  0\n",
       "comments              0\n",
       "comments_lemma    23125\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:03:05.426909Z",
     "start_time": "2019-12-05T20:03:04.150414Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean = df_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:07:33.957772Z",
     "start_time": "2019-12-05T20:07:16.918016Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove the digits and replace with white space \n",
    "pattern = '[0-9]'\n",
    "\n",
    "df_clean['comments_lemma'] = df_clean['comments_lemma'].apply(lambda x: re.sub(pattern,' ', x))\n",
    "\n",
    "# remove underscore \n",
    "df_clean['comments_lemma'] = df_clean['comments_lemma'].apply(lambda x: x.replace('_',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:12:11.754652Z",
     "start_time": "2019-12-05T20:12:03.902002Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_clean['comments_lemma']\n",
    "y = df_clean['MBTI']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:15:56.679543Z",
     "start_time": "2019-12-05T20:12:16.094603Z"
    }
   },
   "outputs": [],
   "source": [
    "bagofwords = CountVectorizer(min_df=50, stop_words='english')\n",
    "bagofwords.fit(X_train)\n",
    "X_train_dtm = bagofwords.transform(X_train)\n",
    "X_test_dtm = bagofwords.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:15:56.695425Z",
     "start_time": "2019-12-05T20:15:56.682355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2084359, 23766)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:15:56.732754Z",
     "start_time": "2019-12-05T20:15:56.698935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaaaaand',\n",
       " 'aaaaand',\n",
       " 'aaaand',\n",
       " 'aaah',\n",
       " 'aaand',\n",
       " 'aac',\n",
       " 'aah',\n",
       " 'aan',\n",
       " 'aang',\n",
       " 'aaron',\n",
       " 'aaryn',\n",
       " 'aas',\n",
       " 'ab',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abandonment',\n",
       " 'abbey',\n",
       " 'abbott',\n",
       " 'abbreviate',\n",
       " 'abbreviation',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdoman',\n",
       " 'abdominal',\n",
       " 'abduct',\n",
       " 'abduction',\n",
       " 'abe',\n",
       " 'abed',\n",
       " 'abel',\n",
       " 'aber',\n",
       " 'aberration',\n",
       " 'abh',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abide',\n",
       " 'abilify',\n",
       " 'ability',\n",
       " 'abit',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'ableist',\n",
       " 'ableton',\n",
       " 'abnormal',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'aboard',\n",
       " 'abolish',\n",
       " 'abolition']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagofwords.get_feature_names()[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:36:07.695075Z",
     "start_time": "2019-12-05T20:36:07.410029Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = df_clean.sample(n=2000)\n",
    "X_trial = df_test['comments_lemma']\n",
    "y_trial = df_test['MBTI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:36:09.683404Z",
     "start_time": "2019-12-05T20:36:09.669865Z"
    }
   },
   "outputs": [],
   "source": [
    "X_trial_train, X_trial_test, y_trial_train, y_trial_test = train_test_split(X_trial, y_trial, test_size=0.3, stratify=y_trial, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T23:55:47.503124Z",
     "start_time": "2019-12-05T23:32:28.241971Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3216 candidates, totalling 16080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1505 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1617 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1674 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1733 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1853 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1914 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2105 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2237 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2304 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2373 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2513 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2657 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2730 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2805 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2957 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3113 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3354 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3437 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3605 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3690 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3777 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3864 tasks      | elapsed: 23.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-cd6835761f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mfittedgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trial_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trial_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mfittedgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trial_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trial_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([ ('vect', CountVectorizer()),('model', LogisticRegression())])\n",
    "\n",
    "param_grid = [\n",
    "    # Logistic Regression\n",
    "    {'vect':[TfidfVectorizer()], 'model':[LogisticRegression(solver='saga')],\n",
    "    'model__penalty':['l1','l2'], 'model__C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "     'vect__min_df':[50, 100, 300, 500], 'vect__smooth_idf': (True, False),\n",
    "     'vect__norm': ('l1', 'l2', None)},\n",
    "    \n",
    "    # Random Forest\n",
    "    {'vect':[TfidfVectorizer()], 'model':[RandomForestClassifier()],\n",
    "     'vect__min_df':[50, 100, 300, 500], \n",
    "     'model__n_estimators': [50, 100, 150, 200], 'model__max_depth':[2, 5, 10, 15, 20],\n",
    "     'vect__smooth_idf': (True, False), 'vect__norm': ('l1', 'l2', None)},\n",
    "    \n",
    "    # XG Boost\n",
    "    {'vect':[TfidfVectorizer()], 'model':[XGBClassifier()],\n",
    "     'vect__min_df':[50, 100, 300, 500], 'model__learning_rate': [0.1, 0.5, 1, 2],\n",
    "     'model__n_estimators': [50, 100, 150, 200], 'model__max_depth':[2, 5, 10, 15, 20],\n",
    "     'vect__smooth_idf': (True, False), 'vect__norm': ('l1', 'l2', None)},\n",
    "    \n",
    "    # Linear SVC\n",
    "    {'vect':[TfidfVectorizer()], 'model':[SGDClassifier()],\n",
    "     'vect__min_df':[50, 100, 300, 500], 'model__learning_rate': [0.1, 0.5, 1, 2],\n",
    "     'model__max_depth':[2, 5, 10, 15, 20],\n",
    "     'vect__smooth_idf': (True, False), 'vect__norm': ('l1', 'l2', None)}\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, verbose=10, n_jobs=-1)\n",
    "fittedgrid = grid.fit(X_trial_train, y_trial_train)\n",
    "\n",
    "fittedgrid.score(X_trial_test, y_trial_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid.best_estimator_, 'bestmodel.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:43:41.255766Z",
     "start_time": "2019-12-05T20:43:41.248946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=500,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True...penalty='l2', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:44:32.784803Z",
     "start_time": "2019-12-05T20:44:32.766892Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_results = pd.concat([pd.DataFrame(fittedgrid.cv_results_[\"params\"]),pd.DataFrame(fittedgrid.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1).sort_values(by='Accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T20:44:41.670156Z",
     "start_time": "2019-12-05T20:44:41.615886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model__C</th>\n",
       "      <th>model__penalty</th>\n",
       "      <th>vect</th>\n",
       "      <th>vect__min_df</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>0.100</td>\n",
       "      <td>l2</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>500</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>500</td>\n",
       "      <td>0.113571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>500</td>\n",
       "      <td>0.113571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>500</td>\n",
       "      <td>0.113571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>500</td>\n",
       "      <td>0.113571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.068571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.068571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.068571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>500</td>\n",
       "      <td>0.067857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.061429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model  model__C  \\\n",
       "47   LogisticRegression(C=0.1, class_weight=None, d...     0.100   \n",
       "103  LogisticRegression(C=0.1, class_weight=None, d...  1000.000   \n",
       "87   LogisticRegression(C=0.1, class_weight=None, d...   100.000   \n",
       "63   LogisticRegression(C=0.1, class_weight=None, d...     1.000   \n",
       "79   LogisticRegression(C=0.1, class_weight=None, d...    10.000   \n",
       "..                                                 ...       ...   \n",
       "88   LogisticRegression(C=0.1, class_weight=None, d...   100.000   \n",
       "96   LogisticRegression(C=0.1, class_weight=None, d...  1000.000   \n",
       "80   LogisticRegression(C=0.1, class_weight=None, d...   100.000   \n",
       "59   LogisticRegression(C=0.1, class_weight=None, d...     1.000   \n",
       "4    LogisticRegression(C=0.1, class_weight=None, d...     0.001   \n",
       "\n",
       "    model__penalty                                               vect  \\\n",
       "47              l2  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "103             l1  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "87              l1  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "63              l2  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "79              l2  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "..             ...                                                ...   \n",
       "88              l2  CountVectorizer(analyzer='word', binary=False,...   \n",
       "96              l1  CountVectorizer(analyzer='word', binary=False,...   \n",
       "80              l1  CountVectorizer(analyzer='word', binary=False,...   \n",
       "59              l2  CountVectorizer(analyzer='word', binary=False,...   \n",
       "4               l1  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "\n",
       "     vect__min_df  Accuracy  \n",
       "47            500  0.115000  \n",
       "103           500  0.113571  \n",
       "87            500  0.113571  \n",
       "63            500  0.113571  \n",
       "79            500  0.113571  \n",
       "..            ...       ...  \n",
       "88             50  0.068571  \n",
       "96             50  0.068571  \n",
       "80             50  0.068571  \n",
       "59            500  0.067857  \n",
       "4              50  0.061429  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
