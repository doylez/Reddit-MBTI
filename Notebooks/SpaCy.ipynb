{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore SpaCy \n",
    "\n",
    "### Import packages and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:45:24.607451Z",
     "start_time": "2019-12-06T16:45:21.284373Z"
    }
   },
   "outputs": [],
   "source": [
    "# regular package \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re \n",
    "import os\n",
    "import string \n",
    "\n",
    "# nlp specific \n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:45:44.658600Z",
     "start_time": "2019-12-06T16:45:31.242928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# import data \n",
    "df_punc = pd.read_csv('../../clean_data/with_punc.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T18:43:36.440096Z",
     "start_time": "2019-12-06T18:43:36.235724Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sample = df_punc.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:45:52.898209Z",
     "start_time": "2019-12-06T16:45:52.874607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1533251</td>\n",
       "      <td>INFP</td>\n",
       "      <td>Also, this is availble on jailbroken iPhones a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489172</td>\n",
       "      <td>INFP</td>\n",
       "      <td>Damn spices eating all my jeans!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1434585</td>\n",
       "      <td>INFP</td>\n",
       "      <td>When my friend first showed me a picture of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>979964</td>\n",
       "      <td>INFP</td>\n",
       "      <td>Lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50650</td>\n",
       "      <td>ENFJ</td>\n",
       "      <td>I have impressed the guy who taught me not to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1265</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>Asian American History: Movement and Dislocati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122703</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>I'm not saying that all media is bad all of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1101969</td>\n",
       "      <td>INTP</td>\n",
       "      <td>Carthage. Spam cities and pick up that +2 Scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61720</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>Redditors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305117</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>So other than just get the Trump administratio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MBTI                                           comments\n",
       "1533251  INFP  Also, this is availble on jailbroken iPhones a...\n",
       "489172   INFP                   Damn spices eating all my jeans!\n",
       "1434585  INFP  When my friend first showed me a picture of th...\n",
       "979964   INFP                                             Lovely\n",
       "50650    ENFJ  I have impressed the guy who taught me not to ...\n",
       "...       ...                                                ...\n",
       "1265     ESTP  Asian American History: Movement and Dislocati...\n",
       "122703   ENTJ  I'm not saying that all media is bad all of th...\n",
       "1101969  INTP  Carthage. Spam cities and pick up that +2 Scie...\n",
       "61720    ESTJ                                          Redditors\n",
       "1305117  ENTP  So other than just get the Trump administratio...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T06:32:35.838231Z",
     "start_time": "2019-12-04T06:32:35.290292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBTI        0\n",
       "comments    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "df_punc.isna().sum()\n",
    "\n",
    "# good there is no null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T06:33:19.730814Z",
     "start_time": "2019-12-04T06:33:19.726761Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_punc.comments\n",
    "y = df_punc.MBTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T06:33:23.286153Z",
     "start_time": "2019-12-04T06:33:22.026152Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing in SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T16:46:04.099722Z",
     "start_time": "2019-12-06T16:46:01.690779Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the large English NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Parse the text with spaCy. This runs the entire pipeline.\n",
    "\n",
    "# function for cleaning text \n",
    "def token_filter(token):\n",
    "    return not (token.is_punct | token.is_space | token.is_stop | len(token.text) <= 2 | token.like_email | token.like_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T20:20:17.100887Z",
     "start_time": "2019-12-04T20:20:17.089336Z"
    }
   },
   "outputs": [],
   "source": [
    "# function cleaning \n",
    "def clean_text(docs): \n",
    "    filtered_tokens = []\n",
    "    for doc in nlp.pipe(docs):\n",
    "        tokens = [token.lemma_ for token in doc if token_filter(token) ]\n",
    "        # [tok.lemma_.lower().strip(this removes the -- in -pron-) if tok.lemma_ != \"-PRON-\" else tok.lower_ for tok in tokens]\n",
    "        tokens = [word.lower() for word in tokens]\n",
    "        tokens = [word for word in tokens if word != '-pron-']\n",
    "        tokens = [re.sub(r\"http\\S+\", \"\", word) for word in tokens]\n",
    "        filtered_tokens.append(tokens)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T19:34:24.634641Z",
     "start_time": "2019-12-06T19:34:24.628564Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tqdm/std.py:654: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "from time import sleep\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T19:47:17.013562Z",
     "start_time": "2019-12-06T19:47:17.002825Z"
    }
   },
   "outputs": [],
   "source": [
    "# Further function cleaning \n",
    "def clean_text(docs): \n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for doc in nlp.pipe(docs):\n",
    "        tokens = [token.lemma_ for token in doc if token_filter(token) ]\n",
    "        # [tok.lemma_.lower().strip(this removes the -- in -pron-) if tok.lemma_ != \"-PRON-\" else tok.lower_ for tok in tokens]\n",
    "        tokens = [word.lower() for word in tokens]\n",
    "        tokens = [word for word in tokens if word != '-pron-']\n",
    "        #tokens = [re.sub(r\"http\\S+\", \"\", word) for word in tokens]\n",
    "        tokens = [re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', 'url', word) for word in tokens]\n",
    "        tokens = [re.sub(\"[^a-zA-Z]\", \" \", word) for word in tokens] # keep only words\n",
    "        tokens = [re.sub(' +', ' ', word) for word in tokens] # remove space > 1\n",
    "        filtered_tokens.append(tokens)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T19:44:39.789293Z",
     "start_time": "2019-12-06T19:44:28.022198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118e64b1047b43c493c81b28497a74b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample['text_lemma'] = clean_text(df_sample['comments'])\n",
    "df_sample['text_lemma'] = df_sample['text_lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T18:45:08.018255Z",
     "start_time": "2019-12-06T18:45:07.986457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>787840</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>It's not quite that simple. The \"test taking\" environment is completely different to day-to-day stuff. Dead silence, no referencing/quick checks which I do constantly (to reaffirm my knowledge), the stress of trying to get a good grade, being tested on the spot, having a time limit, etc. It impairs (at least my) ability to remember things.  But just get me out of the blue when I'm completely relaxed and there's no stress or anything? Sure, I could easily tell you.  Also, the questions on exams are usually different than how you'd usually use the knowledge as well as different from how you learned it.  Also, some people are just shit at thoroughly making sure that the knowledge is down on paper. Sometimes you forget to mention something that the other person would simply just follow up on and ask about, which you'd then respond. On a test, that doesn't happen, you just get points knocked off.</td>\n",
       "      <td>be not quite that simple the test take environment be completely different to day to day stuff dead silence no referencing quick check which do constantly to reaffirm knowledge the stress of try to get good grade be test on the spot have time limit etc impair at least ability to remember thing but just get out of the blue when be completely relaxed and there be no stress or anything sure could easily tell also the question on exam be usually different than how would usually use the knowledge as well as different from how learn also some people be just shit at thoroughly make sure that the knowledge be down on paper sometimes forget to mention something that the other person would simply just follow up on and ask about which would then respond on test that do not happen just get point knock off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46144</td>\n",
       "      <td>ISTJ</td>\n",
       "      <td>For those who haven't been in touch with the game for long or very closely (including the creator of this video I assume), in the past we have had multiple news agencies blow up at Arma 3 for being an \"ISIS training simulator\" because of a mod that added ISIS units. Don't let this happen again. Please remove this for the sake of the game.</td>\n",
       "      <td>for those who have not be in touch with the game for long or very closely include the creator of this video assume in the past have have multiple news agency blow up at arma for be an isis training simulator because of mod that add isis unit do not let this happen again please remove this for the sake of the game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321942</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>The fat toothless kid from *Stranger Things*.    He seems to be the only one of the kids who has a grasp of the bigger picture.  He starts off as more  of a sidekick until the other two kids start to lose it, then he steps from out of the shadows, smacks them around until they see sense, and gets everything back on track.</td>\n",
       "      <td>the fat toothless kid from stranger things    seem to be the only one of the kid who have grasp of the big picture start off as more of sidekick until the other two kid start to lose then step from out of the shadow smack around until see sense and get everything back on track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123281</td>\n",
       "      <td>ENFP</td>\n",
       "      <td>I wasn't allowed to wear nail polish, get natural-colored highlights, wear makeup (even to cover a zit), or have any piercing besides one normal-sized love at my school.</td>\n",
       "      <td>be not allow to wear nail polish get natural color highlight wear makeup even to cover zit or have any piercing besides one normal sized love at school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263516</td>\n",
       "      <td>ISFJ</td>\n",
       "      <td>She's been off the grid for what...like a month? Two months? No one in the fandom knows where she is or what she's doing right now. It doesn't surprise me that she didn't go and I'm not sure why everyone is so upset about it. I feel like if she did go, it would have been all over the news (because the media is obsessed with her), then people would be saying \"Ugh, why is Taylor Swift making the women's march all about her?\" Girl can't win.  Not to mention the fact that she has all kinds of psychos who stalk her and doesn't go anywhere without security...all that plus the paparazzi would have created a huge spectacle and detracted from the importance of the march.  Beyonce uses feminism to promote her brand way more than Taylor does, and no one's salty about her not going. I'll never understand why people have such a stick up their ass about Taylor.</td>\n",
       "      <td>be be off the grid for what   like month two month no one in the fandom know where be or what be do right now do not surprise that do not go and be not sure why everyone be so upset about feel like if did go would have be all over the news because the medium be obsess with then people would be say ugh why be taylor swift make the woman  s march all about girl can not win not to mention the fact that have all kind of psychos who stalk and do not go anywhere without security   all that plus the paparazzi would have create huge spectacle and detract from the importance of the march beyonce use feminism to promote brand way more than taylor do and no one  s salty about not go will never understand why people have such stick up ass about taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>689063</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>This isn't about respect this is about ending suffering, hatred has never in all of human history conquered hate and until we decide to tackle the problems at their roots instead of dehumanizing people hate will never end.</td>\n",
       "      <td>this be not about respect this be about end suffering hatred have never in all of human history conquer hate and until decide to tackle the problem at root instead of dehumanize people hate will never end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288663</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>I can help you out personally :) I know a lot about python and have even made a bot in python (/u/dogetipchecker). PM me if you are interested, and I can recommend some books and also answer specific questions about python. I can give you my skype number, and we can chat with skype too if you are OK with that.</td>\n",
       "      <td>can help out personally   know lot about python and have even make bot in python dogetipchecker if be interested and can recommend some book and also answer specific question about python can give skype number and can chat with skype too if be with that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996000</td>\n",
       "      <td>INFP</td>\n",
       "      <td>TIL that the fires of Hell are blue! O_O</td>\n",
       "      <td>til that the fire of hell be blue o o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20057</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>Doesn't spoofing require kernel? Hype?</td>\n",
       "      <td>do not spoof require kernel hype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1127354</td>\n",
       "      <td>INFP</td>\n",
       "      <td>&amp;gt;Trust me on the sunscreen.    Not the sunscreen song?</td>\n",
       "      <td>gt trust on the sunscreen   not the sunscreen song</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MBTI  \\\n",
       "787840   ISTP   \n",
       "46144    ISTJ   \n",
       "321942   ENTP   \n",
       "123281   ENFP   \n",
       "263516   ISFJ   \n",
       "...       ...   \n",
       "689063   ISTP   \n",
       "288663   ENTP   \n",
       "996000   INFP   \n",
       "20057    ISTP   \n",
       "1127354  INFP   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         comments  \\\n",
       "787840   It's not quite that simple. The \"test taking\" environment is completely different to day-to-day stuff. Dead silence, no referencing/quick checks which I do constantly (to reaffirm my knowledge), the stress of trying to get a good grade, being tested on the spot, having a time limit, etc. It impairs (at least my) ability to remember things.  But just get me out of the blue when I'm completely relaxed and there's no stress or anything? Sure, I could easily tell you.  Also, the questions on exams are usually different than how you'd usually use the knowledge as well as different from how you learned it.  Also, some people are just shit at thoroughly making sure that the knowledge is down on paper. Sometimes you forget to mention something that the other person would simply just follow up on and ask about, which you'd then respond. On a test, that doesn't happen, you just get points knocked off.   \n",
       "46144    For those who haven't been in touch with the game for long or very closely (including the creator of this video I assume), in the past we have had multiple news agencies blow up at Arma 3 for being an \"ISIS training simulator\" because of a mod that added ISIS units. Don't let this happen again. Please remove this for the sake of the game.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "321942   The fat toothless kid from *Stranger Things*.    He seems to be the only one of the kids who has a grasp of the bigger picture.  He starts off as more  of a sidekick until the other two kids start to lose it, then he steps from out of the shadows, smacks them around until they see sense, and gets everything back on track.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "123281   I wasn't allowed to wear nail polish, get natural-colored highlights, wear makeup (even to cover a zit), or have any piercing besides one normal-sized love at my school.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "263516   She's been off the grid for what...like a month? Two months? No one in the fandom knows where she is or what she's doing right now. It doesn't surprise me that she didn't go and I'm not sure why everyone is so upset about it. I feel like if she did go, it would have been all over the news (because the media is obsessed with her), then people would be saying \"Ugh, why is Taylor Swift making the women's march all about her?\" Girl can't win.  Not to mention the fact that she has all kinds of psychos who stalk her and doesn't go anywhere without security...all that plus the paparazzi would have created a huge spectacle and detracted from the importance of the march.  Beyonce uses feminism to promote her brand way more than Taylor does, and no one's salty about her not going. I'll never understand why people have such a stick up their ass about Taylor.                                                \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...                                            \n",
       "689063   This isn't about respect this is about ending suffering, hatred has never in all of human history conquered hate and until we decide to tackle the problems at their roots instead of dehumanizing people hate will never end.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "288663   I can help you out personally :) I know a lot about python and have even made a bot in python (/u/dogetipchecker). PM me if you are interested, and I can recommend some books and also answer specific questions about python. I can give you my skype number, and we can chat with skype too if you are OK with that.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "996000   TIL that the fires of Hell are blue! O_O                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "20057    Doesn't spoofing require kernel? Hype?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "1127354  &gt;Trust me on the sunscreen.    Not the sunscreen song?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text_lemma  \n",
       "787840   be not quite that simple the test take environment be completely different to day to day stuff dead silence no referencing quick check which do constantly to reaffirm knowledge the stress of try to get good grade be test on the spot have time limit etc impair at least ability to remember thing but just get out of the blue when be completely relaxed and there be no stress or anything sure could easily tell also the question on exam be usually different than how would usually use the knowledge as well as different from how learn also some people be just shit at thoroughly make sure that the knowledge be down on paper sometimes forget to mention something that the other person would simply just follow up on and ask about which would then respond on test that do not happen just get point knock off  \n",
       "46144    for those who have not be in touch with the game for long or very closely include the creator of this video assume in the past have have multiple news agency blow up at arma for be an isis training simulator because of mod that add isis unit do not let this happen again please remove this for the sake of the game                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "321942   the fat toothless kid from stranger things    seem to be the only one of the kid who have grasp of the big picture start off as more of sidekick until the other two kid start to lose then step from out of the shadow smack around until see sense and get everything back on track                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "123281   be not allow to wear nail polish get natural color highlight wear makeup even to cover zit or have any piercing besides one normal sized love at school                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "263516   be be off the grid for what   like month two month no one in the fandom know where be or what be do right now do not surprise that do not go and be not sure why everyone be so upset about feel like if did go would have be all over the news because the medium be obsess with then people would be say ugh why be taylor swift make the woman  s march all about girl can not win not to mention the fact that have all kind of psychos who stalk and do not go anywhere without security   all that plus the paparazzi would have create huge spectacle and detract from the importance of the march beyonce use feminism to promote brand way more than taylor do and no one  s salty about not go will never understand why people have such stick up ass about taylor                                                         \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...                                                       \n",
       "689063   this be not about respect this be about end suffering hatred have never in all of human history conquer hate and until decide to tackle the problem at root instead of dehumanize people hate will never end                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "288663   can help out personally   know lot about python and have even make bot in python dogetipchecker if be interested and can recommend some book and also answer specific question about python can give skype number and can chat with skype too if be with that                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "996000   til that the fire of hell be blue o o                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "20057    do not spoof require kernel hype                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "1127354  gt trust on the sunscreen   not the sunscreen song                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample\n",
    "#pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T21:25:33.418581Z",
     "start_time": "2019-12-04T20:23:33.632595Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-70a06912ad0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_punc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments_lemma'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_punc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_punc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments_lemma'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_punc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comments_lemma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-131-86edf1d59169>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(docs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfiltered_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# [tok.lemma_.lower().strip(this removes the -- in -pron-) if tok.lemma_ != \"-PRON-\" else tok.lower_ for tok in tokens]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, texts, as_tuples, n_threads, batch_size, disable, cleanup, component_cfg)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0moriginal_strings_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mnr_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/resnet.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/thinc/neural/_classes/maxout.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X__bi, drop)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdrop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mdrop\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX__bi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_punc['comments_lemma'] = clean_text(df_punc['comments'])\n",
    "df_punc['comments_lemma'] = df_punc['comments_lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T20:22:05.538662Z",
     "start_time": "2019-12-04T20:22:05.522850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>comments</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>162062</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>NO THAT'S THE COMPETITION FOR BORING RUGBY.</td>\n",
       "      <td>no that be the competition for boring rugby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1551436</td>\n",
       "      <td>INFP</td>\n",
       "      <td>Search for it.</td>\n",
       "      <td>search for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54899</td>\n",
       "      <td>ESFJ</td>\n",
       "      <td>I quickly made a room in GroupMe if you wanted...</td>\n",
       "      <td>quickly make room in groupme if want to give t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>He never said that, god damn your such a strawman</td>\n",
       "      <td>never say that god damn such strawman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>933076</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>\"Great, I'll remember that,\" I smile before si...</td>\n",
       "      <td>great will remember that smile before sip beer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15416</td>\n",
       "      <td>ESTJ</td>\n",
       "      <td>&amp;gt; ENTJ for Gilgamesh, not ESTJ and definite...</td>\n",
       "      <td>entj for gilgamesh not estj and definitely not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>759747</td>\n",
       "      <td>INFP</td>\n",
       "      <td>People who lack empathy usually also lack shame</td>\n",
       "      <td>people who lack empathy usually also lack shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1209225</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ESFJ mom and Entp dad. Sisters are ENFP, INTP,...</td>\n",
       "      <td>esfj mom and entp dad sister be enfp intp isfj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380907</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>i haven't updated my flair, I graduated about ...</td>\n",
       "      <td>have not update flair graduate about month ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>939715</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>Reddit gold costs less than a beer. Either do ...</td>\n",
       "      <td>reddit gold cost less than beer either do or d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MBTI                                           comments  \\\n",
       "162062   ISTP        NO THAT'S THE COMPETITION FOR BORING RUGBY.   \n",
       "1551436  INFP                                    Search for it.    \n",
       "54899    ESFJ  I quickly made a room in GroupMe if you wanted...   \n",
       "1960     ESTP  He never said that, god damn your such a strawman   \n",
       "933076   INFJ  \"Great, I'll remember that,\" I smile before si...   \n",
       "...       ...                                                ...   \n",
       "15416    ESTJ  &gt; ENTJ for Gilgamesh, not ESTJ and definite...   \n",
       "759747   INFP    People who lack empathy usually also lack shame   \n",
       "1209225  ENTJ  ESFJ mom and Entp dad. Sisters are ENFP, INTP,...   \n",
       "380907   ENTP  i haven't updated my flair, I graduated about ...   \n",
       "939715   ENTJ  Reddit gold costs less than a beer. Either do ...   \n",
       "\n",
       "                                                text_lemma  \n",
       "162062         no that be the competition for boring rugby  \n",
       "1551436                                         search for  \n",
       "54899    quickly make room in groupme if want to give t...  \n",
       "1960                 never say that god damn such strawman  \n",
       "933076   great will remember that smile before sip beer...  \n",
       "...                                                    ...  \n",
       "15416    entj for gilgamesh not estj and definitely not...  \n",
       "759747     people who lack empathy usually also lack shame  \n",
       "1209225  esfj mom and entp dad sister be enfp intp isfj...  \n",
       "380907   have not update flair graduate about month ago...  \n",
       "939715   reddit gold cost less than beer either do or d...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T20:22:15.136205Z",
     "start_time": "2019-12-04T20:22:14.772875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about 15 months ago 40 59 DATE\n",
      "3 days 94 100 DATE\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(df_sample['comments'].iloc[98])\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
